{
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdullatifHabiba/Semi-Supervised-Approach-for-Sentiment/blob/main/Semi_Supervised_Approach_for_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configuring and importing libraries"
      ],
      "metadata": {
        "id": "3xecUisTpFDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install arabic-stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QhzXTieqB7E",
        "outputId": "001ffc70-0d1a-479e-eee3-15be4e7b7eda",
        "execution": {
          "iopub.status.busy": "2023-07-29T12:01:12.693267Z",
          "iopub.execute_input": "2023-07-29T12:01:12.693618Z",
          "iopub.status.idle": "2023-07-29T12:01:26.699180Z",
          "shell.execute_reply.started": "2023-07-29T12:01:12.693588Z",
          "shell.execute_reply": "2023-07-29T12:01:26.697922Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arabic-stopwords\n",
            "  Downloading Arabic_Stopwords-0.4.3-py3-none-any.whl (360 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.5/360.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarabic>=0.6.2 (from arabic-stopwords)\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic>=0.6.2->arabic-stopwords) (1.16.0)\n",
            "Installing collected packages: pyarabic, arabic-stopwords\n",
            "Successfully installed arabic-stopwords-0.4.3 pyarabic-0.6.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gdown"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:01:26.701529Z",
          "iopub.execute_input": "2023-07-29T12:01:26.702185Z",
          "iopub.status.idle": "2023-07-29T12:01:38.354370Z",
          "shell.execute_reply.started": "2023-07-29T12:01:26.702148Z",
          "shell.execute_reply": "2023-07-29T12:01:38.352955Z"
        },
        "trusted": true,
        "id": "4pxMmVQx7jdA",
        "outputId": "63543ef6-d4a7-4e73-ba1a-632097843b95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install camel-tools\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:01:38.356531Z",
          "iopub.execute_input": "2023-07-29T12:01:38.356912Z",
          "iopub.status.idle": "2023-07-29T12:05:05.326054Z",
          "shell.execute_reply.started": "2023-07-29T12:01:38.356875Z",
          "shell.execute_reply": "2023-07-29T12:05:05.324884Z"
        },
        "trusted": true,
        "id": "6syKSfsA7jdA",
        "outputId": "6665c6fe-ed5a-44b8-ef5e-3c794c4946c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting camel-tools\n",
            "  Downloading camel_tools-1.5.2-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m828.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from camel-tools) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from camel-tools) (1.16.0)\n",
            "Collecting docopt (from camel-tools)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from camel-tools) (5.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from camel-tools) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from camel-tools) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from camel-tools) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from camel-tools) (1.2.2)\n",
            "Collecting dill (from camel-tools)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from camel-tools) (2.0.1+cu118)\n",
            "Collecting transformers>=3.0.2 (from camel-tools)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from camel-tools) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from camel-tools) (2.27.1)\n",
            "Collecting emoji (from camel-tools)\n",
            "  Downloading emoji-2.7.0.tar.gz (361 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.8/361.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyrsistent in /usr/local/lib/python3.10/dist-packages (from camel-tools) (0.19.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from camel-tools) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from camel-tools) (4.65.0)\n",
            "Collecting muddler (from camel-tools)\n",
            "  Downloading muddler-0.1.3-py3-none-any.whl (16 kB)\n",
            "Collecting camel-kenlm>=2023.3.17.2 (from camel-tools)\n",
            "  Downloading camel-kenlm-2023.3.17.2.tar.gz (426 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel-tools) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel-tools) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel-tools) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel-tools) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel-tools) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel-tools) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->camel-tools) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->camel-tools) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=3.0.2->camel-tools)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel-tools) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel-tools) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel-tools) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=3.0.2->camel-tools)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=3.0.2->camel-tools)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->camel-tools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->camel-tools) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->camel-tools) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->camel-tools) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->camel-tools) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->camel-tools) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->camel-tools) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->camel-tools) (3.2.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.2->camel-tools) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->camel-tools) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->camel-tools) (1.3.0)\n",
            "Building wheels for collected packages: camel-kenlm, docopt, emoji\n",
            "  Building wheel for camel-kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camel-kenlm: filename=camel_kenlm-2023.3.17.2-cp310-cp310-linux_x86_64.whl size=3452676 sha256=993ba2fa9be3aec30f2fc33b2fb69dd6d3b47081440d396d09c60fa0bb8a0ff9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/c5/32/09633c3b70fdfc470b2fb912bd9e90d8d6814df68c794dcaa6\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=d379698d0ed692c63d09268673e75f605bb6d809ba9f6c7b0c8b3a1908a17ec2\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for emoji (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.7.0-py2.py3-none-any.whl size=356563 sha256=0e308ee2994e82c96ea6a46735655ffe31aba3ec9bbbd4bd2cef0eb1fb2379c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/11/48/5df0b9727d5669c9174a141134f10304d1d78a3b89a4676f3d\n",
            "Successfully built camel-kenlm docopt emoji\n",
            "Installing collected packages: tokenizers, safetensors, docopt, camel-kenlm, muddler, emoji, dill, huggingface-hub, transformers, camel-tools\n",
            "Successfully installed camel-kenlm-2023.3.17.2 camel-tools-1.5.2 dill-0.3.7 docopt-0.6.2 emoji-2.7.0 huggingface-hub-0.16.4 muddler-0.1.3 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get important libraries and packages in project"
      ],
      "metadata": {
        "id": "ocOI-SBoLk0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
        "import arabicstopwords.arabicstopwords as ast\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
        "from camel_tools.utils.normalize import normalize_alef_ar\n",
        "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
        "\n",
        "from nltk.stem import ISRIStemmer\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "cIve2txNpMCK",
        "execution": {
          "iopub.status.busy": "2023-07-29T12:05:05.330870Z",
          "iopub.execute_input": "2023-07-29T12:05:05.331172Z",
          "iopub.status.idle": "2023-07-29T12:05:05.685557Z",
          "shell.execute_reply.started": "2023-07-29T12:05:05.331145Z",
          "shell.execute_reply": "2023-07-29T12:05:05.684559Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3_CyrRM_jt9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown \"1Dj9OSnSg-kvpNjJTxhaWW_FpQvh04s3o\"  #our LABR-book-reviews.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwOLw_oANvCd",
        "outputId": "6cfd2d0a-c061-4f01-994a-f5cd431b746a",
        "execution": {
          "iopub.status.busy": "2023-07-29T01:45:39.864149Z",
          "iopub.execute_input": "2023-07-29T01:45:39.864590Z",
          "iopub.status.idle": "2023-07-29T01:45:40.875315Z",
          "shell.execute_reply.started": "2023-07-29T01:45:39.864556Z",
          "shell.execute_reply": "2023-07-29T01:45:40.874125Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Dj9OSnSg-kvpNjJTxhaWW_FpQvh04s3o\n",
            "To: /content/LABR-book-reviews.csv\n",
            "\r  0% 0.00/9.17M [00:00<?, ?B/s]\r100% 9.17M/9.17M [00:00<00:00, 110MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data = pd.read_csv(\"/content/LABR-book-reviews.csv\")"
      ],
      "metadata": {
        "id": "At_Ni2_yPuXb",
        "execution": {
          "iopub.status.busy": "2023-07-29T12:11:54.436418Z",
          "iopub.execute_input": "2023-07-29T12:11:54.436783Z",
          "iopub.status.idle": "2023-07-29T12:11:54.626912Z",
          "shell.execute_reply.started": "2023-07-29T12:11:54.436748Z",
          "shell.execute_reply": "2023-07-29T12:11:54.625920Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DELJzdkxl525",
        "outputId": "9162fe4b-b2a4-4db6-db58-fbe33154c760",
        "execution": {
          "iopub.status.busy": "2023-07-29T01:54:54.476114Z",
          "iopub.execute_input": "2023-07-29T01:54:54.476478Z",
          "iopub.status.idle": "2023-07-29T01:54:54.486576Z",
          "shell.execute_reply.started": "2023-07-29T01:54:54.476448Z",
          "shell.execute_reply": "2023-07-29T01:54:54.485486Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   sentiment                                                txt\n0          0                           مكملتش اكتر 30 صفحه بضان\n1          0  النادر ان يعجبني الفلم اكثر الروايه  تفوق دعاء...\n2          0  كتاب سي الاسلوب ممتع نهايه مفتوحه والكتاب بوجه...\n3          0  قصه مشوقه ونهايه مفتوحه  اسوء صفحه في الروايه ...\n4          0  ابدع الكاتب سرد الحقائق التاريخيه او بمعني اصح...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>txt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>مكملتش اكتر 30 صفحه بضان</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>النادر ان يعجبني الفلم اكثر الروايه  تفوق دعاء...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>كتاب سي الاسلوب ممتع نهايه مفتوحه والكتاب بوجه...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>قصه مشوقه ونهايه مفتوحه  اسوء صفحه في الروايه ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>ابدع الكاتب سرد الحقائق التاريخيه او بمعني اصح...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB7P6ZDErXyS",
        "outputId": "aa11dc52-6e1c-4bda-e723-f083d516bfba",
        "execution": {
          "iopub.status.busy": "2023-07-29T01:49:39.192718Z",
          "iopub.execute_input": "2023-07-29T01:49:39.193592Z",
          "iopub.status.idle": "2023-07-29T01:49:39.221331Z",
          "shell.execute_reply.started": "2023-07-29T01:49:39.193559Z",
          "shell.execute_reply": "2023-07-29T01:49:39.220320Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16448 entries, 0 to 16447\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   sentiment  16448 non-null  int64 \n 1   txt        16448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 257.1+ KB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1eEeno1rksB",
        "outputId": "ab3a50bf-c6f8-4d44-f6b1-5a421b159f59",
        "execution": {
          "iopub.status.busy": "2023-07-29T01:49:39.222700Z",
          "iopub.execute_input": "2023-07-29T01:49:39.223065Z",
          "iopub.status.idle": "2023-07-29T01:49:39.231288Z",
          "shell.execute_reply.started": "2023-07-29T01:49:39.223033Z",
          "shell.execute_reply": "2023-07-29T01:49:39.229826Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    8224\n1    8224\nName: sentiment, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='sentiment', data=Data, palette='viridis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "KtbyREmasQpV",
        "outputId": "016d30f1-c57d-4201-c50a-969eb5cfec43",
        "execution": {
          "iopub.status.busy": "2023-07-29T01:49:39.233008Z",
          "iopub.execute_input": "2023-07-29T01:49:39.233781Z",
          "iopub.status.idle": "2023-07-29T01:49:39.507662Z",
          "shell.execute_reply.started": "2023-07-29T01:49:39.233733Z",
          "shell.execute_reply": "2023-07-29T01:49:39.506784Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<Axes: xlabel='sentiment', ylabel='count'>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4lcVWga5nren"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdNoBQEBnsFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data['txt'][10:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2hKB7EBufFB",
        "outputId": "bc372877-f230-467a-fc49-659eae37b8af",
        "execution": {
          "iopub.status.busy": "2023-07-29T01:49:39.511157Z",
          "iopub.execute_input": "2023-07-29T01:49:39.511464Z",
          "iopub.status.idle": "2023-07-29T01:49:39.518645Z",
          "shell.execute_reply.started": "2023-07-29T01:49:39.511438Z",
          "shell.execute_reply": "2023-07-29T01:49:39.517784Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "10     كوميديا ساخرة عن نظام اسئلة الإمتحانات العقيم...\n11     أذكر أني قرأته وأنا طفلة او بدايات المراهقة ....\n12                     لم يعجبني والشريط منه افضل وامتع\n13     كتاب حلو ويستاهل القراءة اكثر من مرة ولازم ال...\n14     أول رواية أقرأها لأحلام لغتها عذبة ساحرة لذيذ...\n15     روايه ممتعه تحمست لها اكثر لما عرفت انها نقل ...\n16     متوسطة . بالرغم من نضوج أسلوب الكاتبة فيها أك...\n17     كتاب لا بأس به، لطيف و خفيف، أسلوب أستاذ أحمد...\n18     كتاب ممل جدا و لم استمتع الا باولة و يدخل فى ...\n19                            ما استطعت اكمال الرواية .\nName: txt, dtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "UqAyHMxundWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning data"
      ],
      "metadata": {
        "id": "h77HToVRnj3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Reducing Orthographic Ambiguity\n",
        "2.   Remove stopwords\n",
        "3.   Removing Punctuations\n",
        "\n"
      ],
      "metadata": {
        "id": "-kpt0woP2jqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of stop words\n",
        "stop_words = ast.stopwords_list()\n",
        "\n",
        "# Define a string containing Arabic punctuations\n",
        "arabic_punctuations = '''`÷×؛<>_():*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
        "\n",
        "# Get a string containing English punctuations\n",
        "english_punctuations = string.punctuation\n",
        "\n",
        "# Concatenate Arabic and English punctuations to create a single list\n",
        "punctuations_list = arabic_punctuations + english_punctuations"
      ],
      "metadata": {
        "id": "clCZoHifMfxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ortho_normalize(text):\n",
        "    text = normalize_alef_maksura_ar(text)\n",
        "    text = normalize_alef_ar(text)\n",
        "    text = normalize_teh_marbuta_ar(text)\n",
        "    return text\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    return ' '.join(word for word in str(text).split() if word not in stop_words)\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "0bLCQCwPn2Vh",
        "execution": {
          "iopub.status.busy": "2023-07-29T01:49:39.519841Z",
          "iopub.execute_input": "2023-07-29T01:49:39.520730Z",
          "iopub.status.idle": "2023-07-29T01:49:39.532246Z",
          "shell.execute_reply.started": "2023-07-29T01:49:39.520697Z",
          "shell.execute_reply": "2023-07-29T01:49:39.531222Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applay the filter on the text\n",
        "\n",
        "Data['txt'] = Data['txt'].apply(remove_stop_words)\n",
        "\n",
        "Data['txt'] = Data['txt'].apply(remove_punctuations)\n",
        "\n",
        "Data['txt'] = Data['txt'].apply(ortho_normalize)\n"
      ],
      "metadata": {
        "id": "gYwM_tcQAEb3",
        "execution": {
          "iopub.status.busy": "2023-07-29T01:49:39.545589Z",
          "iopub.execute_input": "2023-07-29T01:49:39.546509Z",
          "iopub.status.idle": "2023-07-29T01:52:33.562910Z",
          "shell.execute_reply.started": "2023-07-29T01:49:39.546478Z",
          "shell.execute_reply": "2023-07-29T01:52:33.561911Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### stemming/lemmatization\n",
        "\n",
        "*   snow_stemmer not worked well give long vectors with no change in accuracy\n",
        "*   lemmatization also didn't affect more in results\n",
        "\n"
      ],
      "metadata": {
        "id": "NKyzBeG_JUsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#   Applies stemming to the input Arabic text using the ISRI Arabic stemmer.\n",
        "\n",
        "isri_stemmer = ISRIStemmer()\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "def stemming(text):\n",
        "    s = \" \"\n",
        "    x = w_tokenizer.tokenize(text)\n",
        "    return s.join([isri_stemmer.stem(w) for w in x])\n",
        "\n",
        "Data[\"stemming Words\"] = Data['txt'].apply(stemming)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T21:14:16.292451Z",
          "iopub.execute_input": "2023-07-28T21:14:16.292818Z",
          "iopub.status.idle": "2023-07-28T21:14:22.412745Z",
          "shell.execute_reply.started": "2023-07-28T21:14:16.292775Z",
          "shell.execute_reply": "2023-07-28T21:14:22.411784Z"
        },
        "trusted": true,
        "id": "7BeIBWr67jdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#worse in preformance than the isri stemmer\n",
        "'''snow_stemmer = SnowballStemmer(language='arabic')\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "def stemming(text):\n",
        "  s=\" \"\n",
        "  x = w_tokenizer.tokenize(text)\n",
        "  return s.join([snow_stemmer.stem(w) for w in x])\n",
        "\n",
        "Data[\"stemming Words\"] = Data['txt'].apply(stemming)\n",
        "'''"
      ],
      "metadata": {
        "id": "lvM8K46PxPQV",
        "outputId": "a60b95ed-cf4d-42b6-d345-264d0c4ee0a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "execution": {
          "iopub.status.busy": "2023-07-28T13:20:13.236371Z",
          "iopub.execute_input": "2023-07-28T13:20:13.237604Z",
          "iopub.status.idle": "2023-07-28T13:20:13.250690Z",
          "shell.execute_reply.started": "2023-07-28T13:20:13.237543Z",
          "shell.execute_reply": "2023-07-28T13:20:13.249363Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'snow_stemmer = SnowballStemmer(language=\\'arabic\\')\\n\\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\\ndef stemming(text):\\n  s=\" \"\\n  x = w_tokenizer.tokenize(text)\\n  return s.join([snow_stemmer.stem(w) for w in x])\\n\\nData[\"stemming Words\"] = Data[\\'txt\\'].apply(stemming)\\n'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_text_review_lengths(data_frame, column_name):\n",
        "    # Count the length of each text review\n",
        "    data_frame['text_length'] = data_frame[column_name].apply(len)\n",
        "\n",
        "    # Create a histogram to visualize the distribution of text lengths\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(data_frame['text_length'], bins=50, edgecolor='k')\n",
        "    plt.xlabel('Text Review Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Text Review Lengths')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9Z1G3gUipy6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_text_review_lengths(Data, 'txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "RrDaw6R0pzD1",
        "outputId": "71b5d5df-fcfa-419d-c62b-9fba7e0cc4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=Data.copy()"
      ],
      "metadata": {
        "id": "YggYOSNwqOsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataFrame 'df' with text reviews stored in the 'review_text' column\n",
        "# You can replace 'review_text' with the actual column name containing your text reviews\n",
        "\n",
        "# Create a new column 'word_count' that contains the number of words in each review\n",
        "df['word_count'] = df['txt'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Create a histogram to visualize the distribution of review lengths\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df[df['word_count'] < 10]['word_count'], bins=10, edgecolor='k')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Reviews with Less than 10 Words')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "BnuJgOnfqC8K",
        "outputId": "0de38468-21c8-4173-8306-6b0e9a537268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataFrame 'df' with the 'word_count' column already created as shown in the previous code\n",
        "\n",
        "# Filter the DataFrame to get reviews with less than four words\n",
        "reviews_less_than_4_words = df[df['word_count'] < 3]['txt']\n",
        "\n",
        "# Print four examples of reviews with less than four words\n",
        "for i, review in enumerate(reviews_less_than_4_words.head(4)):\n",
        "    print(f\"Example {i+1}: {review}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRqfvoojrJZI",
        "outputId": "5913a9b3-8b71-4da0-8adb-b50d3ae08789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1: بيضحّك اوي \n",
            "Example 2: ابهرتني\n",
            "Example 3: اسوا قرات\n",
            "Example 4: مليكه\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to get reviews with less than four words\n",
        "reviews_less_than_4_words = df[df['word_count'] < 2]['txt']\n",
        "\n",
        "# Print four examples of reviews with less than four words\n",
        "for i, review in enumerate(reviews_less_than_4_words.head(8)):\n",
        "    print(f\"Example {i+1}: {review}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsreIrGNrasY",
        "outputId": "ff9c543f-67a9-43fa-8000-0e563c9c9ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1: ابهرتني\n",
            "Example 2: مليكه\n",
            "Example 3: رائع\n",
            "Example 4: حبيييت \n",
            "Example 5: ابدااااااااع \n",
            "Example 6: معجبنيش\n",
            "Example 7: جميل \n",
            "Example 8: صالح\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding : MarBert model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WstkItJqG9vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#specifys the model we are using the intilze the bert toknizer and embedding\n",
        "marbert_model_path = 'UBC-NLP/MARBERT'\n",
        "tokenizer = AutoTokenizer.from_pretrained(marbert_model_path, from_tf=True)\n",
        "marbert_model = TFAutoModel.from_pretrained(marbert_model_path, output_hidden_states=True)\n",
        "\n",
        "def bert_tokenize(texts: str) -> list:\n",
        "    max_len = 0\n",
        "    for text in texts:\n",
        "        max_len = max(len(tokenizer.tokenize(f'[CLS] {text} [SEP]')), max_len)\n",
        "    tokens = tokenizer(texts, padding='max_length', truncation=True, max_length=max_len)\n",
        "    return (tokens['input_ids'], tokens['attention_mask'], tokens['token_type_ids'])\n",
        "\n",
        "def get_embeddings(tokens):\n",
        "    ids = tf.convert_to_tensor(tokens[0])\n",
        "    mask = tf.convert_to_tensor(tokens[1])\n",
        "    type_ids = tf.convert_to_tensor(tokens[2])\n",
        "    hidden_states = marbert_model(input_ids=ids, attention_mask=mask, token_type_ids=type_ids)[2]\n",
        "    sentence_embd = tf.reduce_mean(tf.reduce_sum(tf.stack(hidden_states[-4:]), axis = 0), axis=1)\n",
        "    return sentence_embd"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T21:34:24.636175Z",
          "iopub.execute_input": "2023-07-28T21:34:24.636559Z",
          "iopub.status.idle": "2023-07-28T21:34:47.363140Z",
          "shell.execute_reply.started": "2023-07-28T21:34:24.636523Z",
          "shell.execute_reply": "2023-07-28T21:34:47.362044Z"
        },
        "trusted": true,
        "id": "dwZiAZLO7jdT",
        "outputId": "2ab18bf2-91e9-4cba-9ddd-e6f8e6bd9d99",
        "colab": {
          "referenced_widgets": [
            "81b11428ea8d410586911486cb5630d7"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading tf_model.h5:   0%|          | 0.00/652M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81b11428ea8d410586911486cb5630d7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "All model checkpoint layers were used when initializing TFBertModel.\n\nAll the layers of TFBertModel were initialized from the model checkpoint at UBC-NLP/MARBERT.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# DIVIDING THE DATA INTO BATCHEoS AND PROCESSING THAT TO KEEP THE TRANING STABLE due to hardware limitations\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming your data is already loaded and `Data['txt'].values` is available\n",
        "batch_size=4\n",
        "batch_size = Data['txt'].values.shape[0] // 10\n",
        "rem = Data['txt'].values.shape[0] % 10\n",
        "start_batch_idx = 0  # Set this variable to the desired starting batch index\n",
        "\n",
        "for batch_idx in range(start_batch_idx, 10):\n",
        "    if batch_idx < 9:\n",
        "        batch_data = Data['txt'].values[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
        "    else:\n",
        "        batch_data = Data['txt'].values[batch_idx * batch_size :]\n",
        "\n",
        "    x_batch = np.empty(shape=(batch_data.shape[0], 768), dtype=np.float64)\n",
        "\n",
        "    for i, text in enumerate(tqdm(batch_data, desc=f'Processing batch {batch_idx+1}..')):\n",
        "        tokens = bert_tokenize([text])\n",
        "        x_batch[i] = get_embeddings(tokens)\n",
        "\n",
        "    np.save(f'batch_features_{batch_idx}.npy', x_batch)\n",
        "    print(f'Batch {batch_idx+1} features saved.')\n",
        "\n",
        "print(\"All batches processed and saved.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T22:30:04.827096Z",
          "iopub.execute_input": "2023-07-28T22:30:04.827501Z",
          "iopub.status.idle": "2023-07-28T23:26:52.184356Z",
          "shell.execute_reply.started": "2023-07-28T22:30:04.827468Z",
          "shell.execute_reply": "2023-07-28T23:26:52.183108Z"
        },
        "trusted": true,
        "id": "ocuhtkgY7jdT",
        "outputId": "ca59de79-4ab1-486b-a37b-b6bd3c2eae38"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Processing batch 1..: 100%|██████████| 1644/1644 [05:35<00:00,  4.90it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 1 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 2..: 100%|██████████| 1644/1644 [05:34<00:00,  4.91it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 2 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 3..: 100%|██████████| 1644/1644 [05:31<00:00,  4.95it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 3 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 4..: 100%|██████████| 1644/1644 [05:31<00:00,  4.95it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 4 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 5..: 100%|██████████| 1644/1644 [05:31<00:00,  4.96it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 5 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 6..: 100%|██████████| 1644/1644 [05:31<00:00,  4.96it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 6 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 7..: 100%|██████████| 1644/1644 [05:40<00:00,  4.83it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 7 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 8..: 100%|██████████| 1644/1644 [05:55<00:00,  4.62it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 8 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 9..: 100%|██████████| 1644/1644 [05:56<00:00,  4.61it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 9 features saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing batch 10..: 100%|██████████| 1652/1652 [05:57<00:00,  4.62it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Batch 10 features saved.\nAll batches processed and saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create an empty list to store the batch feature arrays\n",
        "all_batches = []\n",
        "\n",
        "start_batch_idx = 0\n",
        "\n",
        "for batch_idx in range(start_batch_idx, 10):\n",
        "    batch_file_path = f'batch_features_{batch_idx}.npy'\n",
        "    batch_features = np.load(batch_file_path)\n",
        "    all_batches.append(batch_features)\n",
        "\n",
        "# Concatenate all the batches along the first axis (axis=0)\n",
        "x_train = np.concatenate(all_batches, axis=0)\n",
        "\n",
        "# Now `x_train` contains the combined feature array from all the batches\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T23:32:22.367778Z",
          "iopub.execute_input": "2023-07-28T23:32:22.368155Z",
          "iopub.status.idle": "2023-07-28T23:32:22.543517Z",
          "shell.execute_reply.started": "2023-07-28T23:32:22.368122Z",
          "shell.execute_reply": "2023-07-28T23:32:22.542472Z"
        },
        "trusted": true,
        "id": "oCkbYUOQ7jdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# ... (previous code to combine all batches into x_train)\n",
        "\n",
        "# Save the combined feature array to a file\n",
        "np.save('x_train_marbert_embed.npy', x_train)\n",
        "\n",
        "print(\"Combined feature array saved as 'x_train.npy'.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T23:34:14.345232Z",
          "iopub.execute_input": "2023-07-28T23:34:14.345659Z",
          "iopub.status.idle": "2023-07-28T23:34:14.434691Z",
          "shell.execute_reply.started": "2023-07-28T23:34:14.345618Z",
          "shell.execute_reply": "2023-07-28T23:34:14.433515Z"
        },
        "trusted": true,
        "id": "6TOPpTPz7jdi",
        "outputId": "227342f4-93d8-4cb2-fa25-66ee62c07757"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Combined feature array saved as 'x_train.npy'.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = '/kaggle/working/x_train_marbert_embed.npy'\n",
        "\n",
        "# Load the data from the .npy file\n",
        "x_train = np.load(file_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-07-29T16:06:42.046331Z",
          "iopub.execute_input": "2023-07-29T16:06:42.047470Z",
          "iopub.status.idle": "2023-07-29T16:06:42.092629Z",
          "shell.execute_reply.started": "2023-07-29T16:06:42.047436Z",
          "shell.execute_reply": "2023-07-29T16:06:42.091519Z"
        },
        "trusted": true,
        "id": "3sgixViR7jdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T23:32:56.579998Z",
          "iopub.execute_input": "2023-07-28T23:32:56.580390Z",
          "iopub.status.idle": "2023-07-28T23:32:56.588742Z",
          "shell.execute_reply.started": "2023-07-28T23:32:56.580357Z",
          "shell.execute_reply": "2023-07-28T23:32:56.587630Z"
        },
        "trusted": true,
        "id": "OoZRWO_w7jdi",
        "outputId": "317000db-899a-445a-9c75-af4223ff7f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(16448, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### split data after loading embedding"
      ],
      "metadata": {
        "id": "W2Dr1e8jL2lI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you have 'embeddings' and 'labels' arrays\n",
        "# Here 'embeddings' should be of shape (num_samples, 768) and 'labels' of shape (num_samples, 1)\n",
        "\n",
        "# Number of samples to select for each label\n",
        "num_samples_per_label = 5000\n",
        "\n",
        "# Select indices for samples with label 1\n",
        "indices_label_1 = np.where(Data[\"sentiment\"] == 1)[0]\n",
        "selected_indices_label_1 = np.random.choice(indices_label_1, num_samples_per_label, replace=False)\n",
        "\n",
        "# Select indices for samples with label 0\n",
        "indices_label_0 = np.where(Data[\"sentiment\"] == 0)[0]\n",
        "selected_indices_label_0 = np.random.choice(indices_label_0, num_samples_per_label, replace=False)\n",
        "\n",
        "# Combine the selected indices for both labels\n",
        "selected_indices = np.concatenate([selected_indices_label_1, selected_indices_label_0])\n",
        "\n",
        "# Create the new dataset with selected samples and their embeddings\n",
        "selected_data = x_train[selected_indices]\n",
        "selected_labels = Data[\"sentiment\"][selected_indices]\n",
        "\n",
        "# Shuffle the dataset\n",
        "shuffled_indices = np.random.permutation(len(selected_data))\n",
        "selected_data = x_train[shuffled_indices]\n",
        "selected_labels =  Data[\"sentiment\"][shuffled_indices]\n",
        "\n",
        "# Now you have a new dataset 'selected_data' containing embeddings\n",
        "# and 'selected_labels' containing corresponding labels for 5000 samples of each label (1 and 0).\n",
        "remaining_indices = np.setdiff1d(np.arange(len(x_train)),shuffled_indices)\n",
        "\n",
        "# Create the dataset with the remaining samples and their embeddings\n",
        "remaining_data = x_train[remaining_indices]\n",
        "remaining_labels = Data[\"sentiment\"][remaining_indices]\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have 'selected_data' and 'selected_labels' arrays\n",
        "# 'selected_data' should be of shape (num_samples, 768) and 'selected_labels' of shape (num_samples, 1)\n",
        "\n",
        "# Split the selected data into training and testing sets\n",
        "test_size = 0.2  # Proportion of data to use as the test set\n",
        "random_state = 42  # Set a random seed for reproducibility\n",
        "\n",
        "# Perform the split\n",
        "X_train_ara, X_test_ara, y_train_ara, y_test_Ara = train_test_split(\n",
        "    selected_data, selected_labels, test_size=test_size, random_state=random_state\n",
        ")\n",
        "\n",
        "# Now you have the training and testing sets:\n",
        "# X_train_ara: Feature embeddings for the training set\n",
        "# y_train_ara: Corresponding labels for the training set\n",
        "# X_test_ara: Feature embeddings for the testing set\n",
        "# y_test_Ara: Corresponding labels for the testing set"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:06:43.711394Z",
          "iopub.execute_input": "2023-07-29T16:06:43.711805Z",
          "iopub.status.idle": "2023-07-29T16:06:43.812090Z",
          "shell.execute_reply.started": "2023-07-29T16:06:43.711774Z",
          "shell.execute_reply": "2023-07-29T16:06:43.811063Z"
        },
        "trusted": true,
        "id": "srJxdNJ97jdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_data\n",
        "remaining_labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:40:53.087071Z",
          "iopub.execute_input": "2023-07-29T12:40:53.088076Z",
          "iopub.status.idle": "2023-07-29T12:40:53.094547Z",
          "shell.execute_reply.started": "2023-07-29T12:40:53.088038Z",
          "shell.execute_reply": "2023-07-29T12:40:53.093565Z"
        },
        "trusted": true,
        "id": "BU9wibrG7jdV",
        "outputId": "da9dab47-bcad-4185-dfef-278e0831348e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 70,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(6448, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming you have already defined shuffled_indices, selected_data, and selected_labels\n",
        "\n",
        "# Get the indices of the entire x_train array\n",
        "all_indices = np.arange(len(x_train))\n",
        "\n",
        "# Find the indices that were not selected by inverting shuffled_indices using the ~ operator\n",
        "remaining_indices = np.setdiff1d(all_indices, shuffled_indices, assume_unique=True)\n",
        "\n",
        "# Now 'remaining_indices' contains the indices that were not selected\n",
        "# You can use these indices to get the corresponding data and labels\n",
        "remaining_data = x_train[remaining_indices]\n",
        "remaining_labels = Data[\"sentiment\"][remaining_indices]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:08:33.566416Z",
          "iopub.execute_input": "2023-07-29T16:08:33.566794Z",
          "iopub.status.idle": "2023-07-29T16:08:33.595003Z",
          "shell.execute_reply.started": "2023-07-29T16:08:33.566762Z",
          "shell.execute_reply": "2023-07-29T16:08:33.593934Z"
        },
        "trusted": true,
        "id": "dbKYhggA7jdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_indices"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:08:35.764385Z",
          "iopub.execute_input": "2023-07-29T16:08:35.764765Z",
          "iopub.status.idle": "2023-07-29T16:08:35.770967Z",
          "shell.execute_reply.started": "2023-07-29T16:08:35.764735Z",
          "shell.execute_reply": "2023-07-29T16:08:35.770087Z"
        },
        "trusted": true,
        "id": "DlAmo9tG7jdV",
        "outputId": "163910df-5c89-4911-bc07-76fec6452e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 328,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([4765, 5992, 4315, ..., 5108, 2139, 4252])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_indices = np.setdiff1d(np.arange(len(x_train)),shuffled_indices)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:08:40.643972Z",
          "iopub.execute_input": "2023-07-29T16:08:40.645833Z",
          "iopub.status.idle": "2023-07-29T16:08:40.652280Z",
          "shell.execute_reply.started": "2023-07-29T16:08:40.645776Z",
          "shell.execute_reply": "2023-07-29T16:08:40.651077Z"
        },
        "trusted": true,
        "id": "8HrXOnA-7jdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_indices"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:08:41.147847Z",
          "iopub.execute_input": "2023-07-29T16:08:41.148226Z",
          "iopub.status.idle": "2023-07-29T16:08:41.155445Z",
          "shell.execute_reply.started": "2023-07-29T16:08:41.148183Z",
          "shell.execute_reply": "2023-07-29T16:08:41.154284Z"
        },
        "trusted": true,
        "id": "Hvkq_ZoA7jdW",
        "outputId": "8ed0182f-6f1f-4079-d02e-0d708b026fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 331,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([10000, 10001, 10002, ..., 16445, 16446, 16447])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:08:43.242645Z",
          "iopub.execute_input": "2023-07-29T16:08:43.243574Z",
          "iopub.status.idle": "2023-07-29T16:08:43.250274Z",
          "shell.execute_reply.started": "2023-07-29T16:08:43.243525Z",
          "shell.execute_reply": "2023-07-29T16:08:43.249292Z"
        },
        "trusted": true,
        "id": "2aFea_gf7jdW",
        "outputId": "4229d91f-d25c-433a-b40a-f2590285b94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 332,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(6448, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert the nested list to a NumPy array (with inner lists converted to arrays)\n",
        "nested_array = np.array([np.array(sublist) for sublist in document_embeddings])\n",
        "\n",
        "\n",
        "print(\"Shape of the NumPy array:\", nested_array.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T17:55:27.685748Z",
          "iopub.execute_input": "2023-07-28T17:55:27.686255Z",
          "iopub.status.idle": "2023-07-28T17:55:27.727646Z",
          "shell.execute_reply.started": "2023-07-28T17:55:27.686215Z",
          "shell.execute_reply": "2023-07-28T17:55:27.726199Z"
        },
        "trusted": true,
        "id": "0BN8RvYr7jdW",
        "outputId": "e7c69ce9-a8f1-4ce3-92e6-0d0aaa368bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Shape of the NumPy array: (16448,)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_32/248390408.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  nested_array = np.array([np.array(sublist) for sublist in document_embeddings])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T17:55:15.593355Z",
          "iopub.execute_input": "2023-07-28T17:55:15.593793Z",
          "iopub.status.idle": "2023-07-28T17:55:15.603081Z",
          "shell.execute_reply.started": "2023-07-28T17:55:15.593758Z",
          "shell.execute_reply": "2023-07-28T17:55:15.601474Z"
        },
        "trusted": true,
        "id": "qqCRGLJM7jdX",
        "outputId": "ab1771b5-37f4-4aca-a306-715f15e5f01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 379,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(16448, 4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_classifier = LogisticRegression(max_iter=1000, solver='saga',C=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T19:42:07.583162Z",
          "iopub.execute_input": "2023-07-28T19:42:07.583678Z",
          "iopub.status.idle": "2023-07-28T19:42:07.590342Z",
          "shell.execute_reply.started": "2023-07-28T19:42:07.583608Z",
          "shell.execute_reply": "2023-07-28T19:42:07.588656Z"
        },
        "trusted": true,
        "id": "4rmixVX57jdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_y_train.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T19:41:43.551964Z",
          "iopub.execute_input": "2023-07-28T19:41:43.552424Z",
          "iopub.status.idle": "2023-07-28T19:41:43.561345Z",
          "shell.execute_reply.started": "2023-07-28T19:41:43.552387Z",
          "shell.execute_reply": "2023-07-28T19:41:43.559743Z"
        },
        "trusted": true,
        "id": "arTeekFO7jdY",
        "outputId": "bfdd4fab-129b-46b9-ee8c-d244bbb21b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 430,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(8000,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logistic_classifier.fit(global_X_train_counts, global_y_train)\n",
        "logistic_probs = logistic_classifier.predict_proba(global_remaning_counts)\n",
        "\n",
        "\n",
        "plt.hist(logistic_probs, bins=20, edgecolor='black')  # You can adjust the number of bins as needed\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Count')\n",
        "plt.title('log Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T19:42:10.158929Z",
          "iopub.execute_input": "2023-07-28T19:42:10.159404Z",
          "iopub.status.idle": "2023-07-28T19:42:20.766639Z",
          "shell.execute_reply.started": "2023-07-28T19:42:10.159366Z",
          "shell.execute_reply": "2023-07-28T19:42:20.765125Z"
        },
        "trusted": true,
        "id": "ThFg30JW7jdY",
        "outputId": "5c0c73e0-3b34-4c01-b07d-2bc51559ee43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step1 : **Baseline Model** *classify by three model by given labels*"
      ],
      "metadata": {
        "id": "A0Db_LMRoIl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_x_used=X_train_ara\n",
        "train_y_used=y_train_ara\n",
        "test_x_used=X_test_ara\n",
        "test_y_used=y_test_Ara\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T13:27:58.445408Z",
          "iopub.execute_input": "2023-07-29T13:27:58.445767Z",
          "iopub.status.idle": "2023-07-29T13:27:58.451462Z",
          "shell.execute_reply.started": "2023-07-29T13:27:58.445741Z",
          "shell.execute_reply": "2023-07-29T13:27:58.449978Z"
        },
        "trusted": true,
        "id": "LuHzhsjV7jdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_embedded\n",
        "Data[\"sentiment\"]"
      ],
      "metadata": {
        "id": "sfUM4k4J7jdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_global,X_test_global,y_train_global,y_test_global = train_test_split(x_train_embedded, Data[\"sentiment\"],test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:39:11.055886Z",
          "iopub.execute_input": "2023-07-29T15:39:11.056385Z",
          "iopub.status.idle": "2023-07-29T15:39:11.104361Z",
          "shell.execute_reply.started": "2023-07-29T15:39:11.056348Z",
          "shell.execute_reply": "2023-07-29T15:39:11.103248Z"
        },
        "trusted": true,
        "id": "gRpaLtx07jdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define SVM  and Logistic Regression classifiers\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eQH9dLYd7jdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trained on the data after being labled\n",
        "svm_classifier_before = SVC(kernel='rbf', C=1, probability=True)\n",
        "logistic_classifier_before = LogisticRegression(max_iter=1000, solver='saga', C=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:39:05.961466Z",
          "iopub.execute_input": "2023-07-29T15:39:05.962513Z",
          "iopub.status.idle": "2023-07-29T15:39:05.968371Z",
          "shell.execute_reply.started": "2023-07-29T15:39:05.962474Z",
          "shell.execute_reply": "2023-07-29T15:39:05.967364Z"
        },
        "trusted": true,
        "id": "LIIm53oO7jdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train and evalute the models"
      ],
      "metadata": {
        "id": "duddm8k_OV-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train each classifier on its respective dataset\n",
        "svm_classifier_before.fit(X_train_global,y_train_global)\n",
        "logistic_classifier_before.fit(X_train_global, y_train_global)\n",
        "\n",
        "# Make predictions for each classifier\n",
        "y_pred_svm = svm_classifier_before.predict(X_test_global)\n",
        "y_pred_logistic = logistic_classifier_before.predict(X_test_global)\n",
        "\n",
        "print(\"SVM\",classification_report(y_test_global, y_pred_svm))\n",
        "print(\"logistic_classifier \",classification_report(y_test_global, y_pred_logistic))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:39:14.645888Z",
          "iopub.execute_input": "2023-07-29T15:39:14.646280Z",
          "iopub.status.idle": "2023-07-29T15:45:17.005711Z",
          "shell.execute_reply.started": "2023-07-29T15:39:14.646241Z",
          "shell.execute_reply": "2023-07-29T15:45:17.004703Z"
        },
        "trusted": true,
        "id": "98uTEGMT7jdZ",
        "outputId": "a70618f7-e632-4760-f678-4cfe1a48fcfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "SVM               precision    recall  f1-score   support\n\n           0       0.86      0.86      0.86      1692\n           1       0.85      0.85      0.85      1598\n\n    accuracy                           0.86      3290\n   macro avg       0.86      0.86      0.86      3290\nweighted avg       0.86      0.86      0.86      3290\n\nlogistic_classifier                precision    recall  f1-score   support\n\n           0       0.86      0.85      0.86      1692\n           1       0.85      0.85      0.85      1598\n\n    accuracy                           0.85      3290\n   macro avg       0.85      0.85      0.85      3290\nweighted avg       0.85      0.85      0.85      3290\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define GRU classifier\n",
        "\n",
        "*   Used high droup out  to avoid overfitting in model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nuGEtzCgNu7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_gru_global = X_train_global.reshape(X_train_global.shape[0], 1, X_train_global.shape[1]) # reshape input to allow for GRU\n",
        "\n",
        "# Create the GRU model\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "\n",
        "gru_classifier = Sequential()\n",
        "gru_classifier.add(GRU(256, input_shape=(X_train_gru_global.shape[1], X_train_gru_global.shape[2]), return_sequences=True))\n",
        "gru_classifier.add(Dropout(0.2))\n",
        "\n",
        "gru_classifier.add(GRU(128, return_sequences=True))\n",
        "gru_classifier.add(Dropout(0.2))\n",
        "\n",
        "gru_classifier.add(GRU(64))\n",
        "gru_classifier.add(Dropout(0.2))\n",
        "\n",
        "gru_classifier.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "gru_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:46:27.453139Z",
          "iopub.execute_input": "2023-07-29T15:46:27.454235Z",
          "iopub.status.idle": "2023-07-29T15:46:28.208319Z",
          "shell.execute_reply.started": "2023-07-29T15:46:27.454172Z",
          "shell.execute_reply": "2023-07-29T15:46:28.207277Z"
        },
        "trusted": true,
        "id": "f1rNGFh97jda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train and evalute Gru"
      ],
      "metadata": {
        "id": "w38ieTl4Ojmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_classifier.fit(X_train_gru_global, y_train_global, epochs=5,batch_size=128)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:46:31.456620Z",
          "iopub.execute_input": "2023-07-29T15:46:31.456992Z",
          "iopub.status.idle": "2023-07-29T15:46:41.271383Z",
          "shell.execute_reply.started": "2023-07-29T15:46:31.456960Z",
          "shell.execute_reply": "2023-07-29T15:46:41.270414Z"
        },
        "trusted": true,
        "id": "GLFVkz3u7jda",
        "outputId": "ca096ead-9ae2-4539-81df-e21397e66450"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n103/103 [==============================] - 7s 11ms/step - loss: 0.4154 - accuracy: 0.8108\nEpoch 2/5\n103/103 [==============================] - 1s 8ms/step - loss: 0.3270 - accuracy: 0.8601\nEpoch 3/5\n103/103 [==============================] - 1s 7ms/step - loss: 0.3086 - accuracy: 0.8697\nEpoch 4/5\n103/103 [==============================] - 1s 7ms/step - loss: 0.2964 - accuracy: 0.8765\nEpoch 5/5\n103/103 [==============================] - 1s 7ms/step - loss: 0.2792 - accuracy: 0.8830\n",
          "output_type": "stream"
        },
        {
          "execution_count": 298,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x79cb13ad1a80>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_gru_global = X_test_global.reshape(X_test_global.shape[0], 1, X_test_global.shape[1])\n",
        "\n",
        "y_pred_gru = gru_classifier.predict(X_test_gru_global)\n",
        "\n",
        "y_pred_binary = (y_pred_gru > 0.5).astype(int)\n",
        "\n",
        "print(\"GRU\",classification_report(y_test_global, y_pred_binary))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:47:29.509383Z",
          "iopub.execute_input": "2023-07-29T15:47:29.509782Z",
          "iopub.status.idle": "2023-07-29T15:47:29.943974Z",
          "shell.execute_reply.started": "2023-07-29T15:47:29.509748Z",
          "shell.execute_reply": "2023-07-29T15:47:29.942777Z"
        },
        "trusted": true,
        "id": "O7NtsWa77jda",
        "outputId": "fc04ae74-6071-4827-b5f0-9ad826d016f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "103/103 [==============================] - 0s 3ms/step\nGRU               precision    recall  f1-score   support\n\n           0       0.87      0.88      0.88      1692\n           1       0.87      0.86      0.87      1598\n\n    accuracy                           0.87      3290\n   macro avg       0.87      0.87      0.87      3290\nweighted avg       0.87      0.87      0.87      3290\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trained and test on the 10000 labled data only"
      ],
      "metadata": {
        "id": "LLtzQqQ77jdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_classifier = SVC(kernel='rbf', C=1, probability=True)\n",
        "logistic_classifier = LogisticRegression(C=0.1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:16:28.655380Z",
          "iopub.execute_input": "2023-07-29T12:16:28.655748Z",
          "iopub.status.idle": "2023-07-29T12:16:28.661246Z",
          "shell.execute_reply.started": "2023-07-29T12:16:28.655721Z",
          "shell.execute_reply": "2023-07-29T12:16:28.660116Z"
        },
        "trusted": true,
        "id": "q9rPIZY57jdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train each classifier on its respective dataset\n",
        "svm_classifier.fit(train_x_used, train_y_used)\n",
        "logistic_classifier.fit(train_x_used, train_y_used)\n",
        "\n",
        "# Make predictions for each classifier\n",
        "y_pred_svm = svm_classifier.predict(test_x_used)\n",
        "y_pred_logistic = logistic_classifier.predict(test_x_used)\n",
        "print(\"SVM\",classification_report(test_y_used, y_pred_svm))\n",
        "print(\"logistic_classifier \",classification_report(test_y_used, y_pred_logistic))"
      ],
      "metadata": {
        "id": "iH8AbqNwoY4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47197957-72ce-410f-c9c1-a1032cff0b2c",
        "execution": {
          "iopub.status.busy": "2023-07-29T12:16:28.859975Z",
          "iopub.execute_input": "2023-07-29T12:16:28.860327Z",
          "iopub.status.idle": "2023-07-29T12:17:55.104861Z",
          "shell.execute_reply.started": "2023-07-29T12:16:28.860299Z",
          "shell.execute_reply": "2023-07-29T12:17:55.103849Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "SVM               precision    recall  f1-score   support\n\n           0       0.86      0.85      0.85      1025\n           1       0.85      0.85      0.85       975\n\n    accuracy                           0.85      2000\n   macro avg       0.85      0.85      0.85      2000\nweighted avg       0.85      0.85      0.85      2000\n\nlogistic_classifier                precision    recall  f1-score   support\n\n           0       0.86      0.86      0.86      1025\n           1       0.85      0.85      0.85       975\n\n    accuracy                           0.85      2000\n   macro avg       0.85      0.85      0.85      2000\nweighted avg       0.86      0.85      0.86      2000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_gru = train_x_used.reshape(train_x_used.shape[0], 1, train_x_used.shape[1])\n",
        "\n",
        "# Create the GRU model\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "\n",
        "gru_classifier = Sequential()\n",
        "gru_classifier.add(GRU(256, input_shape=(X_train_gru.shape[1], X_train_gru.shape[2]), return_sequences=True))\n",
        "gru_classifier.add(Dropout(0.2))\n",
        "\n",
        "gru_classifier.add(GRU(128, return_sequences=True))\n",
        "gru_classifier.add(Dropout(0.2))\n",
        "\n",
        "gru_classifier.add(GRU(64))\n",
        "gru_classifier.add(Dropout(0.2))\n",
        "\n",
        "gru_classifier.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "gru_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "_szKKQnNIIA-",
        "execution": {
          "iopub.status.busy": "2023-07-29T12:21:09.869272Z",
          "iopub.execute_input": "2023-07-29T12:21:09.869895Z",
          "iopub.status.idle": "2023-07-29T12:21:10.867609Z",
          "shell.execute_reply.started": "2023-07-29T12:21:09.869865Z",
          "shell.execute_reply": "2023-07-29T12:21:10.866649Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_classifier.fit(X_train_gru, train_y_used, epochs=10,batch_size=128)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:22:36.792010Z",
          "iopub.execute_input": "2023-07-29T12:22:36.792576Z",
          "iopub.status.idle": "2023-07-29T12:22:41.764340Z",
          "shell.execute_reply.started": "2023-07-29T12:22:36.792535Z",
          "shell.execute_reply": "2023-07-29T12:22:41.763169Z"
        },
        "trusted": true,
        "id": "XD8H6yZD7jdc",
        "outputId": "6882c89a-07fc-4e3c-df79-4c5fd07ebbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n63/63 [==============================] - 1s 10ms/step - loss: 0.0977 - accuracy: 0.9620\nEpoch 2/10\n63/63 [==============================] - 1s 11ms/step - loss: 0.0924 - accuracy: 0.9641\nEpoch 3/10\n63/63 [==============================] - 0s 8ms/step - loss: 0.0769 - accuracy: 0.9710\nEpoch 4/10\n63/63 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9644\nEpoch 5/10\n63/63 [==============================] - 0s 7ms/step - loss: 0.0638 - accuracy: 0.9766\nEpoch 6/10\n63/63 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9726\nEpoch 7/10\n63/63 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9721\nEpoch 8/10\n63/63 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9790\nEpoch 9/10\n63/63 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9803\nEpoch 10/10\n63/63 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9800\n",
          "output_type": "stream"
        },
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x79ca90eee770>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_gru = test_x_used.reshape(test_x_used.shape[0], 1, test_x_used.shape[1])\n",
        "\n",
        "y_pred_gru = gru_classifier.predict(X_test_gru)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y0rmsjxPepw",
        "outputId": "65f9cfe7-f50d-4bcd-9b9b-3d84f6f28b5b",
        "execution": {
          "iopub.status.busy": "2023-07-29T12:22:41.766347Z",
          "iopub.execute_input": "2023-07-29T12:22:41.766695Z",
          "iopub.status.idle": "2023-07-29T12:22:42.127211Z",
          "shell.execute_reply.started": "2023-07-29T12:22:41.766661Z",
          "shell.execute_reply": "2023-07-29T12:22:42.126270Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "63/63 [==============================] - 0s 3ms/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_binary = (y_pred_gru > 0.5).astype(int)\n",
        "print(\"GRU\",classification_report(test_y_used, y_pred_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNBNR3kFQK-p",
        "outputId": "d6b33014-db2d-444a-9290-4d7deaf0f902",
        "execution": {
          "iopub.status.busy": "2023-07-29T12:22:42.128780Z",
          "iopub.execute_input": "2023-07-29T12:22:42.129112Z",
          "iopub.status.idle": "2023-07-29T12:22:42.146829Z",
          "shell.execute_reply.started": "2023-07-29T12:22:42.129079Z",
          "shell.execute_reply": "2023-07-29T12:22:42.145907Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "GRU               precision    recall  f1-score   support\n\n           0       0.89      0.81      0.85      1025\n           1       0.82      0.90      0.86       975\n\n    accuracy                           0.85      2000\n   macro avg       0.86      0.85      0.85      2000\nweighted avg       0.86      0.85      0.85      2000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_2dZrfEtqEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Cnn,lstm,gru)"
      ],
      "metadata": {
        "id": "o5Rjus5ZtqPg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yuZtlI5utxJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the SVM ,  logistic models\n",
        "\n",
        "X_train_gru = train_x_used_semi.toarray().reshape(train_x_used_semi.shape[0], 1, train_x_used_semi.shape[1])\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "\n",
        "gru_classifier_semi = Sequential()\n",
        "gru_classifier_semi.add(GRU(256, input_shape=(X_train_gru.shape[1], X_train_gru.shape[2]), return_sequences=True))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(GRU(128, return_sequences=True))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(GRU(64))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "gru_classifier_semi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-01T19:54:50.314444Z",
          "iopub.execute_input": "2023-08-01T19:54:50.314833Z",
          "iopub.status.idle": "2023-08-01T19:54:51.090402Z",
          "shell.execute_reply.started": "2023-08-01T19:54:50.314800Z",
          "shell.execute_reply": "2023-08-01T19:54:51.089275Z"
        },
        "trusted": true,
        "id": "KOV5fv-BtW9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "X_train_lstm = train_x_used_semi.toarray().reshape(train_x_used_semi.shape[0], 1, train_x_used_semi.shape[1])\n",
        "lstm_classifier_semi = Sequential()\n",
        "lstm_classifier_semi.add(LSTM(256, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=True))\n",
        "lstm_classifier_semi.add(Dropout(0.2))\n",
        "lstm_classifier_semi.add(LSTM(128, return_sequences=True))\n",
        "lstm_classifier_semi.add(Dropout(0.2))\n",
        "lstm_classifier_semi.add(LSTM(64))\n",
        "lstm_classifier_semi.add(Dropout(0.2))\n",
        "lstm_classifier_semi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "lstm_classifier_semi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "pqA0ImTBtynD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Assuming `sequence_length` is the length of the sequence (e.g., 15320)\n",
        "sequence_length = 768\n",
        "\n",
        "# Create the CNN model\n",
        "cnn_classifier_semi = Sequential()\n",
        "cnn_classifier_semi.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(sequence_length, 1)))\n",
        "cnn_classifier_semi.add(MaxPooling1D(pool_size=2))\n",
        "cnn_classifier_semi.add(Flatten())\n",
        "cnn_classifier_semi.add(Dense(128, activation='relu'))\n",
        "cnn_classifier_semi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_classifier_semi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "WKTF2fVBt7yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_used_semi=csr_matrix(X_train_ara)\n",
        "train_y_used_semi=y_train_ara\n",
        "test_x_used_semi=csr_matrix(X_test_ara)\n",
        "test_y_used_semi=y_test_Ara\n",
        "reamining_data_used=csr_matrix(remaining_data)\n"
      ],
      "metadata": {
        "id": "O9rshg_Yt8Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_X_train, final_X_test, final_y_train, final_y_test = train_test_split(train_x_used_semi, train_y_used_semi,test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "pu_-75eXt-II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_gru = final_X_train.toarray().reshape(final_X_train.shape[0], 1, final_X_train.shape[1])\n",
        "print('lstm')\n",
        "lstm_classifier_semi.fit(X_train_gru, final_y_train,epochs=15, batch_size=32)\n",
        "print('CNN')\n",
        "X_train_cnn = final_X_train.toarray().reshape(final_X_train.shape[0], sequence_length, 1)\n",
        "cnn_classifier_semi.fit(X_train_cnn, final_y_train,epochs=15, batch_size=32)\n",
        "print('gru')\n",
        "\n",
        "gru_classifier_semi.fit(X_train_gru, final_y_train, epochs=15, batch_size=64)  # Adjust epochs and batch size as needed"
      ],
      "metadata": {
        "id": "ejKrb1DIuCVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semi_remaning_counts_gru = final_X_test.toarray().reshape(final_X_test.shape[0], 1, final_X_test.shape[1])\n",
        "semi_remaning_counts_cnn = final_X_test.toarray().reshape(final_X_test.shape[0], sequence_length, 1)\n",
        "\n",
        "\n",
        "\n",
        "lstm_predictions = lstm_classifier_semi.predict(semi_remaning_counts_gru)\n",
        "cnn_predictions = cnn_classifier_semi.predict(semi_remaning_counts_cnn)\n",
        "gru_predictions = gru_classifier_semi.predict(semi_remaning_counts_gru)\n",
        "\n"
      ],
      "metadata": {
        "id": "7aDkNibTuC1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_binary = (lstm_predictions > 0.5).astype(int)\n",
        "print(\"lstm \",classification_report(final_y_test, y_pred_binary))\n",
        "y_pred_binary = (cnn_predictions > 0.5).astype(int)\n",
        "print(\"cnn \",classification_report(final_y_test, y_pred_binary))\n",
        "y_pred_binary = (gru_predictions > 0.5).astype(int)\n",
        "print(\"gru \",classification_report(final_y_test, y_pred_binary))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-01T20:02:01.683118Z",
          "iopub.execute_input": "2023-08-01T20:02:01.683529Z",
          "iopub.status.idle": "2023-08-01T20:02:01.722986Z",
          "shell.execute_reply.started": "2023-08-01T20:02:01.683499Z",
          "shell.execute_reply": "2023-08-01T20:02:01.721956Z"
        },
        "trusted": true,
        "id": "RTg-9JuatW9Z",
        "outputId": "a1216328-cd69-4cd7-bfff-7777fab3ab6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "lstm                precision    recall  f1-score   support\n\n           0       0.91      0.79      0.85       799\n           1       0.82      0.92      0.87       801\n\n    accuracy                           0.86      1600\n   macro avg       0.86      0.86      0.86      1600\nweighted avg       0.86      0.86      0.86      1600\n\ncnn                precision    recall  f1-score   support\n\n           0       0.90      0.76      0.83       799\n           1       0.80      0.92      0.85       801\n\n    accuracy                           0.84      1600\n   macro avg       0.85      0.84      0.84      1600\nweighted avg       0.85      0.84      0.84      1600\n\ngru                precision    recall  f1-score   support\n\n           0       0.87      0.84      0.86       799\n           1       0.85      0.88      0.86       801\n\n    accuracy                           0.86      1600\n   macro avg       0.86      0.86      0.86      1600\nweighted avg       0.86      0.86      0.86      1600\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 :**semi supervise learning**\n",
        "\n",
        "*    create new labels\n",
        "\n"
      ],
      "metadata": {
        "id": "yH8tFZoYowY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm  # For the progress bar\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:43:52.468781Z",
          "iopub.execute_input": "2023-07-29T12:43:52.469154Z",
          "iopub.status.idle": "2023-07-29T12:43:52.474009Z",
          "shell.execute_reply.started": "2023-07-29T12:43:52.469126Z",
          "shell.execute_reply": "2023-07-29T12:43:52.472726Z"
        },
        "trusted": true,
        "id": "HS-U88PI7jdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_x_used_semi=csr_matrix(X_train_ara)\n",
        "train_y_used_semi=y_train_ara\n",
        "test_x_used_semi=csr_matrix(X_test_ara)\n",
        "test_y_used_semi=y_test_Ara\n",
        "reamining_data_used=csr_matrix(remaining_data)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T14:15:49.730942Z",
          "iopub.execute_input": "2023-07-29T14:15:49.731336Z",
          "iopub.status.idle": "2023-07-29T14:15:50.163913Z",
          "shell.execute_reply.started": "2023-07-29T14:15:49.731306Z",
          "shell.execute_reply": "2023-07-29T14:15:50.162857Z"
        },
        "trusted": true,
        "id": "8aZGnt5Z7jdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the SVM ,  logistic ,gru models\n",
        "\n",
        "svm_classifier_semi = SVC(max_iter=2,kernel='rbf', C=1, probability=True)\n",
        "logistic_classifier_semi = LogisticRegression(max_iter=2, solver='saga', C=1)\n",
        "\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "\n",
        "gru_classifier_semi = Sequential()\n",
        "gru_classifier_semi.add(GRU(256, input_shape=(X_train_gru.shape[1], X_train_gru.shape[2]), return_sequences=True))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(GRU(128, return_sequences=True))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(GRU(64))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "gru_classifier_semi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T14:15:53.671820Z",
          "iopub.execute_input": "2023-07-29T14:15:53.672559Z",
          "iopub.status.idle": "2023-07-29T14:15:54.349384Z",
          "shell.execute_reply.started": "2023-07-29T14:15:53.672521Z",
          "shell.execute_reply": "2023-07-29T14:15:54.348358Z"
        },
        "trusted": true,
        "id": "TqVWmI_o7jdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_threshold = 0.9"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T13:35:26.963143Z",
          "iopub.execute_input": "2023-07-29T13:35:26.963788Z",
          "iopub.status.idle": "2023-07-29T13:35:26.968170Z",
          "shell.execute_reply.started": "2023-07-29T13:35:26.963739Z",
          "shell.execute_reply": "2023-07-29T13:35:26.967258Z"
        },
        "trusted": true,
        "id": "KymNe8Ge7jdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import vstack,csr_matrix\n",
        "## allow store new labels and remove from unlabel data\n",
        "def compare_arrays(array1, array2, array3,threshold,unlabled_data,labeled_x,labeled_y):\n",
        "    assert array1.shape == array2.shape == array3.shape, \"Arrays must have the same shape.\"\n",
        "\n",
        "    indexes_to_delete = []\n",
        "\n",
        "    for index, (elem1, elem2, elem3) in enumerate(zip(array1, array2, array3)):\n",
        "        if elem1 > threshold and elem2 > threshold and elem3 > threshold:\n",
        "            #\n",
        "            #store the indexes of the elements that we will remove from the unlabeled\n",
        "            indexes_to_delete.append(index)\n",
        "            #append the elment the meet our threshhold to the traninf data ,using vstack because its a sparce matrix\n",
        "            labeled_x = vstack([labeled_x, csr_matrix(unlabled_data[index])], format='csr')\n",
        "            #append the predection to the traning data\n",
        "            labeled_y = np.concatenate([labeled_y, np.array([1])])\n",
        "\n",
        "        elif elem1 < (1-threshold) and elem2 < (1-threshold) and elem3 < (1-threshold):\n",
        "\n",
        "            indexes_to_delete.append(index)\n",
        "            labeled_x = vstack([labeled_x, csr_matrix(unlabled_data[index])], format='csr')\n",
        "            labeled_y = np.concatenate([labeled_y, np.array([0])])\n",
        "        # you can add more conditions here.\n",
        "\n",
        "\n",
        "    print(\"############\")\n",
        "    print(f\"  unlabeled shape before deletion {unlabled_data.shape}\")\n",
        "    print(f\"  indexes_to_delete shape before deletion {len(indexes_to_delete)}\")\n",
        "    print(f\"  unlabeled shape before deletion {unlabled_data.shape}\")\n",
        "    # Drop elements from the main_array using the stored indexes\n",
        "    if indexes_to_delete is not None and unlabled_data is not None:\n",
        "\n",
        "        unlabled_data = np.delete(unlabled_data,indexes_to_delete,axis=0)\n",
        "\n",
        "\n",
        "    print(type(unlabled_data))\n",
        "\n",
        "    print(\"############\")\n",
        "    unlabled_data = np.squeeze(unlabled_data)\n",
        "    print(f\"  unlabeled shape after deletion {csr_matrix(unlabled_data).shape}\")\n",
        "    return csr_matrix(unlabled_data),labeled_x,labeled_y"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T13:51:33.092710Z",
          "iopub.execute_input": "2023-07-29T13:51:33.093074Z",
          "iopub.status.idle": "2023-07-29T13:51:33.105032Z",
          "shell.execute_reply.started": "2023-07-29T13:51:33.093045Z",
          "shell.execute_reply": "2023-07-29T13:51:33.103836Z"
        },
        "trusted": true,
        "id": "G5DhQfz-7jde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_threshold = 0.9"
      ],
      "metadata": {
        "id": "Q9UPXOrk7jde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train semi supervised model"
      ],
      "metadata": {
        "id": "x0rdt6haRV_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "\n",
        "\n",
        "# Number of iterations for semi-supervised learning\n",
        "num_iterations = 50\n",
        "\n",
        "\n",
        "# Semi-supervised learning using iterative approach\n",
        "for _ in range(num_iterations):\n",
        "    print('step 1')\n",
        "    # Step 1: Train models on labeled data\n",
        "    print('train svm')\n",
        "    svm_classifier_semi.fit(train_x_used_semi, train_y_used_semi)\n",
        "    print('log')\n",
        "    logistic_classifier_semi.fit(train_x_used_semi, train_y_used_semi)\n",
        "    print('gru')\n",
        "    X_train_gru = train_x_used_semi.toarray().reshape(train_x_used_semi.shape[0], 1, train_x_used_semi.shape[1])\n",
        "\n",
        "    gru_classifier_semi.fit(X_train_gru, train_y_used_semi, epochs=1, batch_size=64)  # Adjust epochs and batch size as needed\n",
        "    print('step 2')\n",
        "\n",
        "    # Step 2: Make predictions on unlabeled data\n",
        "    svm_predictions = svm_classifier_semi.predict(reamining_data_used)\n",
        "    logistic_predictions = logistic_classifier_semi.predict(reamining_data_used)\n",
        "\n",
        "    global_remaning_counts_gru = reamining_data_used.toarray().reshape(reamining_data_used.shape[0], 1, reamining_data_used.shape[1])\n",
        "\n",
        "    gru_predictions = gru_classifier_semi.predict(global_remaning_counts_gru)\n",
        "\n",
        "    svm_predictions = np.squeeze(svm_predictions)\n",
        "    logistic_predictions = np.squeeze(logistic_predictions)\n",
        "    gru_predictions = np.squeeze(gru_predictions)\n",
        "    print('step 3')\n",
        "\n",
        "    svm_confidences = svm_classifier_semi.predict_proba(reamining_data_used)[:, 1]\n",
        "    logistic_confidences = logistic_classifier_semi.predict_proba(reamining_data_used)[:, 1]\n",
        "\n",
        "    reamining_data_used,train_x_used_semi,train_y_used_semi = compare_arrays(svm_confidences,\n",
        "                                                                                     logistic_confidences,\n",
        "                                                                                     gru_predictions,confidence_threshold,\n",
        "                                                                                     global_remaning_counts_gru,\n",
        "                                                                                     train_x_used_semi,train_y_used_semi)\n",
        "\n",
        "\n",
        "    print(f\"  labeled shape end of run deletion {train_x_used_semi.shape}\")\n",
        "    print(f\"  nmber of unlabled remaning{reamining_data_used.shape[0]}\")\n",
        "\n",
        "    print('repeat')\n",
        "    confidence_threshold=confidence_threshold-0.008\n",
        "    print(f\"confidence_threshold={confidence_threshold}\")\n",
        "\n",
        "    if global_remaning_counts.shape[0] == 0:\n",
        "        print(f\"All data labeled after iteration {iteration+1}. Stopping the loop.\")\n",
        "        break\n",
        "    # After an iteration, the unlabeled dataset is updated with agreed predictions removed.\n",
        "    # The process will be repeated until the stopping criteria is met.\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T14:35:05.433461Z",
          "iopub.execute_input": "2023-07-29T14:35:05.433845Z",
          "iopub.status.idle": "2023-07-29T14:39:35.696642Z",
          "shell.execute_reply.started": "2023-07-29T14:35:05.433814Z",
          "shell.execute_reply": "2023-07-29T14:39:35.695280Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "_hoyYaCh7jde",
        "outputId": "cdf9a370-7878-4d7d-e77b-177fd7cb6364"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "step 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n202/202 [==============================] - 2s 9ms/step - loss: 0.1383 - accuracy: 0.9475\nstep 2\n49/49 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1539, 1, 768)\n  indexes_to_delete shape before deletion 38\n  unlabeled shape before deletion (1539, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1501, 768)\n  labeled shape end of run deletion (12947, 768)\n  nmber of unlabled remaning1501\nrepeat\nconfidence_threshold=0.49199999999999966\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n203/203 [==============================] - 2s 8ms/step - loss: 0.1334 - accuracy: 0.9472\nstep 2\n47/47 [==============================] - 0s 2ms/step\nstep 3\n############\n  unlabeled shape before deletion (1501, 1, 768)\n  indexes_to_delete shape before deletion 15\n  unlabeled shape before deletion (1501, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1486, 768)\n  labeled shape end of run deletion (12962, 768)\n  nmber of unlabled remaning1486\nrepeat\nconfidence_threshold=0.48399999999999965\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n203/203 [==============================] - 2s 8ms/step - loss: 0.1314 - accuracy: 0.9488\nstep 2\n47/47 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1486, 1, 768)\n  indexes_to_delete shape before deletion 22\n  unlabeled shape before deletion (1486, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1464, 768)\n  labeled shape end of run deletion (12984, 768)\n  nmber of unlabled remaning1464\nrepeat\nconfidence_threshold=0.47599999999999965\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n203/203 [==============================] - 2s 8ms/step - loss: 0.1392 - accuracy: 0.9445\nstep 2\n46/46 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1464, 1, 768)\n  indexes_to_delete shape before deletion 61\n  unlabeled shape before deletion (1464, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1403, 768)\n  labeled shape end of run deletion (13045, 768)\n  nmber of unlabled remaning1403\nrepeat\nconfidence_threshold=0.46799999999999964\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n204/204 [==============================] - 2s 8ms/step - loss: 0.1314 - accuracy: 0.9477\nstep 2\n44/44 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1403, 1, 768)\n  indexes_to_delete shape before deletion 90\n  unlabeled shape before deletion (1403, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1313, 768)\n  labeled shape end of run deletion (13135, 768)\n  nmber of unlabled remaning1313\nrepeat\nconfidence_threshold=0.45999999999999963\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n206/206 [==============================] - 2s 11ms/step - loss: 0.1302 - accuracy: 0.9492\nstep 2\n42/42 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1313, 1, 768)\n  indexes_to_delete shape before deletion 564\n  unlabeled shape before deletion (1313, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (749, 768)\n  labeled shape end of run deletion (13699, 768)\n  nmber of unlabled remaning749\nrepeat\nconfidence_threshold=0.4519999999999996\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n215/215 [==============================] - 2s 8ms/step - loss: 0.1337 - accuracy: 0.9479\nstep 2\n24/24 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (749, 1, 768)\n  indexes_to_delete shape before deletion 418\n  unlabeled shape before deletion (749, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (331, 768)\n  labeled shape end of run deletion (14117, 768)\n  nmber of unlabled remaning331\nrepeat\nconfidence_threshold=0.4439999999999996\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n221/221 [==============================] - 2s 8ms/step - loss: 0.1318 - accuracy: 0.9498\nstep 2\n11/11 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (331, 1, 768)\n  indexes_to_delete shape before deletion 151\n  unlabeled shape before deletion (331, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (180, 768)\n  labeled shape end of run deletion (14268, 768)\n  nmber of unlabled remaning180\nrepeat\nconfidence_threshold=0.4359999999999996\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n223/223 [==============================] - 2s 9ms/step - loss: 0.1248 - accuracy: 0.9512\nstep 2\n6/6 [==============================] - 0s 6ms/step\nstep 3\n############\n  unlabeled shape before deletion (180, 1, 768)\n  indexes_to_delete shape before deletion 87\n  unlabeled shape before deletion (180, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (93, 768)\n  labeled shape end of run deletion (14355, 768)\n  nmber of unlabled remaning93\nrepeat\nconfidence_threshold=0.4279999999999996\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n225/225 [==============================] - 2s 8ms/step - loss: 0.1355 - accuracy: 0.9457\nstep 2\n3/3 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (93, 1, 768)\n  indexes_to_delete shape before deletion 24\n  unlabeled shape before deletion (93, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (69, 768)\n  labeled shape end of run deletion (14379, 768)\n  nmber of unlabled remaning69\nrepeat\nconfidence_threshold=0.4199999999999996\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n225/225 [==============================] - 2s 9ms/step - loss: 0.1350 - accuracy: 0.9479\nstep 2\n3/3 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (69, 1, 768)\n  indexes_to_delete shape before deletion 12\n  unlabeled shape before deletion (69, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (57, 768)\n  labeled shape end of run deletion (14391, 768)\n  nmber of unlabled remaning57\nrepeat\nconfidence_threshold=0.4119999999999996\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n225/225 [==============================] - 2s 8ms/step - loss: 0.1337 - accuracy: 0.9487\nstep 2\n2/2 [==============================] - 0s 5ms/step\nstep 3\n############\n  unlabeled shape before deletion (57, 1, 768)\n  indexes_to_delete shape before deletion 13\n  unlabeled shape before deletion (57, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (44, 768)\n  labeled shape end of run deletion (14404, 768)\n  nmber of unlabled remaning44\nrepeat\nconfidence_threshold=0.4039999999999996\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1294 - accuracy: 0.9487\nstep 2\n2/2 [==============================] - 0s 4ms/step\nstep 3\n############\n  unlabeled shape before deletion (44, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (44, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (44, 768)\n  labeled shape end of run deletion (14404, 768)\n  nmber of unlabled remaning44\nrepeat\nconfidence_threshold=0.3959999999999996\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1299 - accuracy: 0.9491\nstep 2\n2/2 [==============================] - 0s 6ms/step\nstep 3\n############\n  unlabeled shape before deletion (44, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (44, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (44, 768)\n  labeled shape end of run deletion (14404, 768)\n  nmber of unlabled remaning44\nrepeat\nconfidence_threshold=0.38799999999999957\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 3s 11ms/step - loss: 0.1308 - accuracy: 0.9490\nstep 2\n2/2 [==============================] - 0s 5ms/step\nstep 3\n############\n  unlabeled shape before deletion (44, 1, 768)\n  indexes_to_delete shape before deletion 5\n  unlabeled shape before deletion (44, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (39, 768)\n  labeled shape end of run deletion (14409, 768)\n  nmber of unlabled remaning39\nrepeat\nconfidence_threshold=0.37999999999999956\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1231 - accuracy: 0.9539\nstep 2\n2/2 [==============================] - 0s 5ms/step\nstep 3\n############\n  unlabeled shape before deletion (39, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (39, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (39, 768)\n  labeled shape end of run deletion (14409, 768)\n  nmber of unlabled remaning39\nrepeat\nconfidence_threshold=0.37199999999999955\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1197 - accuracy: 0.9533\nstep 2\n2/2 [==============================] - 0s 4ms/step\nstep 3\n############\n  unlabeled shape before deletion (39, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (39, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (39, 768)\n  labeled shape end of run deletion (14409, 768)\n  nmber of unlabled remaning39\nrepeat\nconfidence_threshold=0.36399999999999955\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1291 - accuracy: 0.9497\nstep 2\n2/2 [==============================] - 0s 5ms/step\nstep 3\n############\n  unlabeled shape before deletion (39, 1, 768)\n  indexes_to_delete shape before deletion 2\n  unlabeled shape before deletion (39, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (37, 768)\n  labeled shape end of run deletion (14411, 768)\n  nmber of unlabled remaning37\nrepeat\nconfidence_threshold=0.35599999999999954\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1183 - accuracy: 0.9541\nstep 2\n2/2 [==============================] - 0s 5ms/step\nstep 3\n############\n  unlabeled shape before deletion (37, 1, 768)\n  indexes_to_delete shape before deletion 4\n  unlabeled shape before deletion (37, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (33, 768)\n  labeled shape end of run deletion (14415, 768)\n  nmber of unlabled remaning33\nrepeat\nconfidence_threshold=0.34799999999999953\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1207 - accuracy: 0.9535\nstep 2\n2/2 [==============================] - 0s 4ms/step\nstep 3\n############\n  unlabeled shape before deletion (33, 1, 768)\n  indexes_to_delete shape before deletion 6\n  unlabeled shape before deletion (33, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (27, 768)\n  labeled shape end of run deletion (14421, 768)\n  nmber of unlabled remaning27\nrepeat\nconfidence_threshold=0.3399999999999995\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1184 - accuracy: 0.9535\nstep 2\n1/1 [==============================] - 0s 21ms/step\nstep 3\n############\n  unlabeled shape before deletion (27, 1, 768)\n  indexes_to_delete shape before deletion 4\n  unlabeled shape before deletion (27, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (23, 768)\n  labeled shape end of run deletion (14425, 768)\n  nmber of unlabled remaning23\nrepeat\nconfidence_threshold=0.3319999999999995\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 9ms/step - loss: 0.1221 - accuracy: 0.9530\nstep 2\n1/1 [==============================] - 0s 21ms/step\nstep 3\n############\n  unlabeled shape before deletion (23, 1, 768)\n  indexes_to_delete shape before deletion 2\n  unlabeled shape before deletion (23, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (21, 768)\n  labeled shape end of run deletion (14427, 768)\n  nmber of unlabled remaning21\nrepeat\nconfidence_threshold=0.3239999999999995\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1204 - accuracy: 0.9523\nstep 2\n1/1 [==============================] - 0s 20ms/step\nstep 3\n############\n  unlabeled shape before deletion (21, 1, 768)\n  indexes_to_delete shape before deletion 9\n  unlabeled shape before deletion (21, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (12, 768)\n  labeled shape end of run deletion (14436, 768)\n  nmber of unlabled remaning12\nrepeat\nconfidence_threshold=0.3159999999999995\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1166 - accuracy: 0.9556\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (12, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (12, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (12, 768)\n  labeled shape end of run deletion (14436, 768)\n  nmber of unlabled remaning12\nrepeat\nconfidence_threshold=0.3079999999999995\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1188 - accuracy: 0.9525\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (12, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (12, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (12, 768)\n  labeled shape end of run deletion (14436, 768)\n  nmber of unlabled remaning12\nrepeat\nconfidence_threshold=0.2999999999999995\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 9ms/step - loss: 0.1132 - accuracy: 0.9568\nstep 2\n1/1 [==============================] - 0s 22ms/step\nstep 3\n############\n  unlabeled shape before deletion (12, 1, 768)\n  indexes_to_delete shape before deletion 1\n  unlabeled shape before deletion (12, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (11, 768)\n  labeled shape end of run deletion (14437, 768)\n  nmber of unlabled remaning11\nrepeat\nconfidence_threshold=0.2919999999999995\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1095 - accuracy: 0.9560\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (11, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (11, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (11, 768)\n  labeled shape end of run deletion (14437, 768)\n  nmber of unlabled remaning11\nrepeat\nconfidence_threshold=0.2839999999999995\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1151 - accuracy: 0.9570\nstep 2\n1/1 [==============================] - 0s 21ms/step\nstep 3\n############\n  unlabeled shape before deletion (11, 1, 768)\n  indexes_to_delete shape before deletion 1\n  unlabeled shape before deletion (11, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (10, 768)\n  labeled shape end of run deletion (14438, 768)\n  nmber of unlabled remaning10\nrepeat\nconfidence_threshold=0.27599999999999947\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1161 - accuracy: 0.9529\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (10, 1, 768)\n  indexes_to_delete shape before deletion 2\n  unlabeled shape before deletion (10, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (8, 768)\n  labeled shape end of run deletion (14440, 768)\n  nmber of unlabled remaning8\nrepeat\nconfidence_threshold=0.26799999999999946\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1163 - accuracy: 0.9570\nstep 2\n1/1 [==============================] - 0s 18ms/step\nstep 3\n############\n  unlabeled shape before deletion (8, 1, 768)\n  indexes_to_delete shape before deletion 1\n  unlabeled shape before deletion (8, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (7, 768)\n  labeled shape end of run deletion (14441, 768)\n  nmber of unlabled remaning7\nrepeat\nconfidence_threshold=0.25999999999999945\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1122 - accuracy: 0.9572\nstep 2\n1/1 [==============================] - 0s 20ms/step\nstep 3\n############\n  unlabeled shape before deletion (7, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (7, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (7, 768)\n  labeled shape end of run deletion (14441, 768)\n  nmber of unlabled remaning7\nrepeat\nconfidence_threshold=0.25199999999999945\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1082 - accuracy: 0.9578\nstep 2\n1/1 [==============================] - 0s 21ms/step\nstep 3\n############\n  unlabeled shape before deletion (7, 1, 768)\n  indexes_to_delete shape before deletion 1\n  unlabeled shape before deletion (7, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (6, 768)\n  labeled shape end of run deletion (14442, 768)\n  nmber of unlabled remaning6\nrepeat\nconfidence_threshold=0.24399999999999944\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1066 - accuracy: 0.9581\nstep 2\n1/1 [==============================] - 0s 24ms/step\nstep 3\n############\n  unlabeled shape before deletion (6, 1, 768)\n  indexes_to_delete shape before deletion 1\n  unlabeled shape before deletion (6, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (5, 768)\n  labeled shape end of run deletion (14443, 768)\n  nmber of unlabled remaning5\nrepeat\nconfidence_threshold=0.23599999999999943\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1111 - accuracy: 0.9582\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (5, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (5, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (5, 768)\n  labeled shape end of run deletion (14443, 768)\n  nmber of unlabled remaning5\nrepeat\nconfidence_threshold=0.22799999999999943\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1090 - accuracy: 0.9583\nstep 2\n1/1 [==============================] - 0s 20ms/step\nstep 3\n############\n  unlabeled shape before deletion (5, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (5, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (5, 768)\n  labeled shape end of run deletion (14443, 768)\n  nmber of unlabled remaning5\nrepeat\nconfidence_threshold=0.21999999999999942\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1063 - accuracy: 0.9595\nstep 2\n1/1 [==============================] - 0s 20ms/step\nstep 3\n############\n  unlabeled shape before deletion (5, 1, 768)\n  indexes_to_delete shape before deletion 1\n  unlabeled shape before deletion (5, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (4, 768)\n  labeled shape end of run deletion (14444, 768)\n  nmber of unlabled remaning4\nrepeat\nconfidence_threshold=0.2119999999999994\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1023 - accuracy: 0.9598\nstep 2\n1/1 [==============================] - 0s 21ms/step\nstep 3\n############\n  unlabeled shape before deletion (4, 1, 768)\n  indexes_to_delete shape before deletion 2\n  unlabeled shape before deletion (4, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.2039999999999994\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 9ms/step - loss: 0.1123 - accuracy: 0.9554\nstep 2\n1/1 [==============================] - 0s 30ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.1959999999999994\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1087 - accuracy: 0.9580\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.1879999999999994\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1007 - accuracy: 0.9624\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.17999999999999938\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 9ms/step - loss: 0.1088 - accuracy: 0.9583\nstep 2\n1/1 [==============================] - 0s 18ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.17199999999999938\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1040 - accuracy: 0.9596\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.16399999999999937\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1054 - accuracy: 0.9612\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.15599999999999936\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1099 - accuracy: 0.9559\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.14799999999999935\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1055 - accuracy: 0.9603\nstep 2\n1/1 [==============================] - 0s 20ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.13999999999999935\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 10ms/step - loss: 0.0983 - accuracy: 0.9621\nstep 2\n1/1 [==============================] - 0s 18ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 0\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2, 768)\n  labeled shape end of run deletion (14446, 768)\n  nmber of unlabled remaning2\nrepeat\nconfidence_threshold=0.13199999999999934\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 8ms/step - loss: 0.1019 - accuracy: 0.9596\nstep 2\n1/1 [==============================] - 0s 19ms/step\nstep 3\n############\n  unlabeled shape before deletion (2, 1, 768)\n  indexes_to_delete shape before deletion 1\n  unlabeled shape before deletion (2, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1, 768)\n  labeled shape end of run deletion (14447, 768)\n  nmber of unlabled remaning1\nrepeat\nconfidence_threshold=0.12399999999999933\nstep 1\ntrain svm\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "log\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "gru\n226/226 [==============================] - 2s 9ms/step - loss: 0.1101 - accuracy: 0.9572\nstep 2\n1/1 [==============================] - 0s 20ms/step\nstep 3\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[269], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m svm_confidences \u001b[38;5;241m=\u001b[39m svm_classifier_semi\u001b[38;5;241m.\u001b[39mpredict_proba(reamining_data_used)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m logistic_confidences \u001b[38;5;241m=\u001b[39m logistic_classifier_semi\u001b[38;5;241m.\u001b[39mpredict_proba(reamining_data_used)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 42\u001b[0m reamining_data_used,train_x_used_semi,train_y_used_semi \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvm_confidences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mlogistic_confidences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mgru_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mglobal_remaning_counts_gru\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mtrain_x_used_semi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y_used_semi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  labeled shape end of run deletion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_x_used_semi\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  nmber of unlabled remaning\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreamining_data_used\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[254], line 4\u001b[0m, in \u001b[0;36mcompare_arrays\u001b[0;34m(array1, array2, array3, threshold, unlabled_data, labeled_x, labeled_y)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_arrays\u001b[39m(array1, array2, array3,threshold,unlabled_data,labeled_x,labeled_y):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m array1\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m array2\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m array3\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrays must have the same shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     indexes_to_delete \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, (elem1, elem2, elem3) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(array1, array2, array3)):\n",
            "\u001b[0;31mAssertionError\u001b[0m: Arrays must have the same shape."
          ],
          "ename": "AssertionError",
          "evalue": "Arrays must have the same shape.",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_used_semi.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T13:33:15.839344Z",
          "iopub.execute_input": "2023-07-29T13:33:15.839713Z",
          "iopub.status.idle": "2023-07-29T13:33:15.846257Z",
          "shell.execute_reply.started": "2023-07-29T13:33:15.839684Z",
          "shell.execute_reply": "2023-07-29T13:33:15.845244Z"
        },
        "trusted": true,
        "id": "uwhbjShi7jdf",
        "outputId": "2ced183b-2f60-4f70-980c-8af1e001c968"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 213,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(8001, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    global_remaning_counts_gru = global_remaning_counts.toarray().reshape(global_remaning_counts.shape[0], 1, global_remaning_counts.shape[1])\n",
        "    global_remaning_counts,global_X_train_counts,global_y_train = compare_arrays(svm_confidences,\n",
        "                                                                                     logistic_confidences,\n",
        "                                                                                     gru_predictions,confidence_threshold,\n",
        "                                                                                     global_remaning_counts_gru,\n",
        "                                                                                     global_X_train_counts,global_y_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:59:04.771315Z",
          "iopub.execute_input": "2023-07-29T12:59:04.771777Z",
          "iopub.status.idle": "2023-07-29T12:59:07.300915Z",
          "shell.execute_reply.started": "2023-07-29T12:59:04.771736Z",
          "shell.execute_reply": "2023-07-29T12:59:07.299829Z"
        },
        "trusted": true,
        "id": "NfskSbuz7jdf",
        "outputId": "d2741c4b-46f7-467a-e3b2-034c6a239ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "############\n  unlabeled shape before deletion (6448, 1, 768)\n  indexes_to_delete shape before deletion 77\n  unlabeled shape before deletion (6448, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (6371, 768)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get ensemle result by test data"
      ],
      "metadata": {
        "id": "7A7wk4D7Rulf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_x_used_semi\n",
        "svm_predictions = svm_classifier_semi.predict(test_x_used_semi)\n",
        "\n",
        "# Model 2: Logistic Regression Classifier (already trained)\n",
        "logistic_predictions = logistic_classifier_semi.predict(test_x_used_semi)\n",
        "\n",
        "# Model 3: GRU Classifier (already trained)\n",
        "X_test_gru = test_x_used_semi.toarray().reshape(test_x_used_semi.shape[0], 1, test_x_used_semi.shape[1])\n",
        "gru_predictions = gru_classifier_semi.predict(X_test_gru)\n",
        "gru_predictions = (gru_predictions > 0.5).astype(int)  # Thresholding the GRU predictions\n",
        "\n",
        "# Ensemble predictions using majority voting (simple averaging)\n",
        "ensemble_predictions = (svm_predictions + logistic_predictions + gru_predictions.T) / 3\n",
        "\n",
        "# Convert ensemble predictions to binary classes (0 or 1)\n",
        "ensemble_predictions = (ensemble_predictions > 0.5).astype(int)\n",
        "\n",
        "# Classification report for the ensemble predictions\n",
        "classification_rep = classification_report(test_y_used_semi, ensemble_predictions.T)\n",
        "print(\"Ensemble Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T14:41:37.213724Z",
          "iopub.execute_input": "2023-07-29T14:41:37.214136Z",
          "iopub.status.idle": "2023-07-29T14:41:37.553510Z",
          "shell.execute_reply.started": "2023-07-29T14:41:37.214106Z",
          "shell.execute_reply": "2023-07-29T14:41:37.551946Z"
        },
        "trusted": true,
        "id": "fR8NO0k-7jdf",
        "outputId": "f2342418-6e6d-411c-99f1-5d5507c49365"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "63/63 [==============================] - 0s 3ms/step\nEnsemble Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.80      0.84      1023\n           1       0.81      0.89      0.85       977\n\n    accuracy                           0.84      2000\n   macro avg       0.85      0.85      0.84      2000\nweighted avg       0.85      0.84      0.84      2000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM\",classification_report(global_y_test, svm_predictions))\n",
        "print(\"logistic_classifier \",classification_report(global_y_test, logistic_predictions))\n",
        "print(\"gru \",classification_report(global_y_test, gru_predictions))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T14:29:50.280493Z",
          "iopub.execute_input": "2023-07-28T14:29:50.280933Z",
          "iopub.status.idle": "2023-07-28T14:29:50.327213Z",
          "shell.execute_reply.started": "2023-07-28T14:29:50.280898Z",
          "shell.execute_reply": "2023-07-28T14:29:50.325853Z"
        },
        "trusted": true,
        "id": "3EbBNlL07jdg",
        "outputId": "5149d64a-61ae-4e69-dc2b-88298d49d2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "SVM               precision    recall  f1-score   support\n\n           0       0.75      0.90      0.82       988\n           1       0.88      0.70      0.78      1012\n\n    accuracy                           0.80      2000\n   macro avg       0.81      0.80      0.80      2000\nweighted avg       0.81      0.80      0.80      2000\n\nlogistic_classifier                precision    recall  f1-score   support\n\n           0       0.83      0.86      0.85       988\n           1       0.86      0.83      0.84      1012\n\n    accuracy                           0.84      2000\n   macro avg       0.84      0.84      0.84      2000\nweighted avg       0.84      0.84      0.84      2000\n\ngru                precision    recall  f1-score   support\n\n           0       0.82      0.83      0.83       988\n           1       0.83      0.82      0.83      1012\n\n    accuracy                           0.83      2000\n   macro avg       0.83      0.83      0.83      2000\nweighted avg       0.83      0.83      0.83      2000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_classifier = LogisticRegression( max_iter=5,solver='saga',C=1,verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:55:27.350543Z",
          "iopub.execute_input": "2023-07-29T12:55:27.350901Z",
          "iopub.status.idle": "2023-07-29T12:55:27.355887Z",
          "shell.execute_reply.started": "2023-07-29T12:55:27.350873Z",
          "shell.execute_reply": "2023-07-29T12:55:27.354764Z"
        },
        "trusted": true,
        "id": "N9TYNYzp7jdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_classifier.fit(X_train_ara, y_train_ara)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:55:27.570501Z",
          "iopub.execute_input": "2023-07-29T12:55:27.571218Z",
          "iopub.status.idle": "2023-07-29T12:55:28.207427Z",
          "shell.execute_reply.started": "2023-07-29T12:55:27.571183Z",
          "shell.execute_reply": "2023-07-29T12:55:28.206440Z"
        },
        "trusted": true,
        "id": "XgVWty3y7jdi",
        "outputId": "b901ca14-2ba1-468d-83b9-338bceaa08fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "max_iter reached after 1 seconds\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 118,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LogisticRegression(C=1, max_iter=5, solver='saga', verbose=1)",
            "text/html": "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, max_iter=5, solver=&#x27;saga&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=5, solver=&#x27;saga&#x27;, verbose=1)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logistic_ppres = logistic_classifier.predict(X_test_ara)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:55:28.209133Z",
          "iopub.execute_input": "2023-07-29T12:55:28.210482Z",
          "iopub.status.idle": "2023-07-29T12:55:28.221647Z",
          "shell.execute_reply.started": "2023-07-29T12:55:28.210446Z",
          "shell.execute_reply": "2023-07-29T12:55:28.219996Z"
        },
        "trusted": true,
        "id": "gadSLgiW7jdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"logistic_classifier \",classification_report(y_test_Ara, logistic_ppres))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:55:31.058969Z",
          "iopub.execute_input": "2023-07-29T12:55:31.059405Z",
          "iopub.status.idle": "2023-07-29T12:55:31.082673Z",
          "shell.execute_reply.started": "2023-07-29T12:55:31.059370Z",
          "shell.execute_reply": "2023-07-29T12:55:31.081266Z"
        },
        "trusted": true,
        "id": "sBtT_IT47jdj",
        "outputId": "4ea7b248-2d46-41ce-9e0c-01223e5baaff"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "logistic_classifier                precision    recall  f1-score   support\n\n           0       0.84      0.89      0.87      1023\n           1       0.88      0.83      0.85       977\n\n    accuracy                           0.86      2000\n   macro avg       0.86      0.86      0.86      2000\nweighted avg       0.86      0.86      0.86      2000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3 : **train on all annotated data**"
      ],
      "metadata": {
        "id": "1cog6hF5Sa4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semi_X_train_counts.shape,semi_y_train.shape"
      ],
      "metadata": {
        "id": "2a6j-Eg67jdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_X_train, final_X_test, final_y_train, final_y_test = train_test_split(train_x_used_semi, train_y_used_semi,test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T14:53:47.417922Z",
          "iopub.execute_input": "2023-07-29T14:53:47.418362Z",
          "iopub.status.idle": "2023-07-29T14:53:47.470026Z",
          "shell.execute_reply.started": "2023-07-29T14:53:47.418331Z",
          "shell.execute_reply": "2023-07-29T14:53:47.468963Z"
        },
        "trusted": true,
        "id": "JqZjCFfz7jdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_classifier = SVC(kernel='rbf', C=1, probability=True)\n",
        "logistic_classifier = LogisticRegression(max_iter=1000, solver='saga', C=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:21:16.822009Z",
          "iopub.execute_input": "2023-07-29T15:21:16.822406Z",
          "iopub.status.idle": "2023-07-29T15:21:16.829333Z",
          "shell.execute_reply.started": "2023-07-29T15:21:16.822371Z",
          "shell.execute_reply": "2023-07-29T15:21:16.828183Z"
        },
        "trusted": true,
        "id": "pyOieNfL7jdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_classifier.fit(final_X_train, final_y_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:21:19.334284Z",
          "iopub.execute_input": "2023-07-29T15:21:19.334645Z",
          "iopub.status.idle": "2023-07-29T15:28:39.729512Z",
          "shell.execute_reply.started": "2023-07-29T15:21:19.334617Z",
          "shell.execute_reply": "2023-07-29T15:28:39.728235Z"
        },
        "trusted": true,
        "id": "T_vq9NT47jdk",
        "outputId": "49b9c23b-4571-40e5-e1ac-647c7a8bdd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 286,
          "output_type": "execute_result",
          "data": {
            "text/plain": "SVC(C=1, probability=True)",
            "text/html": "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, probability=True)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_svm = svm_classifier.predict(final_X_test)\n",
        "print(\"SVM\",classification_report(final_y_test, y_pred_svm))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:28:39.731688Z",
          "iopub.execute_input": "2023-07-29T15:28:39.732364Z",
          "iopub.status.idle": "2023-07-29T15:29:01.046067Z",
          "shell.execute_reply.started": "2023-07-29T15:28:39.732326Z",
          "shell.execute_reply": "2023-07-29T15:29:01.045043Z"
        },
        "trusted": true,
        "id": "SbsIn8Zy7jdk",
        "outputId": "fc0a5e98-2434-4c23-df9b-658576c184a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "SVM               precision    recall  f1-score   support\n\n           0       0.90      0.91      0.90      1392\n           1       0.91      0.90      0.91      1498\n\n    accuracy                           0.90      2890\n   macro avg       0.90      0.90      0.90      2890\nweighted avg       0.90      0.90      0.90      2890\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train each classifier on its respective dataset\n",
        "logistic_classifier.fit(final_X_train, final_y_train)\n",
        "# Make predictions for each classifier\n",
        "y_pred_logistic = logistic_classifier.predict(final_X_test)\n",
        "print(\"logistic_classifier \",classification_report(final_y_test, y_pred_logistic))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:09:19.460501Z",
          "iopub.execute_input": "2023-07-29T15:09:19.460855Z",
          "iopub.status.idle": "2023-07-29T15:15:11.349500Z",
          "shell.execute_reply.started": "2023-07-29T15:09:19.460825Z",
          "shell.execute_reply": "2023-07-29T15:15:11.348448Z"
        },
        "trusted": true,
        "id": "f_OcC1wg7jdk",
        "outputId": "12ea03b6-5ef1-4c01-8435-11d3e22882f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "SVM               precision    recall  f1-score   support\n\n           0       0.96      0.23      0.37      1392\n           1       0.58      0.99      0.73      1498\n\n    accuracy                           0.62      2890\n   macro avg       0.77      0.61      0.55      2890\nweighted avg       0.76      0.62      0.56      2890\n\nlogistic_classifier                precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90      1392\n           1       0.91      0.91      0.91      1498\n\n    accuracy                           0.90      2890\n   macro avg       0.90      0.90      0.90      2890\nweighted avg       0.90      0.90      0.90      2890\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_gru = final_X_train.toarray().reshape(final_X_train.shape[0], 1, final_X_train.shape[1])\n",
        "gru_classifier.fit(X_train_gru, final_y_train, epochs=5, batch_size=128)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:15:57.950027Z",
          "iopub.execute_input": "2023-07-29T15:15:57.951086Z",
          "iopub.status.idle": "2023-07-29T15:16:05.581208Z",
          "shell.execute_reply.started": "2023-07-29T15:15:57.951045Z",
          "shell.execute_reply": "2023-07-29T15:16:05.580492Z"
        },
        "trusted": true,
        "id": "AyHLLJ027jdk",
        "outputId": "39a903d7-ef3c-4427-c437-f7e2c755e005"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n91/91 [==============================] - 4s 14ms/step - loss: 0.1920 - accuracy: 0.9259\nEpoch 2/5\n91/91 [==============================] - 1s 10ms/step - loss: 0.1420 - accuracy: 0.9442\nEpoch 3/5\n91/91 [==============================] - 1s 9ms/step - loss: 0.1239 - accuracy: 0.9543\nEpoch 4/5\n91/91 [==============================] - 1s 9ms/step - loss: 0.1137 - accuracy: 0.9585\nEpoch 5/5\n91/91 [==============================] - 1s 8ms/step - loss: 0.1025 - accuracy: 0.9609\n",
          "output_type": "stream"
        },
        {
          "execution_count": 279,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x79ca911a91e0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_gru = final_X_test.toarray().reshape(final_X_test.shape[0], 1, final_X_test.shape[1])\n",
        "\n",
        "y_pred_gru = gru_classifier.predict(X_test_gru)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:16:44.470319Z",
          "iopub.execute_input": "2023-07-29T15:16:44.470683Z",
          "iopub.status.idle": "2023-07-29T15:16:44.845723Z",
          "shell.execute_reply.started": "2023-07-29T15:16:44.470652Z",
          "shell.execute_reply": "2023-07-29T15:16:44.844773Z"
        },
        "trusted": true,
        "id": "p848SKYU7jdk",
        "outputId": "52042ec8-460e-4a29-a02a-44d9305074c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "91/91 [==============================] - 0s 3ms/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_binary = (y_pred_gru > 0.5).astype(int)\n",
        "print(\"GRU\",classification_report(final_y_test, y_pred_binary))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T15:16:47.015897Z",
          "iopub.execute_input": "2023-07-29T15:16:47.016294Z",
          "iopub.status.idle": "2023-07-29T15:16:47.035767Z",
          "shell.execute_reply.started": "2023-07-29T15:16:47.016253Z",
          "shell.execute_reply": "2023-07-29T15:16:47.034739Z"
        },
        "trusted": true,
        "id": "-5VqaPZU7jdl",
        "outputId": "debc13fa-41f8-46a6-c301-63d931d9cbae"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "GRU               precision    recall  f1-score   support\n\n           0       0.96      0.92      0.94      1392\n           1       0.93      0.97      0.95      1498\n\n    accuracy                           0.94      2890\n   macro avg       0.94      0.94      0.94      2890\nweighted avg       0.94      0.94      0.94      2890\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cnn Lstm Gru\n",
        "\n",
        "\n",
        "*   here we need to check the effect of DNN models with sentiment analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "jTVhwHA57jdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define models of CNN , Lstm and Gru"
      ],
      "metadata": {
        "id": "0MuTc_frV8Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the SVM ,  logistic models\n",
        "\n",
        "X_train_gru = train_x_used_semi.toarray().reshape(train_x_used_semi.shape[0], 1, train_x_used_semi.shape[1])\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "\n",
        "gru_classifier_semi = Sequential()\n",
        "gru_classifier_semi.add(GRU(256, input_shape=(X_train_gru.shape[1], X_train_gru.shape[2]), return_sequences=True))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(GRU(128, return_sequences=True))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(GRU(64))\n",
        "gru_classifier_semi.add(Dropout(0.2))\n",
        "gru_classifier_semi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "gru_classifier_semi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:46:29.308171Z",
          "iopub.execute_input": "2023-07-29T16:46:29.309153Z",
          "iopub.status.idle": "2023-07-29T16:46:30.163475Z",
          "shell.execute_reply.started": "2023-07-29T16:46:29.309114Z",
          "shell.execute_reply": "2023-07-29T16:46:30.162460Z"
        },
        "trusted": true,
        "id": "x904XQBM7jdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "X_train_lstm = train_x_used_semi.toarray().reshape(train_x_used_semi.shape[0], 1, train_x_used_semi.shape[1])\n",
        "lstm_classifier_semi = Sequential()\n",
        "lstm_classifier_semi.add(LSTM(256, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=True))\n",
        "lstm_classifier_semi.add(Dropout(0.6))\n",
        "lstm_classifier_semi.add(LSTM(128, return_sequences=True))\n",
        "lstm_classifier_semi.add(Dropout(0.6))\n",
        "lstm_classifier_semi.add(LSTM(64))\n",
        "lstm_classifier_semi.add(Dropout(0.6))\n",
        "lstm_classifier_semi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "lstm_classifier_semi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:46:30.165664Z",
          "iopub.execute_input": "2023-07-29T16:46:30.166017Z",
          "iopub.status.idle": "2023-07-29T16:46:31.099456Z",
          "shell.execute_reply.started": "2023-07-29T16:46:30.165983Z",
          "shell.execute_reply": "2023-07-29T16:46:31.098430Z"
        },
        "trusted": true,
        "id": "Qdc2jrAQ7jdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_used_semi.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:46:31.101716Z",
          "iopub.execute_input": "2023-07-29T16:46:31.102097Z",
          "iopub.status.idle": "2023-07-29T16:46:31.109023Z",
          "shell.execute_reply.started": "2023-07-29T16:46:31.102063Z",
          "shell.execute_reply": "2023-07-29T16:46:31.107791Z"
        },
        "trusted": true,
        "id": "vUojRygm7jdm",
        "outputId": "bcfb33c1-bbbe-44f7-eb4c-9937e595f4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 342,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(14382, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Assuming `sequence_length` is the length of the sequence (e.g., 15320)\n",
        "sequence_length = 768\n",
        "\n",
        "# Create the CNN model\n",
        "cnn_classifier_semi = Sequential()\n",
        "cnn_classifier_semi.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(sequence_length, 1)))\n",
        "cnn_classifier_semi.add(MaxPooling1D(pool_size=2))\n",
        "cnn_classifier_semi.add(Flatten())\n",
        "cnn_classifier_semi.add(Dense(128, activation='relu'))\n",
        "cnn_classifier_semi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_classifier_semi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:46:31.111038Z",
          "iopub.execute_input": "2023-07-29T16:46:31.111488Z",
          "iopub.status.idle": "2023-07-29T16:46:31.173190Z",
          "shell.execute_reply.started": "2023-07-29T16:46:31.111453Z",
          "shell.execute_reply": "2023-07-29T16:46:31.172193Z"
        },
        "trusted": true,
        "id": "BCOSjpC87jdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_used_semi=csr_matrix(X_train_ara)\n",
        "train_y_used_semi=y_train_ara\n",
        "test_x_used_semi=csr_matrix(X_test_ara)\n",
        "test_y_used_semi=y_test_Ara\n",
        "reamining_data_used=csr_matrix(remaining_data)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:06:51.658660Z",
          "iopub.execute_input": "2023-07-29T16:06:51.659041Z",
          "iopub.status.idle": "2023-07-29T16:06:52.114578Z",
          "shell.execute_reply.started": "2023-07-29T16:06:51.659008Z",
          "shell.execute_reply": "2023-07-29T16:06:52.113533Z"
        },
        "trusted": true,
        "id": "oSyD-AU27jdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_threshold=0.9"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:14:05.165162Z",
          "iopub.execute_input": "2023-07-29T16:14:05.165904Z",
          "iopub.status.idle": "2023-07-29T16:14:05.174436Z",
          "shell.execute_reply.started": "2023-07-29T16:14:05.165860Z",
          "shell.execute_reply": "2023-07-29T16:14:05.173334Z"
        },
        "trusted": true,
        "id": "tNGkLBcG7jdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "\n",
        "\n",
        "# Number of iterations for semi-supervised learning\n",
        "num_iterations = 50\n",
        "\n",
        "\n",
        "# Semi-supervised learning using iterative approach\n",
        "for _ in range(num_iterations):\n",
        "    X_train_gru = train_x_used_semi.toarray().reshape(train_x_used_semi.shape[0], 1, train_x_used_semi.shape[1])\n",
        "    print('step 1')\n",
        "    # Step 1: Train models on labeled data\n",
        "    print('lstm')\n",
        "    lstm_classifier_semi.fit(X_train_gru, train_y_used_semi,epochs=1, batch_size=16)\n",
        "    print('CNN')\n",
        "    X_train_cnn = train_x_used_semi.toarray().reshape(train_x_used_semi.shape[0], sequence_length, 1)\n",
        "    cnn_classifier_semi.fit(X_train_cnn, train_y_used_semi,epochs=1, batch_size=16)\n",
        "    print('gru')\n",
        "    X_train_gru = train_x_used_semi.toarray().reshape(train_x_used_semi.shape[0], 1, train_x_used_semi.shape[1])\n",
        "\n",
        "    gru_classifier_semi.fit(X_train_gru, train_y_used_semi, epochs=1, batch_size=64)  # Adjust epochs and batch size as needed\n",
        "    print('step 2')\n",
        "\n",
        "    # Step 2: Make predictions on unlabeled data\n",
        "\n",
        "\n",
        "    semi_remaning_counts_gru = reamining_data_used.toarray().reshape(reamining_data_used.shape[0], 1, reamining_data_used.shape[1])\n",
        "    semi_remaning_counts_cnn = reamining_data_used.toarray().reshape(reamining_data_used.shape[0], sequence_length, 1)\n",
        "\n",
        "\n",
        "\n",
        "    lstm_predictions = lstm_classifier_semi.predict(semi_remaning_counts_gru)\n",
        "    cnn_predictions = cnn_classifier_semi.predict(semi_remaning_counts_cnn)\n",
        "    gru_predictions = gru_classifier_semi.predict(semi_remaning_counts_gru)\n",
        "\n",
        "    lstm_predictions = np.squeeze(lstm_predictions)\n",
        "    cnn_predictions = np.squeeze(cnn_predictions)\n",
        "    gru_predictions = np.squeeze(gru_predictions)\n",
        "\n",
        "\n",
        "    print('step 3')\n",
        "    reamining_data_used,train_x_used_semi,train_y_used_semi = compare_arrays(lstm_predictions,\n",
        "                                                                                     cnn_predictions,\n",
        "                                                                                     gru_predictions,confidence_threshold,\n",
        "                                                                                     semi_remaning_counts_gru,\n",
        "                                                                                     train_x_used_semi,train_y_used_semi)\n",
        "\n",
        "\n",
        "    print(f\"  labeled shape end of run deletion {train_x_used_semi.shape}\")\n",
        "    print(f\"  nmber of unlabled remaning{reamining_data_used.shape[0]}\")\n",
        "\n",
        "    print('repeat')\n",
        "    confidence_threshold=confidence_threshold-0.008\n",
        "    print(f\"confidence_threshold={confidence_threshold}\")\n",
        "\n",
        "    if global_remaning_counts.shape[0] == 0:\n",
        "        print(f\"All data labeled after iteration {iteration+1}. Stopping the loop.\")\n",
        "        break\n",
        "    # After an iteration, the unlabeled dataset is updated with agreed predictions removed.\n",
        "    # The process will be repeated until the stopping criteria is met.\n",
        "\n",
        "# After the iterations, you can use the trained models for predictions on new data.\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:14:07.918381Z",
          "iopub.execute_input": "2023-07-29T16:14:07.918846Z",
          "iopub.status.idle": "2023-07-29T16:33:19.648152Z",
          "shell.execute_reply.started": "2023-07-29T16:14:07.918807Z",
          "shell.execute_reply": "2023-07-29T16:33:19.647102Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "PB__6gQt7jdn",
        "outputId": "5f1dc45f-2444-46b8-b07a-3bc5248876da"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "step 1\nlstm\n500/500 [==============================] - 3s 6ms/step - loss: 0.3547 - accuracy: 0.8528\nCNN\n500/500 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.8780\ngru\n125/125 [==============================] - 1s 6ms/step - loss: 0.3542 - accuracy: 0.8558\nstep 2\n202/202 [==============================] - 1s 3ms/step\n202/202 [==============================] - 0s 2ms/step\n202/202 [==============================] - 1s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (6448, 1, 768)\n  indexes_to_delete shape before deletion 3214\n  unlabeled shape before deletion (6448, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (3234, 768)\n  labeled shape end of run deletion (11214, 768)\n  nmber of unlabled remaning3234\nrepeat\nconfidence_threshold=0.892\nstep 1\nlstm\n701/701 [==============================] - 9s 9ms/step - loss: 0.2729 - accuracy: 0.8960\nCNN\n701/701 [==============================] - 5s 6ms/step - loss: 0.2098 - accuracy: 0.9149\ngru\n176/176 [==============================] - 5s 9ms/step - loss: 0.2687 - accuracy: 0.8980\nstep 2\n102/102 [==============================] - 0s 3ms/step\n102/102 [==============================] - 0s 2ms/step\n102/102 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (3234, 1, 768)\n  indexes_to_delete shape before deletion 690\n  unlabeled shape before deletion (3234, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2544, 768)\n  labeled shape end of run deletion (11904, 768)\n  nmber of unlabled remaning2544\nrepeat\nconfidence_threshold=0.884\nstep 1\nlstm\n744/744 [==============================] - 7s 10ms/step - loss: 0.2578 - accuracy: 0.9021\nCNN\n744/744 [==============================] - 4s 5ms/step - loss: 0.1985 - accuracy: 0.9225\ngru\n186/186 [==============================] - 2s 9ms/step - loss: 0.2555 - accuracy: 0.9053\nstep 2\n80/80 [==============================] - 0s 3ms/step\n80/80 [==============================] - 0s 2ms/step\n80/80 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (2544, 1, 768)\n  indexes_to_delete shape before deletion 196\n  unlabeled shape before deletion (2544, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2348, 768)\n  labeled shape end of run deletion (12100, 768)\n  nmber of unlabled remaning2348\nrepeat\nconfidence_threshold=0.876\nstep 1\nlstm\n757/757 [==============================] - 7s 9ms/step - loss: 0.2571 - accuracy: 0.9023\nCNN\n757/757 [==============================] - 4s 6ms/step - loss: 0.1899 - accuracy: 0.9247\ngru\n190/190 [==============================] - 2s 9ms/step - loss: 0.2444 - accuracy: 0.9086\nstep 2\n74/74 [==============================] - 0s 3ms/step\n74/74 [==============================] - 0s 2ms/step\n74/74 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (2348, 1, 768)\n  indexes_to_delete shape before deletion 110\n  unlabeled shape before deletion (2348, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (2238, 768)\n  labeled shape end of run deletion (12210, 768)\n  nmber of unlabled remaning2238\nrepeat\nconfidence_threshold=0.868\nstep 1\nlstm\n764/764 [==============================] - 7s 9ms/step - loss: 0.2467 - accuracy: 0.9103\nCNN\n764/764 [==============================] - 4s 5ms/step - loss: 0.1839 - accuracy: 0.9275\ngru\n191/191 [==============================] - 2s 13ms/step - loss: 0.2419 - accuracy: 0.9117\nstep 2\n70/70 [==============================] - 0s 3ms/step\n70/70 [==============================] - 0s 2ms/step\n70/70 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (2238, 1, 768)\n  indexes_to_delete shape before deletion 323\n  unlabeled shape before deletion (2238, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1915, 768)\n  labeled shape end of run deletion (12533, 768)\n  nmber of unlabled remaning1915\nrepeat\nconfidence_threshold=0.86\nstep 1\nlstm\n784/784 [==============================] - 7s 9ms/step - loss: 0.2431 - accuracy: 0.9083\nCNN\n784/784 [==============================] - 4s 6ms/step - loss: 0.1714 - accuracy: 0.9346\ngru\n196/196 [==============================] - 2s 12ms/step - loss: 0.2358 - accuracy: 0.9149\nstep 2\n60/60 [==============================] - 0s 3ms/step\n60/60 [==============================] - 0s 2ms/step\n60/60 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1915, 1, 768)\n  indexes_to_delete shape before deletion 111\n  unlabeled shape before deletion (1915, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1804, 768)\n  labeled shape end of run deletion (12644, 768)\n  nmber of unlabled remaning1804\nrepeat\nconfidence_threshold=0.852\nstep 1\nlstm\n791/791 [==============================] - 7s 9ms/step - loss: 0.2423 - accuracy: 0.9113\nCNN\n791/791 [==============================] - 5s 6ms/step - loss: 0.1694 - accuracy: 0.9343\ngru\n198/198 [==============================] - 2s 9ms/step - loss: 0.2268 - accuracy: 0.9186\nstep 2\n57/57 [==============================] - 0s 3ms/step\n57/57 [==============================] - 0s 2ms/step\n57/57 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1804, 1, 768)\n  indexes_to_delete shape before deletion 154\n  unlabeled shape before deletion (1804, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1650, 768)\n  labeled shape end of run deletion (12798, 768)\n  nmber of unlabled remaning1650\nrepeat\nconfidence_threshold=0.844\nstep 1\nlstm\n800/800 [==============================] - 8s 10ms/step - loss: 0.2339 - accuracy: 0.9158\nCNN\n800/800 [==============================] - 4s 6ms/step - loss: 0.1572 - accuracy: 0.9388\ngru\n200/200 [==============================] - 2s 9ms/step - loss: 0.2268 - accuracy: 0.9170\nstep 2\n52/52 [==============================] - 0s 3ms/step\n52/52 [==============================] - 0s 2ms/step\n52/52 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1650, 1, 768)\n  indexes_to_delete shape before deletion 126\n  unlabeled shape before deletion (1650, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1524, 768)\n  labeled shape end of run deletion (12924, 768)\n  nmber of unlabled remaning1524\nrepeat\nconfidence_threshold=0.836\nstep 1\nlstm\n808/808 [==============================] - 7s 9ms/step - loss: 0.2319 - accuracy: 0.9157\nCNN\n808/808 [==============================] - 6s 8ms/step - loss: 0.1453 - accuracy: 0.9439\ngru\n202/202 [==============================] - 3s 13ms/step - loss: 0.2197 - accuracy: 0.9219\nstep 2\n48/48 [==============================] - 0s 3ms/step\n48/48 [==============================] - 0s 2ms/step\n48/48 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1524, 1, 768)\n  indexes_to_delete shape before deletion 69\n  unlabeled shape before deletion (1524, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1455, 768)\n  labeled shape end of run deletion (12993, 768)\n  nmber of unlabled remaning1455\nrepeat\nconfidence_threshold=0.828\nstep 1\nlstm\n813/813 [==============================] - 7s 9ms/step - loss: 0.2291 - accuracy: 0.9178\nCNN\n813/813 [==============================] - 5s 6ms/step - loss: 0.1450 - accuracy: 0.9417\ngru\n204/204 [==============================] - 2s 9ms/step - loss: 0.2167 - accuracy: 0.9220\nstep 2\n46/46 [==============================] - 0s 3ms/step\n46/46 [==============================] - 0s 2ms/step\n46/46 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1455, 1, 768)\n  indexes_to_delete shape before deletion 106\n  unlabeled shape before deletion (1455, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1349, 768)\n  labeled shape end of run deletion (13099, 768)\n  nmber of unlabled remaning1349\nrepeat\nconfidence_threshold=0.82\nstep 1\nlstm\n819/819 [==============================] - 8s 9ms/step - loss: 0.2321 - accuracy: 0.9148\nCNN\n819/819 [==============================] - 5s 6ms/step - loss: 0.1358 - accuracy: 0.9493\ngru\n205/205 [==============================] - 2s 9ms/step - loss: 0.2131 - accuracy: 0.9239\nstep 2\n43/43 [==============================] - 0s 3ms/step\n43/43 [==============================] - 0s 2ms/step\n43/43 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1349, 1, 768)\n  indexes_to_delete shape before deletion 183\n  unlabeled shape before deletion (1349, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1166, 768)\n  labeled shape end of run deletion (13282, 768)\n  nmber of unlabled remaning1166\nrepeat\nconfidence_threshold=0.8119999999999999\nstep 1\nlstm\n831/831 [==============================] - 8s 10ms/step - loss: 0.2260 - accuracy: 0.9208\nCNN\n831/831 [==============================] - 4s 5ms/step - loss: 0.1282 - accuracy: 0.9509\ngru\n208/208 [==============================] - 2s 9ms/step - loss: 0.2167 - accuracy: 0.9217\nstep 2\n37/37 [==============================] - 0s 3ms/step\n37/37 [==============================] - 0s 2ms/step\n37/37 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1166, 1, 768)\n  indexes_to_delete shape before deletion 38\n  unlabeled shape before deletion (1166, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1128, 768)\n  labeled shape end of run deletion (13320, 768)\n  nmber of unlabled remaning1128\nrepeat\nconfidence_threshold=0.8039999999999999\nstep 1\nlstm\n833/833 [==============================] - 7s 9ms/step - loss: 0.2246 - accuracy: 0.9208\nCNN\n833/833 [==============================] - 4s 5ms/step - loss: 0.1174 - accuracy: 0.9566\ngru\n209/209 [==============================] - 2s 9ms/step - loss: 0.2088 - accuracy: 0.9262\nstep 2\n36/36 [==============================] - 0s 3ms/step\n36/36 [==============================] - 0s 2ms/step\n36/36 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1128, 1, 768)\n  indexes_to_delete shape before deletion 105\n  unlabeled shape before deletion (1128, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (1023, 768)\n  labeled shape end of run deletion (13425, 768)\n  nmber of unlabled remaning1023\nrepeat\nconfidence_threshold=0.7959999999999999\nstep 1\nlstm\n840/840 [==============================] - 7s 9ms/step - loss: 0.2237 - accuracy: 0.9194\nCNN\n840/840 [==============================] - 5s 5ms/step - loss: 0.1093 - accuracy: 0.9558\ngru\n210/210 [==============================] - 2s 9ms/step - loss: 0.2081 - accuracy: 0.9262\nstep 2\n32/32 [==============================] - 0s 3ms/step\n32/32 [==============================] - 0s 2ms/step\n32/32 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (1023, 1, 768)\n  indexes_to_delete shape before deletion 84\n  unlabeled shape before deletion (1023, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (939, 768)\n  labeled shape end of run deletion (13509, 768)\n  nmber of unlabled remaning939\nrepeat\nconfidence_threshold=0.7879999999999999\nstep 1\nlstm\n845/845 [==============================] - 7s 9ms/step - loss: 0.2274 - accuracy: 0.9156\nCNN\n845/845 [==============================] - 5s 6ms/step - loss: 0.1018 - accuracy: 0.9616\ngru\n212/212 [==============================] - 2s 10ms/step - loss: 0.2008 - accuracy: 0.9295\nstep 2\n30/30 [==============================] - 0s 3ms/step\n30/30 [==============================] - 0s 2ms/step\n30/30 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (939, 1, 768)\n  indexes_to_delete shape before deletion 92\n  unlabeled shape before deletion (939, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (847, 768)\n  labeled shape end of run deletion (13601, 768)\n  nmber of unlabled remaning847\nrepeat\nconfidence_threshold=0.7799999999999999\nstep 1\nlstm\n851/851 [==============================] - 8s 9ms/step - loss: 0.2219 - accuracy: 0.9197\nCNN\n851/851 [==============================] - 5s 6ms/step - loss: 0.1002 - accuracy: 0.9608\ngru\n213/213 [==============================] - 2s 9ms/step - loss: 0.2059 - accuracy: 0.9261\nstep 2\n27/27 [==============================] - 0s 4ms/step\n27/27 [==============================] - 0s 3ms/step\n27/27 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (847, 1, 768)\n  indexes_to_delete shape before deletion 31\n  unlabeled shape before deletion (847, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (816, 768)\n  labeled shape end of run deletion (13632, 768)\n  nmber of unlabled remaning816\nrepeat\nconfidence_threshold=0.7719999999999999\nstep 1\nlstm\n852/852 [==============================] - 8s 10ms/step - loss: 0.2167 - accuracy: 0.9234\nCNN\n852/852 [==============================] - 5s 6ms/step - loss: 0.0857 - accuracy: 0.9671\ngru\n213/213 [==============================] - 2s 10ms/step - loss: 0.1997 - accuracy: 0.9290\nstep 2\n26/26 [==============================] - 0s 4ms/step\n26/26 [==============================] - 0s 2ms/step\n26/26 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (816, 1, 768)\n  indexes_to_delete shape before deletion 47\n  unlabeled shape before deletion (816, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (769, 768)\n  labeled shape end of run deletion (13679, 768)\n  nmber of unlabled remaning769\nrepeat\nconfidence_threshold=0.7639999999999999\nstep 1\nlstm\n855/855 [==============================] - 8s 10ms/step - loss: 0.2174 - accuracy: 0.9221\nCNN\n855/855 [==============================] - 5s 6ms/step - loss: 0.0866 - accuracy: 0.9675\ngru\n214/214 [==============================] - 2s 10ms/step - loss: 0.1966 - accuracy: 0.9299\nstep 2\n25/25 [==============================] - 0s 3ms/step\n25/25 [==============================] - 0s 2ms/step\n25/25 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (769, 1, 768)\n  indexes_to_delete shape before deletion 43\n  unlabeled shape before deletion (769, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (726, 768)\n  labeled shape end of run deletion (13722, 768)\n  nmber of unlabled remaning726\nrepeat\nconfidence_threshold=0.7559999999999999\nstep 1\nlstm\n858/858 [==============================] - 8s 10ms/step - loss: 0.2163 - accuracy: 0.9210\nCNN\n858/858 [==============================] - 5s 5ms/step - loss: 0.0800 - accuracy: 0.9681\ngru\n215/215 [==============================] - 2s 11ms/step - loss: 0.1975 - accuracy: 0.9308\nstep 2\n23/23 [==============================] - 0s 5ms/step\n23/23 [==============================] - 0s 3ms/step\n23/23 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (726, 1, 768)\n  indexes_to_delete shape before deletion 95\n  unlabeled shape before deletion (726, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (631, 768)\n  labeled shape end of run deletion (13817, 768)\n  nmber of unlabled remaning631\nrepeat\nconfidence_threshold=0.7479999999999999\nstep 1\nlstm\n864/864 [==============================] - 8s 9ms/step - loss: 0.2211 - accuracy: 0.9187\nCNN\n864/864 [==============================] - 5s 6ms/step - loss: 0.0818 - accuracy: 0.9701\ngru\n216/216 [==============================] - 2s 10ms/step - loss: 0.1934 - accuracy: 0.9320\nstep 2\n20/20 [==============================] - 0s 3ms/step\n20/20 [==============================] - 0s 2ms/step\n20/20 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (631, 1, 768)\n  indexes_to_delete shape before deletion 40\n  unlabeled shape before deletion (631, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (591, 768)\n  labeled shape end of run deletion (13857, 768)\n  nmber of unlabled remaning591\nrepeat\nconfidence_threshold=0.7399999999999999\nstep 1\nlstm\n867/867 [==============================] - 9s 10ms/step - loss: 0.2203 - accuracy: 0.9192\nCNN\n867/867 [==============================] - 5s 6ms/step - loss: 0.0766 - accuracy: 0.9697\ngru\n217/217 [==============================] - 2s 9ms/step - loss: 0.1975 - accuracy: 0.9315\nstep 2\n19/19 [==============================] - 0s 3ms/step\n19/19 [==============================] - 0s 2ms/step\n19/19 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (591, 1, 768)\n  indexes_to_delete shape before deletion 55\n  unlabeled shape before deletion (591, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (536, 768)\n  labeled shape end of run deletion (13912, 768)\n  nmber of unlabled remaning536\nrepeat\nconfidence_threshold=0.7319999999999999\nstep 1\nlstm\n870/870 [==============================] - 8s 9ms/step - loss: 0.2119 - accuracy: 0.9243\nCNN\n870/870 [==============================] - 5s 6ms/step - loss: 0.0769 - accuracy: 0.9690\ngru\n218/218 [==============================] - 2s 10ms/step - loss: 0.1937 - accuracy: 0.9301\nstep 2\n17/17 [==============================] - 0s 4ms/step\n17/17 [==============================] - 0s 2ms/step\n17/17 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (536, 1, 768)\n  indexes_to_delete shape before deletion 61\n  unlabeled shape before deletion (536, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (475, 768)\n  labeled shape end of run deletion (13973, 768)\n  nmber of unlabled remaning475\nrepeat\nconfidence_threshold=0.7239999999999999\nstep 1\nlstm\n874/874 [==============================] - 8s 9ms/step - loss: 0.2202 - accuracy: 0.9225\nCNN\n874/874 [==============================] - 5s 5ms/step - loss: 0.0605 - accuracy: 0.9761\ngru\n219/219 [==============================] - 2s 8ms/step - loss: 0.1934 - accuracy: 0.9311\nstep 2\n15/15 [==============================] - 0s 3ms/step\n15/15 [==============================] - 0s 2ms/step\n15/15 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (475, 1, 768)\n  indexes_to_delete shape before deletion 19\n  unlabeled shape before deletion (475, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (456, 768)\n  labeled shape end of run deletion (13992, 768)\n  nmber of unlabled remaning456\nrepeat\nconfidence_threshold=0.7159999999999999\nstep 1\nlstm\n875/875 [==============================] - 8s 10ms/step - loss: 0.2202 - accuracy: 0.9205\nCNN\n875/875 [==============================] - 5s 5ms/step - loss: 0.0584 - accuracy: 0.9776\ngru\n219/219 [==============================] - 2s 9ms/step - loss: 0.1926 - accuracy: 0.9328\nstep 2\n15/15 [==============================] - 0s 3ms/step\n15/15 [==============================] - 0s 2ms/step\n15/15 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (456, 1, 768)\n  indexes_to_delete shape before deletion 26\n  unlabeled shape before deletion (456, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (430, 768)\n  labeled shape end of run deletion (14018, 768)\n  nmber of unlabled remaning430\nrepeat\nconfidence_threshold=0.7079999999999999\nstep 1\nlstm\n877/877 [==============================] - 8s 9ms/step - loss: 0.2152 - accuracy: 0.9228\nCNN\n877/877 [==============================] - 5s 5ms/step - loss: 0.0619 - accuracy: 0.9763\ngru\n220/220 [==============================] - 2s 9ms/step - loss: 0.1879 - accuracy: 0.9335\nstep 2\n14/14 [==============================] - 0s 3ms/step\n14/14 [==============================] - 0s 2ms/step\n14/14 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (430, 1, 768)\n  indexes_to_delete shape before deletion 69\n  unlabeled shape before deletion (430, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (361, 768)\n  labeled shape end of run deletion (14087, 768)\n  nmber of unlabled remaning361\nrepeat\nconfidence_threshold=0.6999999999999998\nstep 1\nlstm\n881/881 [==============================] - 8s 9ms/step - loss: 0.2139 - accuracy: 0.9229\nCNN\n881/881 [==============================] - 5s 6ms/step - loss: 0.0601 - accuracy: 0.9773\ngru\n221/221 [==============================] - 2s 9ms/step - loss: 0.1827 - accuracy: 0.9352\nstep 2\n12/12 [==============================] - 0s 3ms/step\n12/12 [==============================] - 0s 2ms/step\n12/12 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (361, 1, 768)\n  indexes_to_delete shape before deletion 16\n  unlabeled shape before deletion (361, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (345, 768)\n  labeled shape end of run deletion (14103, 768)\n  nmber of unlabled remaning345\nrepeat\nconfidence_threshold=0.6919999999999998\nstep 1\nlstm\n882/882 [==============================] - 8s 9ms/step - loss: 0.2212 - accuracy: 0.9202\nCNN\n882/882 [==============================] - 5s 6ms/step - loss: 0.0477 - accuracy: 0.9817\ngru\n221/221 [==============================] - 2s 9ms/step - loss: 0.1794 - accuracy: 0.9364\nstep 2\n11/11 [==============================] - 0s 3ms/step\n11/11 [==============================] - 0s 2ms/step\n11/11 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (345, 1, 768)\n  indexes_to_delete shape before deletion 72\n  unlabeled shape before deletion (345, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (273, 768)\n  labeled shape end of run deletion (14175, 768)\n  nmber of unlabled remaning273\nrepeat\nconfidence_threshold=0.6839999999999998\nstep 1\nlstm\n886/886 [==============================] - 8s 9ms/step - loss: 0.2179 - accuracy: 0.9209\nCNN\n886/886 [==============================] - 5s 6ms/step - loss: 0.0598 - accuracy: 0.9765\ngru\n222/222 [==============================] - 3s 12ms/step - loss: 0.1843 - accuracy: 0.9349\nstep 2\n9/9 [==============================] - 0s 3ms/step\n9/9 [==============================] - 0s 2ms/step\n9/9 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (273, 1, 768)\n  indexes_to_delete shape before deletion 11\n  unlabeled shape before deletion (273, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (262, 768)\n  labeled shape end of run deletion (14186, 768)\n  nmber of unlabled remaning262\nrepeat\nconfidence_threshold=0.6759999999999998\nstep 1\nlstm\n887/887 [==============================] - 8s 9ms/step - loss: 0.2136 - accuracy: 0.9198\nCNN\n887/887 [==============================] - 5s 5ms/step - loss: 0.0550 - accuracy: 0.9791\ngru\n222/222 [==============================] - 2s 9ms/step - loss: 0.1804 - accuracy: 0.9365\nstep 2\n9/9 [==============================] - 0s 3ms/step\n9/9 [==============================] - 0s 2ms/step\n9/9 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (262, 1, 768)\n  indexes_to_delete shape before deletion 4\n  unlabeled shape before deletion (262, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (258, 768)\n  labeled shape end of run deletion (14190, 768)\n  nmber of unlabled remaning258\nrepeat\nconfidence_threshold=0.6679999999999998\nstep 1\nlstm\n887/887 [==============================] - 8s 10ms/step - loss: 0.2140 - accuracy: 0.9223\nCNN\n887/887 [==============================] - 5s 6ms/step - loss: 0.0434 - accuracy: 0.9839\ngru\n222/222 [==============================] - 2s 9ms/step - loss: 0.1798 - accuracy: 0.9370\nstep 2\n9/9 [==============================] - 0s 3ms/step\n9/9 [==============================] - 0s 2ms/step\n9/9 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (258, 1, 768)\n  indexes_to_delete shape before deletion 12\n  unlabeled shape before deletion (258, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (246, 768)\n  labeled shape end of run deletion (14202, 768)\n  nmber of unlabled remaning246\nrepeat\nconfidence_threshold=0.6599999999999998\nstep 1\nlstm\n888/888 [==============================] - 8s 9ms/step - loss: 0.2108 - accuracy: 0.9230\nCNN\n888/888 [==============================] - 5s 6ms/step - loss: 0.0491 - accuracy: 0.9823\ngru\n222/222 [==============================] - 2s 9ms/step - loss: 0.1841 - accuracy: 0.9329\nstep 2\n8/8 [==============================] - 0s 3ms/step\n8/8 [==============================] - 0s 2ms/step\n8/8 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (246, 1, 768)\n  indexes_to_delete shape before deletion 8\n  unlabeled shape before deletion (246, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (238, 768)\n  labeled shape end of run deletion (14210, 768)\n  nmber of unlabled remaning238\nrepeat\nconfidence_threshold=0.6519999999999998\nstep 1\nlstm\n889/889 [==============================] - 9s 10ms/step - loss: 0.2088 - accuracy: 0.9247\nCNN\n889/889 [==============================] - 5s 5ms/step - loss: 0.0390 - accuracy: 0.9854\ngru\n223/223 [==============================] - 2s 9ms/step - loss: 0.1789 - accuracy: 0.9354\nstep 2\n8/8 [==============================] - 0s 3ms/step\n8/8 [==============================] - 0s 2ms/step\n8/8 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (238, 1, 768)\n  indexes_to_delete shape before deletion 8\n  unlabeled shape before deletion (238, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (230, 768)\n  labeled shape end of run deletion (14218, 768)\n  nmber of unlabled remaning230\nrepeat\nconfidence_threshold=0.6439999999999998\nstep 1\nlstm\n889/889 [==============================] - 8s 9ms/step - loss: 0.2098 - accuracy: 0.9230\nCNN\n889/889 [==============================] - 5s 5ms/step - loss: 0.0354 - accuracy: 0.9870\ngru\n223/223 [==============================] - 2s 10ms/step - loss: 0.1780 - accuracy: 0.9376\nstep 2\n8/8 [==============================] - 0s 5ms/step\n8/8 [==============================] - 0s 3ms/step\n8/8 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (230, 1, 768)\n  indexes_to_delete shape before deletion 16\n  unlabeled shape before deletion (230, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (214, 768)\n  labeled shape end of run deletion (14234, 768)\n  nmber of unlabled remaning214\nrepeat\nconfidence_threshold=0.6359999999999998\nstep 1\nlstm\n890/890 [==============================] - 8s 9ms/step - loss: 0.2071 - accuracy: 0.9251\nCNN\n890/890 [==============================] - 5s 5ms/step - loss: 0.0454 - accuracy: 0.9828\ngru\n223/223 [==============================] - 2s 9ms/step - loss: 0.1777 - accuracy: 0.9359\nstep 2\n7/7 [==============================] - 0s 3ms/step\n7/7 [==============================] - 0s 2ms/step\n7/7 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (214, 1, 768)\n  indexes_to_delete shape before deletion 14\n  unlabeled shape before deletion (214, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (200, 768)\n  labeled shape end of run deletion (14248, 768)\n  nmber of unlabled remaning200\nrepeat\nconfidence_threshold=0.6279999999999998\nstep 1\nlstm\n891/891 [==============================] - 8s 9ms/step - loss: 0.2040 - accuracy: 0.9247\nCNN\n891/891 [==============================] - 5s 6ms/step - loss: 0.0351 - accuracy: 0.9874\ngru\n223/223 [==============================] - 2s 9ms/step - loss: 0.1727 - accuracy: 0.9379\nstep 2\n7/7 [==============================] - 0s 3ms/step\n7/7 [==============================] - 0s 2ms/step\n7/7 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (200, 1, 768)\n  indexes_to_delete shape before deletion 16\n  unlabeled shape before deletion (200, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (184, 768)\n  labeled shape end of run deletion (14264, 768)\n  nmber of unlabled remaning184\nrepeat\nconfidence_threshold=0.6199999999999998\nstep 1\nlstm\n892/892 [==============================] - 8s 9ms/step - loss: 0.2089 - accuracy: 0.9251\nCNN\n892/892 [==============================] - 5s 6ms/step - loss: 0.0400 - accuracy: 0.9847\ngru\n223/223 [==============================] - 2s 9ms/step - loss: 0.1732 - accuracy: 0.9390\nstep 2\n6/6 [==============================] - 0s 3ms/step\n6/6 [==============================] - 0s 2ms/step\n6/6 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (184, 1, 768)\n  indexes_to_delete shape before deletion 13\n  unlabeled shape before deletion (184, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (171, 768)\n  labeled shape end of run deletion (14277, 768)\n  nmber of unlabled remaning171\nrepeat\nconfidence_threshold=0.6119999999999998\nstep 1\nlstm\n893/893 [==============================] - 9s 10ms/step - loss: 0.2043 - accuracy: 0.9265\nCNN\n893/893 [==============================] - 5s 6ms/step - loss: 0.0369 - accuracy: 0.9873\ngru\n224/224 [==============================] - 2s 9ms/step - loss: 0.1704 - accuracy: 0.9397\nstep 2\n6/6 [==============================] - 0s 3ms/step\n6/6 [==============================] - 0s 2ms/step\n6/6 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (171, 1, 768)\n  indexes_to_delete shape before deletion 14\n  unlabeled shape before deletion (171, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (157, 768)\n  labeled shape end of run deletion (14291, 768)\n  nmber of unlabled remaning157\nrepeat\nconfidence_threshold=0.6039999999999998\nstep 1\nlstm\n894/894 [==============================] - 8s 9ms/step - loss: 0.2117 - accuracy: 0.9232\nCNN\n894/894 [==============================] - 5s 6ms/step - loss: 0.0310 - accuracy: 0.9883\ngru\n224/224 [==============================] - 2s 11ms/step - loss: 0.1667 - accuracy: 0.9425\nstep 2\n5/5 [==============================] - 0s 3ms/step\n5/5 [==============================] - 0s 3ms/step\n5/5 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (157, 1, 768)\n  indexes_to_delete shape before deletion 7\n  unlabeled shape before deletion (157, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (150, 768)\n  labeled shape end of run deletion (14298, 768)\n  nmber of unlabled remaning150\nrepeat\nconfidence_threshold=0.5959999999999998\nstep 1\nlstm\n894/894 [==============================] - 8s 9ms/step - loss: 0.2057 - accuracy: 0.9273\nCNN\n894/894 [==============================] - 5s 5ms/step - loss: 0.0352 - accuracy: 0.9860\ngru\n224/224 [==============================] - 2s 9ms/step - loss: 0.1653 - accuracy: 0.9420\nstep 2\n5/5 [==============================] - 0s 3ms/step\n5/5 [==============================] - 0s 2ms/step\n5/5 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (150, 1, 768)\n  indexes_to_delete shape before deletion 9\n  unlabeled shape before deletion (150, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (141, 768)\n  labeled shape end of run deletion (14307, 768)\n  nmber of unlabled remaning141\nrepeat\nconfidence_threshold=0.5879999999999997\nstep 1\nlstm\n895/895 [==============================] - 8s 9ms/step - loss: 0.2043 - accuracy: 0.9269\nCNN\n895/895 [==============================] - 6s 6ms/step - loss: 0.0307 - accuracy: 0.9885\ngru\n224/224 [==============================] - 2s 9ms/step - loss: 0.1649 - accuracy: 0.9409\nstep 2\n5/5 [==============================] - 0s 3ms/step\n5/5 [==============================] - 0s 3ms/step\n5/5 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (141, 1, 768)\n  indexes_to_delete shape before deletion 11\n  unlabeled shape before deletion (141, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (130, 768)\n  labeled shape end of run deletion (14318, 768)\n  nmber of unlabled remaning130\nrepeat\nconfidence_threshold=0.5799999999999997\nstep 1\nlstm\n895/895 [==============================] - 8s 9ms/step - loss: 0.2054 - accuracy: 0.9252\nCNN\n895/895 [==============================] - 5s 5ms/step - loss: 0.0362 - accuracy: 0.9877\ngru\n224/224 [==============================] - 2s 9ms/step - loss: 0.1630 - accuracy: 0.9418\nstep 2\n5/5 [==============================] - 0s 3ms/step\n5/5 [==============================] - 0s 2ms/step\n5/5 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (130, 1, 768)\n  indexes_to_delete shape before deletion 9\n  unlabeled shape before deletion (130, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (121, 768)\n  labeled shape end of run deletion (14327, 768)\n  nmber of unlabled remaning121\nrepeat\nconfidence_threshold=0.5719999999999997\nstep 1\nlstm\n896/896 [==============================] - 9s 10ms/step - loss: 0.2004 - accuracy: 0.9270\nCNN\n896/896 [==============================] - 5s 5ms/step - loss: 0.0327 - accuracy: 0.9879\ngru\n224/224 [==============================] - 2s 9ms/step - loss: 0.1630 - accuracy: 0.9430\nstep 2\n4/4 [==============================] - 0s 4ms/step\n4/4 [==============================] - 0s 2ms/step\n4/4 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (121, 1, 768)\n  indexes_to_delete shape before deletion 1\n  unlabeled shape before deletion (121, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (120, 768)\n  labeled shape end of run deletion (14328, 768)\n  nmber of unlabled remaning120\nrepeat\nconfidence_threshold=0.5639999999999997\nstep 1\nlstm\n896/896 [==============================] - 8s 9ms/step - loss: 0.2060 - accuracy: 0.9270\nCNN\n896/896 [==============================] - 5s 6ms/step - loss: 0.0271 - accuracy: 0.9895\ngru\n224/224 [==============================] - 2s 9ms/step - loss: 0.1618 - accuracy: 0.9408\nstep 2\n4/4 [==============================] - 0s 4ms/step\n4/4 [==============================] - 0s 3ms/step\n4/4 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (120, 1, 768)\n  indexes_to_delete shape before deletion 8\n  unlabeled shape before deletion (120, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (112, 768)\n  labeled shape end of run deletion (14336, 768)\n  nmber of unlabled remaning112\nrepeat\nconfidence_threshold=0.5559999999999997\nstep 1\nlstm\n896/896 [==============================] - 8s 9ms/step - loss: 0.2055 - accuracy: 0.9249\nCNN\n896/896 [==============================] - 5s 5ms/step - loss: 0.0303 - accuracy: 0.9885\ngru\n224/224 [==============================] - 2s 8ms/step - loss: 0.1628 - accuracy: 0.9428\nstep 2\n4/4 [==============================] - 0s 4ms/step\n4/4 [==============================] - 0s 2ms/step\n4/4 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (112, 1, 768)\n  indexes_to_delete shape before deletion 8\n  unlabeled shape before deletion (112, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (104, 768)\n  labeled shape end of run deletion (14344, 768)\n  nmber of unlabled remaning104\nrepeat\nconfidence_threshold=0.5479999999999997\nstep 1\nlstm\n897/897 [==============================] - 8s 9ms/step - loss: 0.2037 - accuracy: 0.9270\nCNN\n897/897 [==============================] - 5s 5ms/step - loss: 0.0383 - accuracy: 0.9866\ngru\n225/225 [==============================] - 2s 9ms/step - loss: 0.1577 - accuracy: 0.9438\nstep 2\n4/4 [==============================] - 0s 4ms/step\n4/4 [==============================] - 0s 3ms/step\n4/4 [==============================] - 0s 3ms/step\nstep 3\n############\n  unlabeled shape before deletion (104, 1, 768)\n  indexes_to_delete shape before deletion 8\n  unlabeled shape before deletion (104, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (96, 768)\n  labeled shape end of run deletion (14352, 768)\n  nmber of unlabled remaning96\nrepeat\nconfidence_threshold=0.5399999999999997\nstep 1\nlstm\n897/897 [==============================] - 8s 9ms/step - loss: 0.2040 - accuracy: 0.9266\nCNN\n897/897 [==============================] - 5s 5ms/step - loss: 0.0285 - accuracy: 0.9905\ngru\n225/225 [==============================] - 2s 9ms/step - loss: 0.1539 - accuracy: 0.9465\nstep 2\n3/3 [==============================] - 0s 4ms/step\n3/3 [==============================] - 0s 3ms/step\n3/3 [==============================] - 0s 4ms/step\nstep 3\n############\n  unlabeled shape before deletion (96, 1, 768)\n  indexes_to_delete shape before deletion 4\n  unlabeled shape before deletion (96, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (92, 768)\n  labeled shape end of run deletion (14356, 768)\n  nmber of unlabled remaning92\nrepeat\nconfidence_threshold=0.5319999999999997\nstep 1\nlstm\n898/898 [==============================] - 9s 10ms/step - loss: 0.2008 - accuracy: 0.9271\nCNN\n898/898 [==============================] - 5s 6ms/step - loss: 0.0221 - accuracy: 0.9928\ngru\n225/225 [==============================] - 2s 9ms/step - loss: 0.1557 - accuracy: 0.9464\nstep 2\n3/3 [==============================] - 0s 4ms/step\n3/3 [==============================] - 0s 5ms/step\n3/3 [==============================] - 0s 4ms/step\nstep 3\n############\n  unlabeled shape before deletion (92, 1, 768)\n  indexes_to_delete shape before deletion 8\n  unlabeled shape before deletion (92, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (84, 768)\n  labeled shape end of run deletion (14364, 768)\n  nmber of unlabled remaning84\nrepeat\nconfidence_threshold=0.5239999999999997\nstep 1\nlstm\n898/898 [==============================] - 8s 9ms/step - loss: 0.1978 - accuracy: 0.9294\nCNN\n898/898 [==============================] - 5s 6ms/step - loss: 0.0232 - accuracy: 0.9915\ngru\n225/225 [==============================] - 2s 9ms/step - loss: 0.1567 - accuracy: 0.9464\nstep 2\n3/3 [==============================] - 0s 4ms/step\n3/3 [==============================] - 0s 3ms/step\n3/3 [==============================] - 0s 4ms/step\nstep 3\n############\n  unlabeled shape before deletion (84, 1, 768)\n  indexes_to_delete shape before deletion 11\n  unlabeled shape before deletion (84, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (73, 768)\n  labeled shape end of run deletion (14375, 768)\n  nmber of unlabled remaning73\nrepeat\nconfidence_threshold=0.5159999999999997\nstep 1\nlstm\n899/899 [==============================] - 8s 9ms/step - loss: 0.1951 - accuracy: 0.9278\nCNN\n899/899 [==============================] - 5s 5ms/step - loss: 0.0298 - accuracy: 0.9887\ngru\n225/225 [==============================] - 2s 9ms/step - loss: 0.1554 - accuracy: 0.9453\nstep 2\n3/3 [==============================] - 0s 4ms/step\n3/3 [==============================] - 0s 3ms/step\n3/3 [==============================] - 0s 4ms/step\nstep 3\n############\n  unlabeled shape before deletion (73, 1, 768)\n  indexes_to_delete shape before deletion 5\n  unlabeled shape before deletion (73, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (68, 768)\n  labeled shape end of run deletion (14380, 768)\n  nmber of unlabled remaning68\nrepeat\nconfidence_threshold=0.5079999999999997\nstep 1\nlstm\n899/899 [==============================] - 9s 10ms/step - loss: 0.1957 - accuracy: 0.9286\nCNN\n899/899 [==============================] - 5s 6ms/step - loss: 0.0306 - accuracy: 0.9886\ngru\n225/225 [==============================] - 2s 9ms/step - loss: 0.1525 - accuracy: 0.9449\nstep 2\n3/3 [==============================] - 0s 4ms/step\n3/3 [==============================] - 0s 2ms/step\n3/3 [==============================] - 0s 4ms/step\nstep 3\n############\n  unlabeled shape before deletion (68, 1, 768)\n  indexes_to_delete shape before deletion 2\n  unlabeled shape before deletion (68, 1, 768)\n<class 'numpy.ndarray'>\n############\n  unlabeled shape after deletion (66, 768)\n  labeled shape end of run deletion (14382, 768)\n  nmber of unlabled remaning66\nrepeat\nconfidence_threshold=0.49999999999999967\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evalute the Models"
      ],
      "metadata": {
        "id": "tpvk97EYXtHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_X_train, final_X_test, final_y_train, final_y_test = train_test_split(train_x_used_semi, train_y_used_semi,test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:48:39.348519Z",
          "iopub.execute_input": "2023-07-29T16:48:39.348951Z",
          "iopub.status.idle": "2023-07-29T16:48:39.399288Z",
          "shell.execute_reply.started": "2023-07-29T16:48:39.348917Z",
          "shell.execute_reply": "2023-07-29T16:48:39.398257Z"
        },
        "trusted": true,
        "id": "HnmesgVv7jdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_gru = final_X_train.toarray().reshape(final_X_train.shape[0], 1, final_X_train.shape[1])\n",
        "print('lstm')\n",
        "lstm_classifier_semi.fit(X_train_gru, final_y_train,epochs=10, batch_size=32)\n",
        "print('CNN')\n",
        "X_train_cnn = final_X_train.toarray().reshape(final_X_train.shape[0], sequence_length, 1)\n",
        "cnn_classifier_semi.fit(X_train_cnn, final_y_train,epochs=10, batch_size=32)\n",
        "print('gru')\n",
        "\n",
        "gru_classifier_semi.fit(X_train_gru, final_y_train, epochs=10, batch_size=64)  # Adjust epochs and batch size as needed"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T17:13:20.069372Z",
          "iopub.execute_input": "2023-07-29T17:13:20.069749Z",
          "iopub.status.idle": "2023-07-29T17:14:42.615727Z",
          "shell.execute_reply.started": "2023-07-29T17:13:20.069718Z",
          "shell.execute_reply": "2023-07-29T17:14:42.614653Z"
        },
        "trusted": true,
        "id": "xHswZ0RR7jdn",
        "outputId": "a7bdf3ea-7088-47be-9c45-cb2759d14d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "lstm\nEpoch 1/10\n360/360 [==============================] - 3s 8ms/step - loss: 0.1906 - accuracy: 0.9331\nEpoch 2/10\n360/360 [==============================] - 3s 8ms/step - loss: 0.1902 - accuracy: 0.9297\nEpoch 3/10\n360/360 [==============================] - 3s 8ms/step - loss: 0.1852 - accuracy: 0.9351\nEpoch 4/10\n360/360 [==============================] - 3s 9ms/step - loss: 0.1883 - accuracy: 0.9342\nEpoch 5/10\n360/360 [==============================] - 3s 8ms/step - loss: 0.1821 - accuracy: 0.9350\nEpoch 6/10\n360/360 [==============================] - 3s 8ms/step - loss: 0.1762 - accuracy: 0.9386\nEpoch 7/10\n360/360 [==============================] - 3s 8ms/step - loss: 0.1843 - accuracy: 0.9362\nEpoch 8/10\n360/360 [==============================] - 3s 7ms/step - loss: 0.1786 - accuracy: 0.9374\nEpoch 9/10\n360/360 [==============================] - 3s 8ms/step - loss: 0.1787 - accuracy: 0.9385\nEpoch 10/10\n360/360 [==============================] - 3s 8ms/step - loss: 0.1749 - accuracy: 0.9399\nCNN\nEpoch 1/10\n360/360 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9933\nEpoch 2/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9905\nEpoch 3/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9771\nEpoch 4/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9910\nEpoch 5/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9916\nEpoch 6/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9957\nEpoch 7/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9956\nEpoch 8/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9905\nEpoch 9/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9933\nEpoch 10/10\n360/360 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9922\ngru\nEpoch 1/10\n180/180 [==============================] - 1s 7ms/step - loss: 0.1775 - accuracy: 0.9368\nEpoch 2/10\n180/180 [==============================] - 1s 7ms/step - loss: 0.1757 - accuracy: 0.9375\nEpoch 3/10\n180/180 [==============================] - 1s 7ms/step - loss: 0.1715 - accuracy: 0.9394\nEpoch 4/10\n180/180 [==============================] - 1s 7ms/step - loss: 0.1686 - accuracy: 0.9415\nEpoch 5/10\n180/180 [==============================] - 1s 7ms/step - loss: 0.1671 - accuracy: 0.9403\nEpoch 6/10\n180/180 [==============================] - 1s 7ms/step - loss: 0.1621 - accuracy: 0.9429\nEpoch 7/10\n180/180 [==============================] - 1s 7ms/step - loss: 0.1657 - accuracy: 0.9404\nEpoch 8/10\n180/180 [==============================] - 1s 7ms/step - loss: 0.1656 - accuracy: 0.9439\nEpoch 9/10\n180/180 [==============================] - 1s 8ms/step - loss: 0.1594 - accuracy: 0.9432\nEpoch 10/10\n180/180 [==============================] - 2s 9ms/step - loss: 0.1567 - accuracy: 0.9442\n",
          "output_type": "stream"
        },
        {
          "execution_count": 359,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x79ca749b0070>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "semi_remaning_counts_gru = final_X_test.toarray().reshape(final_X_test.shape[0], 1, final_X_test.shape[1])\n",
        "semi_remaning_counts_cnn = final_X_test.toarray().reshape(final_X_test.shape[0], sequence_length, 1)\n",
        "\n",
        "\n",
        "\n",
        "lstm_predictions = lstm_classifier_semi.predict(semi_remaning_counts_gru)\n",
        "cnn_predictions = cnn_classifier_semi.predict(semi_remaning_counts_cnn)\n",
        "gru_predictions = gru_classifier_semi.predict(semi_remaning_counts_gru)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T17:15:06.091419Z",
          "iopub.execute_input": "2023-07-29T17:15:06.091985Z",
          "iopub.status.idle": "2023-07-29T17:15:07.346703Z",
          "shell.execute_reply.started": "2023-07-29T17:15:06.091943Z",
          "shell.execute_reply": "2023-07-29T17:15:07.345686Z"
        },
        "trusted": true,
        "id": "CZUssqtN7jdn",
        "outputId": "d534eb16-6053-4461-855f-f6500557fab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "90/90 [==============================] - 0s 4ms/step\n90/90 [==============================] - 0s 2ms/step\n90/90 [==============================] - 0s 3ms/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_binary = (lstm_predictions > 0.5).astype(int)\n",
        "print(\"lstm \",classification_report(final_y_test, y_pred_binary))\n",
        "y_pred_binary = (cnn_predictions > 0.5).astype(int)\n",
        "print(\"cnn \",classification_report(final_y_test, y_pred_binary))\n",
        "y_pred_binary = (gru_predictions > 0.5).astype(int)\n",
        "print(\"gru \",classification_report(final_y_test, y_pred_binary))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T17:15:07.477859Z",
          "iopub.execute_input": "2023-07-29T17:15:07.479547Z",
          "iopub.status.idle": "2023-07-29T17:15:07.522317Z",
          "shell.execute_reply.started": "2023-07-29T17:15:07.479482Z",
          "shell.execute_reply": "2023-07-29T17:15:07.521284Z"
        },
        "trusted": true,
        "id": "yIUF4hnQ7jdo",
        "outputId": "e4530fe8-f6d5-41af-c0e6-ef5d71deb7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "lstm                precision    recall  f1-score   support\n\n           0       0.91      0.93      0.92      1446\n           1       0.93      0.90      0.91      1431\n\n    accuracy                           0.92      2877\n   macro avg       0.92      0.92      0.92      2877\nweighted avg       0.92      0.92      0.92      2877\n\ncnn                precision    recall  f1-score   support\n\n           0       0.86      0.94      0.90      1446\n           1       0.93      0.85      0.89      1431\n\n    accuracy                           0.90      2877\n   macro avg       0.90      0.90      0.90      2877\nweighted avg       0.90      0.90      0.90      2877\n\ngru                precision    recall  f1-score   support\n\n           0       0.93      0.92      0.92      1446\n           1       0.92      0.92      0.92      1431\n\n    accuracy                           0.92      2877\n   macro avg       0.92      0.92      0.92      2877\nweighted avg       0.92      0.92      0.92      2877\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "####10 epochs :\n",
        "overfitting happens for cnn with 10 epochs"
      ],
      "metadata": {
        "id": "OwDoWcp67jdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_binary = (lstm_predictions > 0.5).astype(int)\n",
        "print(\"lstm \",classification_report(final_y_test, y_pred_binary))\n",
        "y_pred_binary = (cnn_predictions > 0.5).astype(int)\n",
        "print(\"cnn \",classification_report(final_y_test, y_pred_binary))\n",
        "y_pred_binary = (gru_predictions > 0.5).astype(int)\n",
        "print(\"gru \",classification_report(final_y_test, y_pred_binary))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:53:34.306808Z",
          "iopub.execute_input": "2023-07-29T16:53:34.307184Z",
          "iopub.status.idle": "2023-07-29T16:53:34.348973Z",
          "shell.execute_reply.started": "2023-07-29T16:53:34.307152Z",
          "shell.execute_reply": "2023-07-29T16:53:34.347724Z"
        },
        "trusted": true,
        "id": "K0C7QFYB7jdo",
        "outputId": "ac4da129-7b9c-487b-9e25-f5d889eb6e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "lstm                precision    recall  f1-score   support\n\n           0       0.90      0.92      0.91      1446\n           1       0.92      0.90      0.91      1431\n\n    accuracy                           0.91      2877\n   macro avg       0.91      0.91      0.91      2877\nweighted avg       0.91      0.91      0.91      2877\n\ncnn                precision    recall  f1-score   support\n\n           0       0.95      0.80      0.87      1446\n           1       0.82      0.95      0.88      1431\n\n    accuracy                           0.88      2877\n   macro avg       0.88      0.88      0.87      2877\nweighted avg       0.89      0.88      0.87      2877\n\ngru                precision    recall  f1-score   support\n\n           0       0.90      0.93      0.92      1446\n           1       0.93      0.89      0.91      1431\n\n    accuracy                           0.91      2877\n   macro avg       0.91      0.91      0.91      2877\nweighted avg       0.91      0.91      0.91      2877\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 epochs"
      ],
      "metadata": {
        "id": "sxEJbFss7jdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# after 5\n",
        "y_pred_binary = (lstm_predictions > 0.5).astype(int)\n",
        "print(\"lstm \",classification_report(final_y_test, y_pred_binary))\n",
        "y_pred_binary = (cnn_predictions > 0.5).astype(int)\n",
        "print(\"cnn \",classification_report(final_y_test, y_pred_binary))\n",
        "y_pred_binary = (gru_predictions > 0.5).astype(int)\n",
        "print(\"gru \",classification_report(final_y_test, y_pred_binary))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T16:51:31.711849Z",
          "iopub.execute_input": "2023-07-29T16:51:31.712274Z",
          "iopub.status.idle": "2023-07-29T16:51:31.754980Z",
          "shell.execute_reply.started": "2023-07-29T16:51:31.712228Z",
          "shell.execute_reply": "2023-07-29T16:51:31.753910Z"
        },
        "trusted": true,
        "id": "LdKS2nVx7jdp",
        "outputId": "a7303639-0c2e-428b-ddaf-945eb6bf3342"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "lstm                precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91      1446\n           1       0.91      0.91      0.91      1431\n\n    accuracy                           0.91      2877\n   macro avg       0.91      0.91      0.91      2877\nweighted avg       0.91      0.91      0.91      2877\n\ncnn                precision    recall  f1-score   support\n\n           0       0.92      0.90      0.91      1446\n           1       0.90      0.92      0.91      1431\n\n    accuracy                           0.91      2877\n   macro avg       0.91      0.91      0.91      2877\nweighted avg       0.91      0.91      0.91      2877\n\ngru                precision    recall  f1-score   support\n\n           0       0.91      0.90      0.91      1446\n           1       0.90      0.91      0.91      1431\n\n    accuracy                           0.91      2877\n   macro avg       0.91      0.91      0.91      2877\nweighted avg       0.91      0.91      0.91      2877\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes on training with LSTM, GRU ,CNN:\n",
        "\n",
        "\n",
        "*   Gru and Lstm were faster than cnn\n",
        "*   CNN had better accuray during training\n",
        "*   The three models coverged faster than supervised models\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7C8dJjKhWR__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mesure Balance of data after training"
      ],
      "metadata": {
        "id": "VybcFjWXYY22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_balance(binary_data):\n",
        "    # Method 1: Counting occurrences\n",
        "    count_0 = np.sum(binary_data == 0)\n",
        "    count_1 = np.sum(binary_data == 1)\n",
        "\n",
        "    # Method 2: Calculating the proportion\n",
        "    total_samples = len(binary_data)\n",
        "    proportion_0 = count_0 / total_samples\n",
        "    proportion_1 = count_1 / total_samples\n",
        "\n",
        "    return {\n",
        "        \"count_0\": count_0,\n",
        "        \"count_1\": count_1,\n",
        "        \"proportion_0\": proportion_0,\n",
        "        \"proportion_1\": proportion_1\n",
        "    }\n",
        "\n",
        "\n",
        "binary_data = train_y_used_semi\n",
        "balance_measurements = measure_balance(binary_data)\n",
        "print(balance_measurements)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T17:16:38.870179Z",
          "iopub.execute_input": "2023-07-29T17:16:38.871082Z",
          "iopub.status.idle": "2023-07-29T17:16:38.878983Z",
          "shell.execute_reply.started": "2023-07-29T17:16:38.871048Z",
          "shell.execute_reply": "2023-07-29T17:16:38.877795Z"
        },
        "trusted": true,
        "id": "NTHjC61n7jdq",
        "outputId": "aeaa53d3-d05c-407f-ce98-89a93a9bc4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'count_0': 7242, 'count_1': 7140, 'proportion_0': 0.5035460992907801, 'proportion_1': 0.49645390070921985}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Some Trails made in project**"
      ],
      "metadata": {
        "id": "-EaGwVFxM_TO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Back translation\n",
        "\n",
        "we try to use back translation to get more context of sentences"
      ],
      "metadata": {
        "id": "HLkOygiu7jdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install translate"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T01:52:33.564464Z",
          "iopub.execute_input": "2023-07-29T01:52:33.564842Z",
          "iopub.status.idle": "2023-07-29T01:52:45.617049Z",
          "shell.execute_reply.started": "2023-07-29T01:52:33.564809Z",
          "shell.execute_reply": "2023-07-29T01:52:45.615774Z"
        },
        "trusted": true,
        "id": "_5E0u-mU7jdG",
        "outputId": "a8f20da7-fcfd-408b-cd6d-7b6e103c4768"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting translate\n  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from translate) (8.1.3)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from translate) (4.9.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from translate) (2.31.0)\nCollecting libretranslatepy==2.1.1 (from translate)\n  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (2023.5.7)\nInstalling collected packages: libretranslatepy, translate\nSuccessfully installed libretranslatepy-2.1.1 translate-3.6.1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from translate import Translator\n",
        "import random\n",
        "\n",
        "\n",
        "def back_translation(text, target_language='ar', intermediate_language='fr'):\n",
        "    translator= Translator(from_lang=target_language, to_lang=intermediate_language)\n",
        "    intermediate_translation = translator.translate(text)\n",
        "\n",
        "    translator= Translator(from_lang=intermediate_language, to_lang=target_language)\n",
        "    back_translated_text = translator.translate(intermediate_translation)\n",
        "\n",
        "    return back_translated_text\n",
        "\n",
        "# Example text for augmentation\n",
        "arabic_text = \"من النادر ان يعجبني الفلم اكثر من الروايه \"\n",
        "\n",
        "# Perform data augmentation\n",
        "back_translated_text = back_translation(arabic_text)\n",
        "\n",
        "# Print augmented texts\n",
        "print(\"Original Text: \", arabic_text)\n",
        "print(\"Back Translated Text: \", back_translated_text)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T01:52:45.619902Z",
          "iopub.execute_input": "2023-07-29T01:52:45.620628Z",
          "iopub.status.idle": "2023-07-29T01:52:48.222717Z",
          "shell.execute_reply.started": "2023-07-29T01:52:45.620587Z",
          "shell.execute_reply": "2023-07-29T01:52:48.221717Z"
        },
        "trusted": true,
        "id": "1QRVuUNT7jdH",
        "outputId": "b20b4d35-f678-447d-eb6d-16d300c227d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Original Text:  من النادر ان يعجبني الفلم اكثر من الروايه \nBack Translated Text:  نادرًا ما أحب الفيلم أكثر من الرواية.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T9ClTlCcZX_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmetation"
      ],
      "metadata": {
        "id": "12uZPPH57jdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**##########################################################################################**"
      ],
      "metadata": {
        "id": "FsSRSr9r7jdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming your data is stored in a DataFrame called Data with columns 'txt' and 'sentiment'\n",
        "# Here 'txt' contains the text data, and 'sentiment' contains the labels (0 or 1)\n",
        "\n",
        "# Define the percentage of data to augment (20% in this case)\n",
        "augmentation_percent = 0.2\n",
        "\n",
        "# Separate the data based on labels (0 and 1)\n",
        "group_0_data = Data[Data['sentiment'] == 0]['txt']\n",
        "group_1_data = Data[Data['sentiment'] == 1]['txt']\n",
        "\n",
        "# Determine the number of samples to augment from each group\n",
        "num_samples_to_augment_group_0 = int(len(group_0_data) * augmentation_percent)\n",
        "num_samples_to_augment_group_1 = int(len(group_1_data) * augmentation_percent)\n",
        "\n",
        "# Augment data from group 0\n",
        "augmented_group_0_data = []\n",
        "for text in tqdm(group_0_data.sample(num_samples_to_augment_group_0), desc='Augmenting group 0...'):\n",
        "    augmented_text = back_translation(text)\n",
        "    augmented_group_0_data.append(augmented_text)\n",
        "\n",
        "# Augment data from group 1\n",
        "augmented_group_1_data = []\n",
        "for text in tqdm(group_1_data.sample(num_samples_to_augment_group_1), desc='Augmenting group 1...'):\n",
        "    augmented_text = back_translation(text)\n",
        "    augmented_group_1_data.append(augmented_text)\n",
        "\n",
        "# Concatenate the augmented data with the original data\n",
        "augmented_data = pd.DataFrame({\n",
        "    'txt': augmented_group_0_data + augmented_group_1_data,\n",
        "    'sentiment': [0] * len(augmented_group_0_data) + [1] * len(augmented_group_1_data)\n",
        "})\n",
        "\n",
        "# Concatenate the augmented data with the original data\n",
        "augmented_Data = pd.concat([Data, augmented_data], ignore_index=True)\n",
        "\n",
        "# Now you have a new DataFrame called 'augmented_Data' containing the original data\n",
        "# with about 20 percent of the data augmented using the 'back_translation' function.\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T01:59:05.175708Z",
          "iopub.execute_input": "2023-07-29T01:59:05.176403Z",
          "iopub.status.idle": "2023-07-29T03:28:58.020979Z",
          "shell.execute_reply.started": "2023-07-29T01:59:05.176371Z",
          "shell.execute_reply": "2023-07-29T03:28:58.019031Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "Wbxq__MB7jdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_group_0_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T03:29:47.716082Z",
          "iopub.execute_input": "2023-07-29T03:29:47.716444Z",
          "iopub.status.idle": "2023-07-29T03:29:47.750117Z",
          "shell.execute_reply.started": "2023-07-29T03:29:47.716415Z",
          "shell.execute_reply": "2023-07-29T03:29:47.749211Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "9wLInhgm7jdI",
        "outputId": "cb29117b-3cf0-40da-bb0f-d2e5ad26383d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['الاختيار الناجح للكتاب الأخير اختتم تحدي العام حاولت البحث عن عبقرية الرواية أجدها أبحث عنها بشكل جيد مفهومي عن العبقرية يجد الجنس والفحش مكانا لم تعد فيه معرفتي بالمجتمع السوداني الصالح الوحيد للكتاب',\n 'لكي يظل الكتاب ذا قيمة، يجب أن يكون قادرًا على إضافة حاجة للقارئ. يجب تذكر الكتاب بشكل عام. طول الكتاب خفيف. فوجئت أنه كتب 34 كتابًا. يقول: \"لا أعرف ما هو الكتاب الأخير. لقد فهمت قراره باحترام كبير. أحببت مقال عيد ميلادي طول زغروتا ووحشه\".',\n 'كتاب خفيف، قرأت الرحلة، أعجبتني أجزائه، أحب معظمها 1',\n 'كنت أتوقع حلقة مفقودة فيها حقائق رائعة وكلمات جميلة أثارت إعجابي',\n 'كتب الجزء الخلفي من الكتاب. إنها وظيفة عادية. أقول كتابًا عاديًا. هناك فكرة واضحة في النص.',\n 'لسوء الحظ، أنا عرضة للقصص الحزينة، خاصة لوضع النساء في موقف ضعف',\n \"Un gaz est constitué de molécules en agitation permonente. Les molécules sont disperssées et chacune peut parcourir une distance assez grande avant d'en rencontrer une autre : la vitesse moyenne des molécules est de quelques centaines de mètres par seconde (la vitesse moyenne des molécules de dioxygène et de diazote de l'air que nous respirons est de 500 m/s environ ). Après chaque choc ( dans les conditions usuelles, le nombre de chocs subis par une molécule d'un gaz pendant 1 seconde est de l'ordre de 10^8 à 10^9 ) les molécules changent de direction de façon imprévisible .\",\n \"Un gaz est constitué de molécules en agitation permonente. Les molécules sont disperssées et chacune peut parcourir une distance assez grande avant d'en rencontrer une autre : la vitesse moyenne des molécules est de quelques centaines de mètres par seconde (la vitesse moyenne des molécules de dioxygène et de diazote de l'air que nous respirons est de 500 m/s environ ). Après chaque choc ( dans les conditions usuelles, le nombre de chocs subis par une molécule d'un gaz pendant 1 seconde est de l'ordre de 10^8 à 10^9 ) les molécules changent de direction de façon imprévisible .\",\n \"Un gaz est constitué de molécules en agitation permonente. Les molécules sont disperssées et chacune peut parcourir une distance assez grande avant d'en rencontrer une autre : la vitesse moyenne des molécules est de quelques centaines de mètres par seconde (la vitesse moyenne des molécules de dioxygène et de diazote de l'air que nous respirons est de 500 m/s environ ). Après chaque choc ( dans les conditions usuelles, le nombre de chocs subis par une molécule d'un gaz pendant 1 seconde est de l'ordre de 10^8 à 10^9 ) les molécules changent de direction de façon imprévisible .\",\n 'أحب عمر طاهر والكتاب في البداية مضحك وواقعي ولكن أغلبه مبتذل في الأسلوب والموضوع',\n 'QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS',\n 'الكتب التي تحب حقًا حافة الموت.  الحظ يجعلهم سجناء قضبان الذاكرة. يكتب الكاتب الأدبي الجيد طرقًا للتخلص من الذكريات بخطوات أكثر إقناعًا للعقل. كتاب يريد أن ينسى',\n 'في الواقع، كانت مجرد محادثات. كان لديك الوقت الإضافي. أردت أن تعرف عن أحد الكتب المنشورة مؤخرًا، لذا تفضل.',\n 'يا أيها الذين تريدون أن  تعيشوا، تحملوا التفسيرات، الذاكرة المريضة لموت الآخرين، أحلامنا البريئة، الذاكرة المتبقية، لقد رأينا رام الله، الأصل، نحن ممنوعون من رؤية منازلنا، نريد الإنسان، ملاك، كتاب تاريخ لمذكرات إنسان، ذاكرة جماعية',\n 'QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS',\n 'يعتبر أفضل الكتب التقليدية التي تشبه إلى حد كبير ذاكرة الجسم. أعجبتني فعلا، القصة طبيعية وأخرت الوصف كثيرا. ابتلعتني كالمعتاد. اللغة جميلة والأوصاف أكثر جمالا. أعتقد أنها أعطت البطل قيمة',\n 'إنه كتاب ممل. أحب الجزء الذي أتحدث فيه عن الديمقراطية والدولة الدينية الأخرى. قرأت آخر 100 صفحة من الكتاب. في معظم الأحيان، يتعلق الأمر بالحديث. كما تعلمون، لا أريدك أن تفوت ذلك.',\n 'الاسلوب رائع استمتع بالرواية',\n 'لقد عذبت نفسي لإنهائها، ربما الترجمة هي السبب',\n 'QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS',\n 'QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS',\n 'QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS',\n 'لقد صدمت في النهاية',\n 'لم ينل إعجابي',\n 'حلمي يكرر ويمتد التفسير إلى درجة الملل. من الممكن الاحتفاظ بالمواد لفئة عمرية معينة، الإعدادية إلى المدرسة الثانوية. على سبيل المثال، أحببت تيجوا، والضوء، والاستجابة لغروب الشمس. أحب نهاية الغلاف وصورتها والجزء الأمامي والخلفي من الكتاب.',\n 'أعلم أن الكاتب يريد أن ينقل فكرة أو يريد أن ينقل فكرة بالكامل إلى القارئ العربي. من الأفضل ترجمة النصوص ووضعها بين أيدينا لكتابة قصة ورسائل ذات مغزى تعطي شعوراً بالملل',\n 'المألوف على الأكثر يظهر سحر التفاصيل التي يشتهر بها بهاء طاهر بالعديد من الجمل المباشرة المؤامرات السينمائية الجزء المنطقي هو كراهية القنصل لحربي الصعبة يتحول 180 درجة كانت الأسباب هي الظروف المحيطة ملخص القصة هو قراءة إبداعية لبهاء طاهر',\n 'QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS',\n 'ينتهي بك الأمر بقراءته وتجد أن حجم فوائدك شيء',\n 'توقعت أن يكون أفضل بكثير',\n 'كتاب مصري عميق  يجمع بين خفة الظل، يرسم واقع أحد العاملين في الشركة، سائق التاكسي',\n 'قرأتها لفترة من الوقت. تعجبني بساطته. أنا لا أحب الأسلوب السطحي. أنا لست كتومة ومرحة.',\n 'كتاب جميل، أجد شيئًا جديدًا لأتذكر قصص القرار الذي قرأته. مجرد إعادة قراءتها يثير الأمل والحماس. أوصي بقراءة الحقل',\n 'أعجبني فصل يتحدث عن موضوع معين جميل يعطي أمثلة وقصص. أعتقد أن لدي أفكار وردية وخطيرة، خاصة شخص لا يزال يضع قواعده. الحياة وأفكاره تناسبني تمامًا أنه ذكي جدًا. وجهة نظري أنصحك بقراءتها',\n 'سخيفه ؟',\n 'اعتقدت أنه كان أجمل.',\n 'نسيت الرواية، وأعدت قراءتها، ولا أطيق الانتظار لإعادة قراءتها.',\n 'قرأت الكتاب. لقد سمعت أن الكثير من الناس يعتنون بها. أدب فتح جديد. شعرت أن الناس متخلفون عقليًا. أرادوا أن يؤمنوا بالحاجة إلى الخلاص. أكثر ما أزعجني هو الحالة الغريبة المتمثلة في تجاهل حقيقة أن الكتاب قد سرق. شخصية نادي مكافحة الشغب',\n \"Un gaz est constitué de molécules en agitation permonente. Les molécules sont disperssées et chacune peut parcourir une distance assez grande avant d'en rencontrer une autre : la vitesse moyenne des molécules est de quelques centaines de mètres par seconde (la vitesse moyenne des molécules de dioxygène et de diazote de l'air que nous respirons est de 500 m/s environ ). Après chaque choc ( dans les conditions usuelles, le nombre de chocs subis par une molécule d'un gaz pendant 1 seconde est de l'ordre de 10^8 à 10^9 ) les molécules changent de direction de façon imprévisible .\",\n 'سميت من قبل أختي الصغيرة، وسخرت من الاسم لأول مرة. كنت أتوقع أن تحتوي على قصة حب مراهقة تحكي عن حب مأساوي يبهرني. تصف التفاصيل التفاصيل. كانت التفاصيل هي الحد الزمني المحدد. الطريقة التي تقول بها ذلك تنطوي على الكثير من الإثارة. التشويق يصرف انتباهي كثيرًا عن شخصياتها بقدر ما يؤكد نهايتها. قول درويش   الحب كذبنا الصادق',\n 'الرواية محبوبة من الروائي بادبه غازي قادر، روايته أجمل بكثير',\n 'كتاب التطرف',\n 'أنا أحب صياحه',\n \"Un gaz est constitué de molécules en agitation permonente. Les molécules sont disperssées et chacune peut parcourir une distance assez grande avant d'en rencontrer une autre : la vitesse moyenne des molécules est de quelques centaines de mètres par seconde (la vitesse moyenne des molécules de dioxygène et de diazote de l'air que nous respirons est de 500 m/s environ ). Après chaque choc ( dans les conditions usuelles, le nombre de chocs subis par une molécule d'un gaz pendant 1 seconde est de l'ordre de 10^8 à 10^9 ) les molécules changent de direction de façon imprévisible .\",\n 'تعلمت أن أستمع إلى نصيحة شخص يقول: \"الكتاب تحفة أدبية، والكثير من القمامة والأوساخ تجده رواية\".',\n 'تم تجاوز حد طول الاستعلام. الحد الأقصى المسموح به للاستعلام: تم تجاوز حد طول الاستعلام 500 حرف. الحد الأقصى المسموح به للاستعلام: تم تجاوز حد طول الاستعلام 500 حرف. الحد الأقصى المسموح به للاستعلام: 500 حرف',\n 'ليس هناك شك في أن الكتاب ممتع للغاية. أحب القصص التي تخيل الكاتب علاقته ببيل ومواقفه. أعجبتني المقالات. سخر الكاتب من موضوعات مجتمعاتنا. الحقيقة هي أنه من المفترض أن يزرع الكتاب ابتسامة',\n 'الكتاب جيد له. إنها لعبة للرجال. اسمه هيثم في تامر وشوقية',\n \"Un gaz est constitué de molécules en agitation permonente. Les molécules sont disperssées et chacune peut parcourir une distance assez grande avant d'en rencontrer une autre : la vitesse moyenne des molécules est de quelques centaines de mètres par seconde (la vitesse moyenne des molécules de dioxygène et de diazote de l'air que nous respirons est de 500 m/s environ ). Après chaque choc ( dans les conditions usuelles, le nombre de chocs subis par une molécule d'un gaz pendant 1 seconde est de l'ordre de 10^8 à 10^9 ) les molécules changent de direction de façon imprévisible .\",\n 'QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS',\n 'الرواية جيدة نوعا ما ووصف منفلوتي لكنه ناقص بامتصاص الوصف وملله',\n 'أنا أحب الرواية بشكل عام. فاجأني نجم الشخصية البطلة حقًا. ولدت الشخصية المشوشة عجوزًا وخسرت لدرجة أنها تريد حقًا أن تعرف طوال الوقت. أعتقد أنها تعرف النهاية.',\n 'كيف يمكن للناس أن يكونوا بهذه القوة\\xa0؟  أحب أن أفتخر بديني',\n 'يناسب الأسود كتاب الخيال للكاتبة أحلام مستغانمي. آخر واحد حاولت مزج الأحلام مع الواقع. لسوء الحظ، تعرض للإهانة من أغلى ما تملكه الفتاة الأوراسية. الشرف. نتمنى ان يسبح الكاتب بعيدا في بحر خياله. شتائم خيالية',\n 'لا أستطيع إكمالها مملة بشكل طبيعي، لسوء الحظ، فإن التجربة الأولى لقراءة رواية للدكتور رضوي عاشور لا تزال سيئة للغاية بالنسبة لي',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 58 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 57 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 56 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 55 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 54 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 53 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 52 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 51 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 50 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 49 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 48 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 47 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 46 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 45 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 44 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 43 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 42 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 41 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 40 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 39 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 38 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 37 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 36 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 45 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 35 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 34 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 33 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 43 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 41 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 36 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 34 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 27 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 20 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 32 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 58 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 47 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 38 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 31 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 29 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 22 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 19 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 17 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 14 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 12 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 10 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 08 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 05 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 03 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 31 MINUTES 01 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 56 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 54 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 52 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 49 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 24 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 18 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 16 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 15 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 13 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 11 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 09 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 07 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 06 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 04 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 02 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 30 MINUTES 00 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 59 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 57 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 55 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 53 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 51 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 50 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 48 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 46 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 44 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 42 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 40 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 39 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 37 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 35 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 33 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 32 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 30 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 28 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 26 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 25 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 23 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n 'MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  06 HOURS 29 MINUTES 21 SECONDS VISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE',\n ...]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('augmented_group_0_data.npy', augmented_group_0_data)\n",
        "np.save('augmented_group_1_data.npy', augmented_group_1_data)\n",
        "np.save('augmented__data.npy', augmented_Data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T03:28:58.377368Z",
          "iopub.status.idle": "2023-07-29T03:28:58.378170Z",
          "shell.execute_reply.started": "2023-07-29T03:28:58.377924Z",
          "shell.execute_reply": "2023-07-29T03:28:58.377948Z"
        },
        "trusted": true,
        "id": "pWTXuRlz7jdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data[\"txt\"][ Data[\"sentiment\"] == 1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T01:57:43.991274Z",
          "iopub.execute_input": "2023-07-29T01:57:43.991641Z",
          "iopub.status.idle": "2023-07-29T01:57:44.000967Z",
          "shell.execute_reply.started": "2023-07-29T01:57:43.991611Z",
          "shell.execute_reply": "2023-07-29T01:57:43.999978Z"
        },
        "trusted": true,
        "id": "LxDckpN_7jdI",
        "outputId": "ba432f96-9090-49e8-9eea-2bb4cd91e978"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "5        رحله جميله وممتعه يصحبنا الدكتور مصطفي محمود ك...\n6        لمن يدركها معاني حقائق مذهله ادركها تذكره اكتر...\n8        بالضروره ان تكون عظيما تحلم  ان تحلم تكون عظيم...\n13       كتاب حلو ويستاهل القراءه اكثر ولازم الواحد يفك...\n15       روايه ممتعه تحمست اكثر عرفت انها نقل لمخطوطات ...\n                               ...                        \n16437    الروايه راائعه والاسلوب جميل ايحائات جنسيه نفرتني\n16438    احد اهم الكُتب قراتها حياتي استفدت بشكل كبير  ...\n16441      تراب بيحيا بيصير تراب والاصل الموت الحياه وعجبي\n16442    علاء الاسواني طبعا مفيش كلام اقدر اقوله الرواي...\n16446    بدايه الروايه وانا احاول تمالك تعاندني عبرات م...\nName: txt, Length: 8224, dtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T03:28:58.375106Z",
          "iopub.status.idle": "2023-07-29T03:28:58.375603Z",
          "shell.execute_reply.started": "2023-07-29T03:28:58.375364Z",
          "shell.execute_reply": "2023-07-29T03:28:58.375387Z"
        },
        "trusted": true,
        "id": "4rP-1kR-7jdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data without embedding"
      ],
      "metadata": {
        "id": "dD8Z24w0n6Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate positive and negative reviews\n",
        "positive_data = Data[Data['sentiment'] == 1]\n",
        "negative_data = Data[Data['sentiment'] == 0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T21:14:22.414337Z",
          "iopub.execute_input": "2023-07-28T21:14:22.414714Z",
          "iopub.status.idle": "2023-07-28T21:14:22.424783Z",
          "shell.execute_reply.started": "2023-07-28T21:14:22.414679Z",
          "shell.execute_reply": "2023-07-28T21:14:22.423857Z"
        },
        "trusted": true,
        "id": "RtqraOPe7jdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_positive = positive_data.sample(n=5000, random_state=42)\n",
        "random_negative = negative_data.sample(n=5000, random_state=42)\n",
        "random_selected_data = pd.concat([random_positive, random_negative])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T21:14:22.426613Z",
          "iopub.execute_input": "2023-07-28T21:14:22.427051Z",
          "iopub.status.idle": "2023-07-28T21:14:22.437895Z",
          "shell.execute_reply.started": "2023-07-28T21:14:22.427014Z",
          "shell.execute_reply": "2023-07-28T21:14:22.437001Z"
        },
        "trusted": true,
        "id": "vEWbxFz37jdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_selected_data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T21:14:22.439504Z",
          "iopub.execute_input": "2023-07-28T21:14:22.439864Z",
          "iopub.status.idle": "2023-07-28T21:14:22.448919Z",
          "shell.execute_reply.started": "2023-07-28T21:14:22.439830Z",
          "shell.execute_reply": "2023-07-28T21:14:22.448009Z"
        },
        "trusted": true,
        "id": "E7WaiPyx7jdN",
        "outputId": "35b7bbdc-9064-4fb4-c5d1-9f08f299c748"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(10000, 3)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_data = Data.drop(random_selected_data.index)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T21:14:22.450363Z",
          "iopub.execute_input": "2023-07-28T21:14:22.450697Z",
          "iopub.status.idle": "2023-07-28T21:14:22.461039Z",
          "shell.execute_reply.started": "2023-07-28T21:14:22.450665Z",
          "shell.execute_reply": "2023-07-28T21:14:22.460140Z"
        },
        "trusted": true,
        "id": "SQGxz8Cy7jdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(random_selected_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0v8TZFLpn5p9",
        "execution": {
          "iopub.status.busy": "2023-07-28T21:14:22.462680Z",
          "iopub.execute_input": "2023-07-28T21:14:22.463012Z",
          "iopub.status.idle": "2023-07-28T21:14:22.475756Z",
          "shell.execute_reply.started": "2023-07-28T21:14:22.462981Z",
          "shell.execute_reply": "2023-07-28T21:14:22.474836Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_selected_data.to_csv('random_selected_data.csv', index=False)\n",
        "remaining_data.to_csv('remaining_data.csv', index=False)\n",
        "train_data.to_csv('train_data.csv', index=False)\n",
        "test_data.to_csv('test_data.csv', index=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T21:33:25.007438Z",
          "iopub.execute_input": "2023-07-28T21:33:25.008147Z",
          "iopub.status.idle": "2023-07-28T21:33:25.638698Z",
          "shell.execute_reply.started": "2023-07-28T21:33:25.008112Z",
          "shell.execute_reply": "2023-07-28T21:33:25.637593Z"
        },
        "trusted": true,
        "id": "PCbet2vN7jdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_selected_data = pd.read_csv('random_selected_data.csv')\n",
        "remaining_data = pd.read_csv('remaining_data.csv')\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T12:00:57.271274Z",
          "iopub.execute_input": "2023-07-29T12:00:57.271625Z",
          "iopub.status.idle": "2023-07-29T12:00:57.313929Z",
          "shell.execute_reply.started": "2023-07-29T12:00:57.271595Z",
          "shell.execute_reply": "2023-07-29T12:00:57.312511Z"
        },
        "trusted": true,
        "id": "0ijUYQyU7jdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_X_train=train_data['stemming Words']\n",
        "global_y_train=train_data['sentiment'].values\n",
        "global_X_test=test_data['stemming Words']\n",
        "global_y_test=test_data['sentiment'].values"
      ],
      "metadata": {
        "id": "kWNeyOY3CltY",
        "execution": {
          "iopub.status.busy": "2023-07-28T21:33:32.397318Z",
          "iopub.execute_input": "2023-07-28T21:33:32.398420Z",
          "iopub.status.idle": "2023-07-28T21:33:32.406889Z",
          "shell.execute_reply.started": "2023-07-28T21:33:32.398376Z",
          "shell.execute_reply": "2023-07-28T21:33:32.405779Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_data.head(400)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T21:33:32.621966Z",
          "iopub.execute_input": "2023-07-28T21:33:32.622281Z",
          "iopub.status.idle": "2023-07-28T21:33:32.641184Z",
          "shell.execute_reply.started": "2023-07-28T21:33:32.622254Z",
          "shell.execute_reply": "2023-07-28T21:33:32.640129Z"
        },
        "trusted": true,
        "id": "GgclFT417jdP",
        "outputId": "170be45b-b7fd-40ae-eeff-264c82737f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     sentiment                                                txt  \\\n0            0  النادر ان يعجبني الفلم اكثر الروايه  تفوق دعاء...   \n1            0  كتاب سي الاسلوب ممتع نهايه مفتوحه والكتاب بوجه...   \n2            0  قصه مشوقه ونهايه مفتوحه  اسوء صفحه في الروايه ...   \n3            0  ابدع الكاتب سرد الحقائق التاريخيه او بمعني اصح...   \n4            1  لمن يدركها معاني حقائق مذهله ادركها تذكره اكتر...   \n..         ...                                                ...   \n395          0  روايه رديئه تسعدني ماساتي الروايات الرديئه تضي...   \n396          0                               30 رائع والباقي عادي   \n397          1                   روايه اكثر رائعه نهايه اروع اجمل   \n398          1  رايت ضعفي مواطن ضعفه اخافني اخره باضعاف اراحني...   \n399          1  بالرغم بساطته الا انه عميق يصف المجتمع المصري ...   \n\n                                        stemming Words  \n0               ندر ان عجب فلم كثر ريه تفق دعء كرو ريه  \n1               كتب سي سلب متع نهي فتح كتب بوج عام كئب  \n2    قصه شوق ونه فتح اسء صفح في ريه هي اخر صفح عجب ...  \n3    بدع كتب سرد حقق ارخ او بمع اصح فضح وضح صور تكن...  \n4    لمن يدر معا حقق ذهل ادر ذكر كتر فصل عجب الل كل...  \n..                                                 ...  \n395  ريه ردئ سعد است روي ردئ تضع مرت قرء كتب عنه ام...  \n396                                     30 رئع بقي عدي  \n397                            ريه كثر رئع نهي ارع جمل  \n398    ريت ضعف وطن ضعف اخف اخر ضعف ارح اخذ كان بعد ترك  \n399  رغم بسط الا انه عمق يصف جمع صري وضح لسن فرد عب...  \n\n[400 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>txt</th>\n      <th>stemming Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>النادر ان يعجبني الفلم اكثر الروايه  تفوق دعاء...</td>\n      <td>ندر ان عجب فلم كثر ريه تفق دعء كرو ريه</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>كتاب سي الاسلوب ممتع نهايه مفتوحه والكتاب بوجه...</td>\n      <td>كتب سي سلب متع نهي فتح كتب بوج عام كئب</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>قصه مشوقه ونهايه مفتوحه  اسوء صفحه في الروايه ...</td>\n      <td>قصه شوق ونه فتح اسء صفح في ريه هي اخر صفح عجب ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>ابدع الكاتب سرد الحقائق التاريخيه او بمعني اصح...</td>\n      <td>بدع كتب سرد حقق ارخ او بمع اصح فضح وضح صور تكن...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>لمن يدركها معاني حقائق مذهله ادركها تذكره اكتر...</td>\n      <td>لمن يدر معا حقق ذهل ادر ذكر كتر فصل عجب الل كل...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>0</td>\n      <td>روايه رديئه تسعدني ماساتي الروايات الرديئه تضي...</td>\n      <td>ريه ردئ سعد است روي ردئ تضع مرت قرء كتب عنه ام...</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>0</td>\n      <td>30 رائع والباقي عادي</td>\n      <td>30 رئع بقي عدي</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>1</td>\n      <td>روايه اكثر رائعه نهايه اروع اجمل</td>\n      <td>ريه كثر رئع نهي ارع جمل</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>1</td>\n      <td>رايت ضعفي مواطن ضعفه اخافني اخره باضعاف اراحني...</td>\n      <td>ريت ضعف وطن ضعف اخف اخر ضعف ارح اخذ كان بعد ترك</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>1</td>\n      <td>بالرغم بساطته الا انه عميق يصف المجتمع المصري ...</td>\n      <td>رغم بسط الا انه عمق يصف جمع صري وضح لسن فرد عب...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try arabert for embedding , but it crash in memory"
      ],
      "metadata": {
        "id": "SBD34Tr1smfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9fj_WFGWNwc",
        "outputId": "7a423067-66d5-4ba4-c242-0c2e5cdba6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Cloning into 'arabert'...\n",
            "remote: Enumerating objects: 600, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (600/600), 9.14 MiB | 19.07 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n",
            "Requirement already satisfied: PyArabic in /usr/local/lib/python3.10/dist-packages (from -r arabert/requirements.txt (line 3)) (0.6.15)\n",
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.10/dist-packages (from -r arabert/requirements.txt (line 4)) (0.0.14)\n",
            "Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.10/dist-packages (from -r arabert/requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from PyArabic->-r arabert/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy->-r arabert/requirements.txt (line 4)) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy->-r arabert/requirements.txt (line 4)) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->-r arabert/requirements.txt (line 4)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->-r arabert/requirements.txt (line 4)) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->-r arabert/requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->-r arabert/requirements.txt (line 4)) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!git clone https://github.com/aub-mind/arabert\n",
        "!pip install -r arabert/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7gZIaSWXFLP"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from arabert.preprocess import ArabertPreprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzYGeY10XkHz"
      },
      "source": [
        "### Initialize Model, Tokenizer and preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "663255b8f4ff4893b75a80a455cb6006",
            "e1eaf8365c7b49a594d2d1c54f535c8d",
            "01c8e34a273e4136bf94b22e833f378c",
            "a98db3a3af654fdea671b974366d7765",
            "26e1b364c78541da863a7c583b3092c9",
            "5e903cc1259d497891245a59da9a2b87",
            "fbbf651cfcb64409b37803b9e96cce37",
            "67d243f5f2724deeb6be7bd1cb6a8a9f",
            "3a09f3157c944842adb146e8a5407b17",
            "eeabcf770fbd4bccbf990ba2c874f356",
            "bdf2c65a49124275a9830a97ad1151c1",
            "274fc213c4d84c908acd0ca062c62c21",
            "1ad7077b9ec44c76a8b3cfdf3301fe84",
            "1a5d442e0438413dbff6f9852a0aa6ab",
            "47780619e20041b4b3395486e312b85c",
            "b5bff60573ce4aab82efdcd680d48a3c",
            "a3cc535ad8904959aec48e869eb4beee",
            "2a76519e3c5e49e597fb77a7734daf99",
            "c4e526383a824d1db5ffe87a68dc216f",
            "46ee78ec236a4576a3a486786aa9cf98",
            "7df92db0bf3748bebdc1a06e7095ff69",
            "ee833340420c4c5db309bf3d99b85d78"
          ]
        },
        "id": "oviMhf4dWXul",
        "outputId": "655e9e62-ac23-482c-b426-27f8a706393d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 241M/241M [00:28<00:00, 8.40MiB/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2023-07-28 18:13:07,291 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "663255b8f4ff4893b75a80a455cb6006",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "274fc213c4d84c908acd0ca062c62c21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OIF2Bgcaj37"
      },
      "source": [
        "Preprocessing the text before passing through the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_sentence_embeddings(sentences, tokenizer, model, batch_size=32, chunk_size=100):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    num_sentences = len(sentences)\n",
        "    max_length = 0\n",
        "    all_embeddings = []\n",
        "\n",
        "    for start in tqdm(range(0, num_sentences, chunk_size), desc='Chunks'):\n",
        "        end = min(start + chunk_size, num_sentences)\n",
        "        chunk_sentences = sentences[start:end]\n",
        "\n",
        "        for chunk_start in range(0, len(chunk_sentences), batch_size):\n",
        "            chunk_end = min(chunk_start + batch_size, len(chunk_sentences))\n",
        "            batch_sentences = chunk_sentences[chunk_start:chunk_end]\n",
        "\n",
        "            # Preprocess the sentences and encode them using the tokenizer\n",
        "            preprocessed_sentences = [arabert_prep.preprocess(sentence) for sentence in batch_sentences]\n",
        "            inputs = tokenizer(preprocessed_sentences, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "            # Get the embeddings from the model\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            # Extract the embeddings for the text tokens only (excluding [CLS] and [SEP])\n",
        "            embeddings_text_only = outputs['last_hidden_state'][:, 1:-1, :]\n",
        "\n",
        "            # Update the maximum sequence length\n",
        "            max_length = max(max_length, embeddings_text_only.shape[1])\n",
        "\n",
        "            # Convert the PyTorch tensor to a NumPy array and append to the list of embeddings\n",
        "            embeddings_text_only_np = embeddings_text_only.cpu().numpy()\n",
        "            all_embeddings.append(embeddings_text_only_np)\n",
        "\n",
        "    # Pad shorter embeddings to match the maximum sequence length\n",
        "    padded_embeddings = [np.pad(emb, ((0, 0), (0, max_length - emb.shape[1]), (0, 0)), mode='constant') for emb in all_embeddings]\n",
        "\n",
        "    # Concatenate the embeddings from all chunks\n",
        "    all_embeddings_np = np.concatenate(padded_embeddings, axis=0)\n",
        "\n",
        "    return all_embeddings_np\n"
      ],
      "metadata": {
        "id": "o_3ASZa8s70n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "batch_size = global_X_train.shape[0] // 10\n",
        "rem = global_X_train.shape[0] % 10\n",
        "start_batch_idx = 0\n",
        "\n",
        "for batch_idx in range(start_batch_idx, 10):\n",
        "    if batch_idx < 9:\n",
        "        batch_data = global_X_train[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
        "    else:\n",
        "        batch_data = global_X_train[batch_idx * batch_size :]\n",
        "\n",
        "    # Convert batch_data to a list of sentences\n",
        "    batch_sentences = batch_data.tolist()\n",
        "\n",
        "    # Get the embeddings for the current batch\n",
        "    x_batch = get_sentence_embeddings(batch_sentences, tokenizer, model)\n",
        "\n",
        "    # Save the embeddings for the current batch\n",
        "    np.save(f'batch_features_{batch_idx}.npy', x_batch)\n",
        "    print(f'Batch {batch_idx+1} features saved.')\n",
        "\n",
        "print(\"All batches processed and saved.\")\n"
      ],
      "metadata": {
        "id": "sEu6Ugl0tFOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create an empty list to store the batch feature arrays\n",
        "all_batches = []\n",
        "\n",
        "# Set the range of batch indices to be combined (start_batch_idx to 9)\n",
        "start_batch_idx = 0\n",
        "\n",
        "for batch_idx in range(start_batch_idx, 10):\n",
        "    batch_file_path = f'batch_features_{batch_idx}.npy'\n",
        "    batch_features = np.load(batch_file_path)\n",
        "    all_batches.append(batch_features)\n",
        "\n",
        "# Concatenate all the batches along the first axis (axis=0)\n",
        "x_train = np.concatenate(all_batches, axis=0)\n"
      ],
      "metadata": {
        "id": "ir3izX84tTnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QOEItOHbzKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequancy embedding\n",
        "\n",
        "\n",
        "*   give accunacy [.83-.85] in base model but didn't well with semi supervised\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J1rlm0qM7jdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we can improve the vectroization maybe im not sure\n",
        "tfidf = TfidfVectorizer(use_idf=True)\n",
        "global_X_train_counts = tfidf.fit_transform(map(lambda x: str(x), global_X_train))\n",
        "global_X_test_counts = tfidf.transform(global_X_test)\n",
        "global_remaning_counts=tfidf.transform(remaining_data[\"stemming Words\"])"
      ],
      "metadata": {
        "id": "RQzjKFNIDoHM",
        "execution": {
          "iopub.status.busy": "2023-07-28T13:20:14.098572Z",
          "iopub.execute_input": "2023-07-28T13:20:14.099068Z",
          "iopub.status.idle": "2023-07-28T13:20:15.132729Z",
          "shell.execute_reply.started": "2023-07-28T13:20:14.098988Z",
          "shell.execute_reply": "2023-07-28T13:20:15.131437Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf07579-598d-457d-9d68-64929cde4874",
        "id": "cl0hEpT6FlEt"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13158, 17638)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "global_X_train_counts.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aravec\n",
        "\n",
        "\n",
        "*   not worked well gives around .74 in base model\n",
        "\n"
      ],
      "metadata": {
        "id": "QPNpXTf57jdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL to the pre-trained model zip file\n",
        "url = \"https://bakrianoo.ewr1.vultrobjects.com/aravec/full_grams_cbow_300_twitter.zip\"\n",
        "\n",
        "# Directory where you want to save the downloaded and extracted files\n",
        "download_dir = \"/kaggle/working/pretrained_model\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "# Download the zip file\n",
        "zip_file_path = os.path.join(download_dir, \"pretrained_model.zip\")\n",
        "response = requests.get(url)\n",
        "with open(zip_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(download_dir)\n",
        "\n",
        "# Remove the zip file after extraction (optional)\n",
        "os.remove(zip_file_path)\n",
        "\n",
        "# Now the pre-trained model files are extracted in the \"pretrained_model\" directory\n",
        "# You can use them in your code\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T16:02:48.325470Z",
          "iopub.execute_input": "2023-07-28T16:02:48.326087Z",
          "iopub.status.idle": "2023-07-28T16:05:27.128584Z",
          "shell.execute_reply.started": "2023-07-28T16:02:48.326045Z",
          "shell.execute_reply": "2023-07-28T16:05:27.126368Z"
        },
        "trusted": true,
        "id": "xYZVnKLB7jdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://bakrianoo.sfo2.digitaloceanspaces.com/aravec/full_grams_cbow_100_twitter.zip\"\n",
        "!unzip \"full_grams_cbow_100_twitter.zip\""
      ],
      "metadata": {
        "id": "Fq1E3U7T7jdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "# Directory where the pre-trained model files are extracted\n",
        "model_dir = \"/kaggle/working/pretrained_model\"\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model_path = os.path.join(model_dir, \"full_grams_cbow_300_twitter.mdl\")\n",
        "word2vec_model = gensim.models.Word2Vec.load(model_path)\n",
        "\n",
        "# Example: Get the embedding for a word\n",
        "word = \"احمد\"\n",
        "embedding = word2vec_model.wv[word]\n",
        "print(f\"Embedding for '{word}': {embedding}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX9FtJXoEHLR",
        "outputId": "f1bff8ea-fce9-406f-e96e-c63c9f0b0205",
        "execution": {
          "iopub.status.busy": "2023-07-28T16:15:47.319719Z",
          "iopub.execute_input": "2023-07-28T16:15:47.320219Z",
          "iopub.status.idle": "2023-07-28T16:16:52.665697Z",
          "shell.execute_reply.started": "2023-07-28T16:15:47.320178Z",
          "shell.execute_reply": "2023-07-28T16:16:52.663500Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Embedding for 'احمد': [ 1.0711770e+00 -3.6366937e-01 -9.5984745e-01  5.9323770e-01\n -1.6792672e+00  2.7183785e+00  7.6476139e-01 -1.8510075e+00\n  7.6419044e-01 -2.4086001e+00 -3.4724775e-01  5.7128268e-01\n  1.0522168e+00 -2.2497294e+00 -9.9155331e-01 -9.0104245e-02\n  7.4065799e-01 -9.7543144e-01  4.3582708e-01  4.2373198e-01\n  2.6659945e-01  2.5663178e+00 -1.3849914e+00 -3.2364950e-01\n  8.6762732e-01 -6.7532367e-01  3.2190281e-01 -4.7814640e-01\n  7.2252446e-01  1.7651650e-01 -2.4637885e-01  7.6005870e-01\n  1.4308445e+00  3.1840450e-01  1.0302278e+00  2.2154628e-01\n -1.0100104e+00  3.9178032e-01 -2.2038111e-01 -1.2943052e+00\n -3.8881847e-01  1.0120368e+00 -2.1500063e+00 -9.0473139e-01\n  9.3660122e-01 -1.0256208e+00  4.2335141e-01 -5.4581034e-01\n  5.3167492e-01 -3.9438644e-01 -1.9251767e+00 -4.9484327e-01\n  3.6231408e-01  8.8881165e-01  1.4336803e+00 -1.8687539e+00\n  2.5200909e-01  1.0103284e+00  4.1559720e-01 -1.7963324e+00\n  1.5816576e+00  2.0187500e+00  2.6948828e-01  2.1557736e+00\n -1.4629833e+00  3.4545800e-01 -5.4444271e-01  1.3110170e+00\n -4.4778463e-01 -1.6763059e+00 -1.4943743e+00  6.8659492e-02\n -4.9999505e-01 -5.4765564e-01  2.4782176e+00 -3.3011642e-01\n  1.0994622e+00 -9.1615014e-02  1.0270197e+00 -8.9347661e-01\n -1.0467715e+00  4.9377742e-01  1.3938110e+00 -1.1744643e+00\n -1.2843858e+00  5.2092791e-01 -2.1877773e+00 -5.9628451e-01\n -5.9515554e-02  1.3308802e-01 -6.4166796e-01 -1.0425583e+00\n -2.6190996e+00  7.4877572e-01 -1.8037132e+00 -5.7332617e-01\n -1.8459189e+00  2.7582911e-01 -1.4142724e+00 -2.0988595e+00\n  1.3061792e-01  2.2139039e+00 -3.5296339e-01  1.8618697e+00\n -3.0312586e-01 -2.2693266e-01 -3.9853007e-01  3.9847690e-01\n -6.4614102e-02 -8.6888111e-01 -3.1185222e-01  1.9253663e+00\n -9.4609964e-01  7.0823884e-01 -1.4937950e+00 -1.8309753e-01\n -3.9291468e-01 -2.3171561e+00 -2.6376495e-01 -9.1314852e-01\n -9.5464504e-01  1.6651424e+00  7.2662544e-01 -3.1154279e-03\n -1.9414337e+00 -6.4135665e-01 -2.1358262e-01  1.4588784e+00\n -3.1696093e+00 -7.3542058e-01  1.3388401e-01 -7.3035991e-01\n -1.6007941e+00 -1.1032221e+00 -2.1481754e-01  3.6957121e-01\n -8.7605810e-01 -1.2482510e-01  2.5926533e+00  9.7105807e-01\n -8.8577384e-01  8.5109997e-01 -8.0304450e-01 -4.0922663e-01\n  3.7149113e-01  1.7033488e+00  2.8190374e+00  2.6115911e+00\n -3.5986254e-01 -3.6079100e-01  4.9545118e-01 -1.2797512e+00\n  3.4800392e-01 -4.0166837e-01 -1.4775370e-01  6.7237806e-01\n  2.7336831e+00  2.0827308e+00 -3.6590165e-01  2.7831472e-02\n  1.5906016e+00 -1.2682413e+00  2.1467978e-01  8.4479266e-01\n -1.3251543e+00  1.0115632e+00  1.8711056e-01 -6.9093019e-01\n  4.0623972e-01  3.0267921e-01  8.3118922e-01  2.7796903e-01\n  4.3061671e-01  2.9158726e-02 -9.7852784e-01  1.5622998e+00\n  1.8119755e+00  8.3450657e-01  1.0779816e+00  1.2899927e+00\n -1.2978993e-01 -9.4642174e-01  4.2326382e-01 -6.0001481e-01\n  6.9984192e-01  6.9182318e-01 -1.7914319e+00 -2.5867426e-01\n -1.2826610e+00  1.3727975e-01 -4.0680623e-01  7.1051514e-01\n  2.3441719e-01 -1.3460526e-01 -6.3725823e-01 -4.1301605e-01\n -2.1776204e-01  4.8246658e-01 -1.1983854e+00 -1.5850079e+00\n  8.3363467e-01  7.3612648e-01  2.3623066e-01 -2.5386399e-01\n  1.4384458e+00  8.2584429e-01 -1.7417995e-02  1.1667534e+00\n  6.6763155e-02 -9.4466902e-02 -1.3782493e+00 -1.7504586e+00\n  5.3744432e-02 -1.7630585e-01  1.3456994e+00 -4.3351659e-01\n -1.2109065e+00 -5.5902803e-01 -1.0440447e+00 -1.6744192e+00\n -1.0126782e-01 -3.6097911e-01  2.5312865e-01 -1.1342202e+00\n  7.8480172e-01  2.2666767e-01 -5.3035688e-01 -6.0661625e-02\n  7.7265507e-01  2.3906803e+00  4.3428564e-01  1.9703871e+00\n  3.5344693e-01 -2.8641030e-01  6.3583583e-01  1.6237080e+00\n -2.5138791e+00  9.4954330e-01  1.3405101e-01 -5.8639276e-01\n -1.3510861e+00 -1.8962978e+00 -1.7632190e+00 -1.6540661e-01\n -1.5546172e+00 -1.3105881e+00  1.0730512e+00  9.3003821e-01\n -1.6625135e-01 -2.1119292e+00 -1.1410145e+00 -3.8475060e-01\n -4.5317015e-01  2.7200210e-01  2.9568997e-01  2.6230964e-01\n  4.6462074e-01  2.0544636e-01  6.4497226e-01  1.3027203e+00\n -1.5819443e+00  5.7502931e-01 -2.3020408e+00 -5.2312046e-01\n  1.6385690e+00  1.1534277e+00 -2.6038878e+00 -8.1275719e-01\n  5.1478565e-01 -1.7991521e+00 -9.2413163e-01 -1.0524079e+00\n -8.6839414e-01  3.8703206e-01 -4.9998307e-01 -2.0654945e-01\n  1.0529947e+00  6.5306252e-01  1.0465556e+00  1.5021474e+00\n -1.0235078e+00  1.3572066e+00 -1.1644973e-02  1.8623395e+00\n  1.5930665e+00  1.0777982e+00 -4.3393600e-01  1.1171863e+00\n -5.5447900e-01 -6.8717712e-01 -1.3605782e-01 -3.6127356e-01\n -1.8024643e-01 -3.1245261e-01 -9.5498550e-01  2.2388701e+00\n -9.9489814e-01  7.3352492e-01 -8.2870972e-01  1.5122316e+00]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "# Directory where the pre-trained model files are extracted\n",
        "model_dir = \"/kaggle/working/pretrained_model\"\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model_path = os.path.join(model_dir, \"full_grams_cbow_300_twitter.mdl\")\n",
        "word2vec_model = gensim.models.Word2Vec.load(model_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T17:49:06.290463Z",
          "iopub.execute_input": "2023-07-28T17:49:06.290902Z",
          "iopub.status.idle": "2023-07-28T17:50:09.876513Z",
          "shell.execute_reply.started": "2023-07-28T17:49:06.290866Z",
          "shell.execute_reply": "2023-07-28T17:50:09.875018Z"
        },
        "trusted": true,
        "id": "Y9iz8BSk7jdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_document_embeddings(data, word2vec_model):\n",
        "    # Tokenize your sentences into individual words (tokens)\n",
        "    tokenized_data = [doc.split() for doc in data]\n",
        "\n",
        "    document_embeddings = []\n",
        "\n",
        "    for doc_tokens in tokenized_data:\n",
        "        word_embeddings = [word2vec_model.wv[word] for word in doc_tokens if word in word2vec_model.wv.key_to_index]\n",
        "\n",
        "        if word_embeddings:\n",
        "            document_embedding = np.mean(word_embeddings, axis=0)\n",
        "            document_embeddings.append(document_embedding)\n",
        "        else:\n",
        "            document_embedding = np.zeros(300)\n",
        "            document_embeddings.append(document_embedding)# Create a zero-filled array of size 300\n",
        "\n",
        "    return np.array(document_embeddings)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T18:56:30.561433Z",
          "iopub.execute_input": "2023-07-28T18:56:30.561926Z",
          "iopub.status.idle": "2023-07-28T18:56:30.571132Z",
          "shell.execute_reply.started": "2023-07-28T18:56:30.561889Z",
          "shell.execute_reply": "2023-07-28T18:56:30.569587Z"
        },
        "trusted": true,
        "id": "ee8OLw3j7jdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your sentences are stored in Data[\"stemming\"]\n",
        "#we can improve the vectroization maybe im not sure\n",
        "global_X_train_ARAVEC = generate_document_embeddings(global_X_train, word2vec_model)\n",
        "\n",
        "global_X_test_ARAVEC = generate_document_embeddings(global_X_test, word2vec_model)\n",
        "\n",
        "global_remaning_ARAVEC=generate_document_embeddings(remaining_data[\"stemming Words\"], word2vec_model)\n",
        "\n",
        "#ADD FOR THE AUGMENTED DATA\n",
        "\n",
        "# Call the function to get the embedded data\n",
        "\n",
        "print(\"Shape of the embedded data:\", document_embeddings_np.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T19:34:47.053768Z",
          "iopub.execute_input": "2023-07-28T19:34:47.055232Z",
          "iopub.status.idle": "2023-07-28T19:34:54.190301Z",
          "shell.execute_reply.started": "2023-07-28T19:34:47.055176Z",
          "shell.execute_reply": "2023-07-28T19:34:54.189308Z"
        },
        "trusted": true,
        "id": "cU7vMV487jdS",
        "outputId": "92d3ba92-bbf6-451f-c926-4a89f7f079cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Shape of the embedded data: (16448, 300)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6ZohIGicXmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmetation using marbert"
      ],
      "metadata": {
        "id": "Rgk53W6B7jdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install numpy requests nlpaug"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T17:19:53.370276Z",
          "iopub.execute_input": "2023-07-29T17:19:53.370712Z",
          "iopub.status.idle": "2023-07-29T17:20:17.045591Z",
          "shell.execute_reply.started": "2023-07-29T17:19:53.370677Z",
          "shell.execute_reply": "2023-07-29T17:20:17.044192Z"
        },
        "trusted": true,
        "id": "tKgfV3LO7jdJ",
        "outputId": "5405efbc-f1e1-453c-c4c0-e0e5eda53132"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\nCollecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2023.5.7)\nRequirement already satisfied: pandas>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from nlpaug) (1.5.3)\nRequirement already satisfied: gdown>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from nlpaug) (4.7.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (3.12.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (4.12.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2.0->nlpaug) (2023.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.3.2.post1)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests) (1.7.1)\nInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nlpaug.augmenter.word import ContextualWordEmbsAug\n",
        "from sklearn.utils import shuffle\n",
        "from tqdm import tqdm\n",
        "import transformers\n",
        "import numpy as np"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T17:20:17.048525Z",
          "iopub.execute_input": "2023-07-29T17:20:17.049241Z",
          "iopub.status.idle": "2023-07-29T17:20:23.431095Z",
          "shell.execute_reply.started": "2023-07-29T17:20:17.049183Z",
          "shell.execute_reply": "2023-07-29T17:20:23.430092Z"
        },
        "trusted": true,
        "id": "YcbfttWZ7jdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT Augmentator\n",
        "TOPK=20        # default=100\n",
        "ACT = 'insert' # \"substitute\"\n",
        "\n",
        "aug_bert = ContextualWordEmbsAug(\n",
        "    model_path= 'UBC-NLP/MARBERT',\n",
        "    action=ACT,\n",
        "    top_k=TOPK)\n",
        "\n",
        "def augment_text(df, augmented, augmenter, label_name, samples=100, pr=0.2, show=0, device='cuda'):\n",
        "    augmenter.aug_p = pr\n",
        "    new_text = []\n",
        "    new_labels = []\n",
        "\n",
        "    # Selecting the minority class samples (label = 1)\n",
        "    df_label_1 = df[df[label_name] == 1]\n",
        "    df_label_0 = df[df[label_name] == 0]\n",
        "\n",
        "    # Data augmentation loop for label 1\n",
        "    for i in tqdm(np.random.randint(0, len(df_label_1), samples)):\n",
        "        text = df_label_1.iloc[i]['txt']\n",
        "        label = df_label_1.iloc[i][label_name]\n",
        "        augmented_text = augmenter.augment(text)\n",
        "        new_text.append(augmented_text)\n",
        "        new_labels.append(label)\n",
        "\n",
        "    # Data augmentation loop for label 0\n",
        "    for i in tqdm(np.random.randint(0, len(df_label_0), samples)):\n",
        "        text = df_label_0.iloc[i]['txt']\n",
        "        label = df_label_0.iloc[i][label_name]\n",
        "        augmented_text = augmenter.augment(text)\n",
        "        new_text.append(augmented_text)\n",
        "        new_labels.append(label)\n",
        "\n",
        "    # DataFrames\n",
        "    new = pd.DataFrame({'txt': new_text, label_name: new_labels})\n",
        "    augmented = augmented.append(new)\n",
        "    return augmented"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T18:21:48.718510Z",
          "iopub.execute_input": "2023-07-29T18:21:48.718932Z",
          "iopub.status.idle": "2023-07-29T18:21:48.730476Z",
          "shell.execute_reply.started": "2023-07-29T18:21:48.718900Z",
          "shell.execute_reply": "2023-07-29T18:21:48.729272Z"
        },
        "trusted": true,
        "id": "G5bVHe_c7jdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lol =pd.DataFrame()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T18:21:55.856738Z",
          "iopub.execute_input": "2023-07-29T18:21:55.857139Z",
          "iopub.status.idle": "2023-07-29T18:21:55.862502Z",
          "shell.execute_reply.started": "2023-07-29T18:21:55.857107Z",
          "shell.execute_reply": "2023-07-29T18:21:55.861162Z"
        },
        "trusted": true,
        "id": "lNX4nFXq7jdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lol = augment_text(Data,lol, aug_bert, 'sentiment', samples=500, show=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T18:30:49.367806Z",
          "iopub.execute_input": "2023-07-29T18:30:49.368292Z"
        },
        "trusted": true,
        "id": "o9kLXG-17jdK",
        "outputId": "9c9ef1f1-f68b-4413-d284-79c318b3fae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": " 18%|█▊        | 89/500 [03:16<19:45,  2.89s/it]",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_data = lol['sentiment']\n",
        "balance_measurements = measure_balance(binary_data)\n",
        "print(balance_measurements)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T18:29:29.342710Z",
          "iopub.execute_input": "2023-07-29T18:29:29.343106Z",
          "iopub.status.idle": "2023-07-29T18:29:29.350431Z",
          "shell.execute_reply.started": "2023-07-29T18:29:29.343074Z",
          "shell.execute_reply": "2023-07-29T18:29:29.349287Z"
        },
        "trusted": true,
        "id": "K2uJohi57jdK",
        "outputId": "d12422fc-656a-4d7c-9634-b8667aba7678"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'count_0': 100, 'count_1': 100, 'proportion_0': 0.5, 'proportion_1': 0.5}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lol[\"sentiment\"].describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T18:21:58.859767Z",
          "iopub.execute_input": "2023-07-29T18:21:58.860792Z",
          "iopub.status.idle": "2023-07-29T18:22:00.176591Z",
          "shell.execute_reply.started": "2023-07-29T18:21:58.860746Z",
          "shell.execute_reply": "2023-07-29T18:22:00.174161Z"
        },
        "trusted": true,
        "id": "EsGXS__17jdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('aug_df_bert.npy', lol)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-29T03:44:38.608939Z",
          "iopub.execute_input": "2023-07-29T03:44:38.609309Z",
          "iopub.status.idle": "2023-07-29T03:44:38.615454Z",
          "shell.execute_reply.started": "2023-07-29T03:44:38.609279Z",
          "shell.execute_reply": "2023-07-29T03:44:38.614489Z"
        },
        "trusted": true,
        "id": "92-FGFEn7jdL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}